[ìŠ¤íŒŒë¥´íƒ€ì½”ë”©í´ëŸ½] 8ê°•. ì§€ë„í•™ìŠµ : íšŒê·€ëª¨ë¸ ğŸ“˜[SCC] ë°”ë‹¥ë¶€í„° ì‹œì‘í•˜ëŠ” ë¨¸ì‹ ëŸ¬ë‹/ğŸ“š[ìŠ¤íŒŒë¥´íƒ€ì½”ë”©í´ëŸ½] ë°”ë‹¥ë¶€í„° ì‹œì‘í•˜ëŠ” ë¨¸ì‹ ëŸ¬ë‹ - 3ì£¼ì°¨/ğŸ“•[ìŠ¤íŒŒë¥´íƒ€ì½”ë”©í´ëŸ½] 8ê°•. ì§€ë„í•™ìŠµ : íšŒê·€ëª¨ë¸ Made withğŸ“•[ìŠ¤íŒŒë¥´íƒ€ì½”ë”©í´ëŸ½] 8ê°•. ì§€ë„í•™ìŠµ : íšŒê·€ëª¨ë¸ [ìˆ˜ì—… ëª©í‘œ]ë‹¤ì–‘í•œ íšŒê·€ ëª¨ë¸ì— ëŒ€í•´ì„œ ë°°ì›Œë´…ì‹œë‹¤íšŒê·€(Regression)ëª¨ë¸ì€ ì—°ì†ì ì¸ ê°’ì„ ì˜ˆì¸¡í•˜ëŠ” ë¬¸ì œì…ë‹ˆë‹¤.íšŒê·€(Regression)ëª¨ë¸ì€ ì—°ì†ì ì¸ ê°’ì„ ì˜ˆì¸¡í•˜ëŠ” ë¬¸ì œì…ë‹ˆë‹¤.ï»¿
ì˜¤ëŠ˜ì€ ì„ í˜•íšŒê·€/ë‹¤í•­íšŒê·€/ë¦¬ì§€íšŒê·€/ë¼ì˜íšŒê·€ ë¥¼ ë‹¤ë¤„ë³¼ ì˜ˆì •ì…ë‹ˆë‹¤ì˜¤ëŠ˜ì€ ì„ í˜•íšŒê·€/ë‹¤í•­íšŒê·€/ë¦¬ì§€íšŒê·€/ë¼ì˜íšŒê·€ ë¥¼ ë‹¤ë¤„ë³¼ ì˜ˆì •ì…ë‹ˆë‹¤ï»¿â€‹[ëª©ì°¨]01. íšŒê·€ëª¨ë¸y=Î²0â€‹+Î²1â€‹x1â€‹+Î²2â€‹x2â€‹+â‹¯+Î²nâ€‹xnâ€‹+Ïµy=Î²0â€‹+Î²1â€‹x1â€‹+Î²2â€‹x2â€‹+â‹¯+Î²nâ€‹xnâ€‹+Ïµy=Î²0â€‹+Î²1â€‹x1â€‹+Î²2â€‹x2â€‹+â‹¯+Î²nâ€‹xnâ€‹+Ïµï»¿
ì—¬ê¸°ì„œ yëŠ” ì¢…ì†ë³€ìˆ˜, x1,x2,â€¦,xn ì€ ë…ë¦½ë³€ìˆ˜, b0 ëŠ” ì ˆí¸, b1,b2,â€¦,bnì€ íšŒê·€ê³„ìˆ˜, eëŠ” ì˜¤ì°¨ì…ë‹ˆë‹¤ì—¬ê¸°ì„œ yëŠ” ì¢…ì†ë³€ìˆ˜, x1,x2,â€¦,xn ì€ ë…ë¦½ë³€ìˆ˜, b0 ëŠ” ì ˆí¸, b1,b2,â€¦,bnì€ íšŒê·€ê³„ìˆ˜, eëŠ” ì˜¤ì°¨ì…ë‹ˆë‹¤ï»¿
â‹„ ë‹¨ìˆœ ì„ í˜• íšŒê·€ì¼ê²½ìš° â‹„ ë‹¨ìˆœ ì„ í˜• íšŒê·€ì¼ê²½ìš° ï»¿
y=Î²0â€‹+Î²1â€‹x+Ïµy=Î²0â€‹+Î²1â€‹x+Ïµï»¿
â˜‘ï¸ Scikit-learn ì„ ì‚¬ìš©í•œ ì„ í˜• íšŒê·€ ëª¨ë¸ êµ¬í˜„ ë° í‰ê°€ì„ í˜• íšŒê·€ ëª¨ë¸ êµ¬í˜„ ë° í‰ê°€ {5px}ì„ í˜• íšŒê·€ ëª¨ë¸ êµ¬í˜„ ë° í‰ê°€ ï»¿â€‹PythonCopyimport numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

# ë°ì´í„° ìƒì„±
X = np.array([[1, 1], [2, 2], [3, 3], [4, 4], [5, 5],[6,6]])
y = np.array([1, 2, 3, 4, 5, 6])
# ë°ì´í„° ë¶„í•  (í›ˆë ¨ ë°ì´í„°ì™€ í…ŒìŠ¤íŠ¸ ë°ì´í„°)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
# ì„ í˜• íšŒê·€ ëª¨ë¸ ìƒì„± ë° í•™ìŠµ
model = LinearRegression()
model.fit(X_train, y_train)
# ì˜ˆì¸¡
y_pred = model.predict(X_test)
# ëª¨ë¸ í‰ê°€
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
print(f'Mean Squared Error: {mse}')
print(f'R^2 Score: {r2}')
â€‹2) ë‹¤í•­ íšŒê·€â˜‘ï¸ ë‹¤í•­ íšŒê·€ë‹¤í•­ íšŒê·€(Polynomial Regression)ëŠ” ì¢…ì† ë³€ìˆ˜ì™€ ë…ë¦½ ë³€ìˆ˜ ê°„ì˜ ë¹„ì„ í˜• ê´€ê³„ë¥¼ ëª¨ë¸ë§í•˜ëŠ” ë°©ë²•ë…ë¦½ë³€ìˆ˜ì˜ ë‹¤í•­ì‹ì„ ì‚¬ìš©í•˜ì—¬ ê´€ê³„ë¥¼ ëª¨ë¸ë§ í•©ë‹ˆë‹¤.ë‹¤í•­ íšŒê·€ì˜ ê¸°ë³¸ ìˆ˜ì‹ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤ë‹¤í•­ íšŒê·€ì˜ ê¸°ë³¸ ìˆ˜ì‹ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤ï»¿
y=Î²0â€‹+Î²1â€‹x+Î²2â€‹x2+â‹¯+Î²nâ€‹xn+Ïµy=Î²0â€‹+Î²1â€‹x+Î²2â€‹x^2+â‹¯+Î²nâ€‹x^n+Ïµy=Î²0â€‹+Î²1â€‹x+Î²2â€‹x2+â‹¯+Î²nâ€‹xn+Ïµï»¿
ì—¬ê¸°ì„œ yëŠ” ì¢…ì†ë³€ìˆ˜, x1,x2,â€¦,xn ì€ ë…ë¦½ë³€ìˆ˜, b0 ëŠ” ì ˆí¸, b1,b2,â€¦,bnì€ íšŒê·€ê³„ìˆ˜, eëŠ” ì˜¤ì°¨ì…ë‹ˆë‹¤ì—¬ê¸°ì„œ yëŠ” ì¢…ì†ë³€ìˆ˜, x1,x2,â€¦,xn ì€ ë…ë¦½ë³€ìˆ˜, b0 ëŠ” ì ˆí¸, b1,b2,â€¦,bnì€ íšŒê·€ê³„ìˆ˜, eëŠ” ì˜¤ì°¨ì…ë‹ˆë‹¤ï»¿â€‹â˜‘ï¸ ë‹¤í•­ íšŒê·€ ì°¨ìˆ˜ ì„ íƒë‹¤í•­íšŒê·€ ì°¨ìˆ˜(degree) : ë…ë¦½ ë³€ìˆ˜ì˜ ìµœëŒ€ ì°¨ìˆ˜ì°¨ìˆ˜ê°€ ë†’ì„ìˆ˜ë¡ ëª¨ë¸ì´ ë” ë³µì¡í•´ì§€ë©° ê³¼ì í•©(overfitting)ì˜ ìœ„í—˜ ì¡´ì¬ â†’ ì ì ˆí•œ ì°¨ìˆ˜ ì„ íƒ í•„ìš”ê³¼ì í•©ì´ë€ í•™ìŠµë°ì´í„°ì— ëª¨ë¸ì´ ê³¼ë„í•˜ê²Œ ì í•©(fitting)ë˜ëŠ” í˜„ìƒì…ë‹ˆë‹¤ê³¼ì í•©ì´ë€ í•™ìŠµë°ì´í„°ì— ëª¨ë¸ì´ ê³¼ë„í•˜ê²Œ ì í•©(fitting)ë˜ëŠ” í˜„ìƒì…ë‹ˆë‹¤ï»¿â€‹â˜‘ï¸ Scikit-learnì„ ì‚¬ìš©í•œ ë‹¤í•­ íšŒê·€ ëª¨ë¸ êµ¬í˜„ ë° í‰ê°€ë‹¤í•­ íšŒê·€ ëª¨ë¸ êµ¬í˜„ ë° í‰ê°€ {5px}ë‹¤í•­ íšŒê·€ ëª¨ë¸ êµ¬í˜„ ë° í‰ê°€ ï»¿â€‹PythonCopyimport numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

# ë°ì´í„° ìƒì„±
X = np.array([[1], [2], [3], [4], [5], [6]])
y = np.array([1, 4, 9, 16, 25, 36])
# ë‹¤í•­ íŠ¹ì§• ìƒì„± (ì°¨ìˆ˜ 2)
poly = PolynomialFeatures(degree=2)
X_poly = poly.fit_transform(X)
# ë°ì´í„° ë¶„í•  (í›ˆë ¨ ë°ì´í„°ì™€ í…ŒìŠ¤íŠ¸ ë°ì´í„°)
X_train, X_test, y_train, y_test = train_test_split(X_poly, y, test_size=0.2, random_state=42)
# ë‹¤í•­ íšŒê·€ ëª¨ë¸ ìƒì„± ë° í•™ìŠµ
model = LinearRegression()
model.fit(X_train, y_train)
# ì˜ˆì¸¡
y_pred = model.predict(X_test)
# ëª¨ë¸ í‰ê°€
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
print(f'Mean Squared Error: {mse}')
print(f'R^2 Score: {r2}')
â€‹3) ë¦¬ì§€ íšŒê·€â˜‘ï¸ ë¦¬ì§€ íšŒê·€ë¦¬ì§€ íšŒê·€(Ridge Regression)ëŠ” ì„ í˜• íšŒê·€ì˜ ì¼ì¢…íšŒê·€ ê³„ìˆ˜ì˜ í¬ê¸°ë¥¼ ì œì–´í•˜ì—¬ ê³¼ì í•©ì„ ë°©ì§€í•˜ëŠ” ì •ê·œí™” ê¸°ë²•L2 ì •ê·œí™”(regularization)ë¥¼ ì‚¬ìš©í•˜ì—¬ íšŒê·€ ê³„ìˆ˜ì˜ ì œê³±í•©ì„ ìµœì†Œí™” í•©ë‹ˆë‹¤ë¦¬ì§€ íšŒê·€ì˜ ê¸°ë³¸ ìˆ˜ì‹ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤ë¦¬ì§€ íšŒê·€ì˜ ê¸°ë³¸ ìˆ˜ì‹ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤ï»¿
J(Î²)=âˆ‘i=1n(yiâˆ’y^i)2+Î»âˆ‘j=1pÎ²j2J() = _{i=1}^{n} (y_i - _i)^2 +  _{j=1}^{p} _j^2J(Î²)=âˆ‘i=1nâ€‹(yiâ€‹âˆ’y^â€‹iâ€‹)2+Î»âˆ‘j=1pâ€‹Î²j2â€‹ï»¿
ì—¬ê¸°ì„œÎ»ëŠ” ì •ê·œí™” ê°•ë„ë¥¼ ì¡°ì ˆí•˜ëŠ” í•˜ì´í¼íŒŒë¼ë¯¸í„° ì…ë‹ˆë‹¤. ì—¬ê¸°ì„œÎ»ëŠ” ì •ê·œí™” ê°•ë„ë¥¼ ì¡°ì ˆí•˜ëŠ” í•˜ì´í¼íŒŒë¼ë¯¸í„° ì…ë‹ˆë‹¤.ï»¿â€‹â˜‘ï¸ L2 ì •ê·œí™” L2 ì •ê·œí™”ëŠ” ëª¨ë“  ê°€ì¤‘ì¹˜ë¥¼ ì‘ê²Œ ë§Œë“¤ì–´ ëª¨ë¸ì˜ ë³µì¡ë„ë¥¼ ì¤„ì…ë‹ˆë‹¤.ì†ì‹¤ í•¨ìˆ˜ì— ì œê³±í•­ì„ ì¶”ê°€í•˜ì—¬ ë§¤ë„ëŸ¬ìš´ ìµœì í™”ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤.ì •ê·œí™”ëŠ” ëª¨ë¸ì˜ ë³µì¡ë„ë¥¼ ì œì–´í•˜ì—¬ ê³¼ì í•©ì„ ë°©ì§€í•˜ëŠ” ë° í•„ìš”í•©ë‹ˆë‹¤.â˜‘ï¸ Scikit-learnì„ ì‚¬ìš©í•œ ë¦¬ì§€ íšŒê·€ ëª¨ë¸ êµ¬í˜„ ë° í‰ê°€ë¦¬ì§€ íšŒê·€ ëª¨ë¸ êµ¬í˜„ ë° í‰ê°€ {5px}ë¦¬ì§€ íšŒê·€ ëª¨ë¸ êµ¬í˜„ ë° í‰ê°€ ï»¿â€‹PythonCopyimport numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import Ridge
from sklearn.metrics import mean_squared_error, r2_score

# ë°ì´í„° ìƒì„±
X = np.array([[1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6, 6]])
y = np.array([1, 2, 3, 4, 5, 6])
# ë°ì´í„° ë¶„í•  (í›ˆë ¨ ë°ì´í„°ì™€ í…ŒìŠ¤íŠ¸ ë°ì´í„°)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
# ë¦¬ì§€ íšŒê·€ ëª¨ë¸ ìƒì„± ë° í•™ìŠµ
model = Ridge(alpha=1.0)
model.fit(X_train, y_train)
# ì˜ˆì¸¡
y_pred = model.predict(X_test)
# ëª¨ë¸ í‰ê°€
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
print(f'Mean Squared Error: {mse}')
print(f'R^2 Score: {r2}')
â€‹4) ë¼ì˜ íšŒê·€â˜‘ï¸ ë¼ì˜ íšŒê·€ë¼ì˜ íšŒê·€(Lasso Regression)ëŠ” ì„ í˜• íšŒê·€ì˜ ì¼ì¢…íšŒê·€ ê³„ìˆ˜ì˜ í¬ê¸°ë¥¼ ì œì–´í•˜ì—¬ ê³¼ì í•©ì„ ë°©ì§€í•˜ëŠ” ì •ê·œí™” ê¸°ë²•L1 ì •ê·œí™”(regularization)ë¥¼ ì‚¬ìš©í•˜ì—¬ íšŒê·€ ê³„ìˆ˜ì˜ ì ˆëŒ€ê°’ í•©ì„ ìµœì†Œí™” í•©ë‹ˆë‹¤ë¼ì˜ íšŒê·€ì˜ ê¸°ë³¸ ìˆ˜ì‹ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤ë¼ì˜ íšŒê·€ì˜ ê¸°ë³¸ ìˆ˜ì‹ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤ï»¿
J(Î²)=âˆ‘i=1n(yiâˆ’y^i)2+Î»âˆ‘j=1pâˆ£Î²jâˆ£J() = _{i=1}^{n} (y_i - _i)^2 +  _{j=1}^{p} |_j|J(Î²)=âˆ‘i=1nâ€‹(yiâ€‹âˆ’y^â€‹iâ€‹)2+Î»âˆ‘j=1pâ€‹âˆ£Î²jâ€‹âˆ£ï»¿
ì—¬ê¸°ì„œÎ»ëŠ” ì •ê·œí™” ê°•ë„ë¥¼ ì¡°ì ˆí•˜ëŠ” í•˜ì´í¼íŒŒë¼ë¯¸í„° ì…ë‹ˆë‹¤. ì—¬ê¸°ì„œÎ»ëŠ” ì •ê·œí™” ê°•ë„ë¥¼ ì¡°ì ˆí•˜ëŠ” í•˜ì´í¼íŒŒë¼ë¯¸í„° ì…ë‹ˆë‹¤.ï»¿â€‹â˜‘ï¸ L1 ì •ê·œí™”ì™€ íŠ¹ì§• ì„ íƒL1 ì •ê·œí™”ëŠ” ì¼ë¶€ íšŒê·€ ê³„ìˆ˜ë¥¼ 0ìœ¼ë¡œ ë§Œë“¤ì–´ íŠ¹ì§• ì„ íƒ(feature selection)ì„ ìˆ˜í–‰ëª¨ë¸ì˜ í•´ì„ ê°€ëŠ¥ì„±ì„ ë†’ì´ê³ , ë¶ˆí•„ìš”í•œ íŠ¹ì§•ì„ ì œê±°í•˜ëŠ” ë° ìœ ìš©í•©ë‹ˆë‹¤â˜‘ï¸ Scikit-learnì„ ì‚¬ìš©í•œ ë¼ì˜ íšŒê·€ ëª¨ë¸ êµ¬í˜„ ë° í‰ê°€ë¼ì˜ íšŒê·€ ëª¨ë¸ êµ¬í˜„ ë° í‰ê°€ {5px}ë¼ì˜ íšŒê·€ ëª¨ë¸ êµ¬í˜„ ë° í‰ê°€ ï»¿â€‹PythonCopyimport numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import Lasso
from sklearn.metrics import mean_squared_error, r2_score

# ë°ì´í„° ìƒì„±
X = np.array([[1, 1], [2, 2], [3, 3], [4, 4], [5, 5], [6,6]])
y = np.array([1, 2, 3, 4, 5, 6])
# ë°ì´í„° ë¶„í•  (í›ˆë ¨ ë°ì´í„°ì™€ í…ŒìŠ¤íŠ¸ ë°ì´í„°)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
# ë¼ì˜ íšŒê·€ ëª¨ë¸ ìƒì„± ë° í•™ìŠµ
model = Lasso(alpha=1.0)
model.fit(X_train, y_train)
# ì˜ˆì¸¡
y_pred = model.predict(X_test)
# ëª¨ë¸ í‰ê°€
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
print(f'Mean Squared Error: {mse}')
print(f'R^2 Score: {r2}')
â€‹Copyright â“’ TeamSparta All rights reserved.