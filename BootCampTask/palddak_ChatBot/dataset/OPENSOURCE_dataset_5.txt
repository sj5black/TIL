<a href="https://colab.research.google.com/github/happy-jihye/gan/blob/main/1_gan.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="open in colab"/></a># 1 - generative adversarial networks(gan)- [generative adversarial networks (nips 2014)](https://arxiv.org/abs/1406.2661)> - 2021/03/12 happy-jihye> - **reference** : [eriklindernoren/pytorch-gan](https://github.com/eriklindernoren/pytorch-gan/blob/master/implementations/gan/gan.py)---*import torchimport torch.nn as nnimport numpy as np# for mnist dataimport torchvisionfrom torchvision import datasetsimport torchvision.transforms as transformsfrom torchvision.utils import save_imagefrom torch.autograd import variableimport matplotlib.pyplot as plt## preparing data### **loading mnist data**# download the minst databatch_size = 64transforms_train = transforms.compose([    transforms.resize(28),    transforms.totensor(), # data를 pytorch의 tensor형식으로 바꿉니다    transforms.normalize([0.5], [0.5]) # 픽셀값을 0 ~ 1에서 -1 ~ 1 로 바꿔줍니다.])train_dataset = datasets.mnist(root="./dataset", train=true, download=true, transform=transforms_train)# data를 batch size만큼만 가져오는 dataloader를 만듭니다.dataloader = torch.utils.data.dataloader(train_dataset, batch_size = batch_size, shuffle=true, num_workers=4)- 하나의 batch에 들어있는 mnist data를 출력해보았습니다.images, labels = next(iter(dataloader))img = torchvision.utils.make_grid(images)img = img.numpy().transpose(1,2,0)std = [0.5,0.5,0.5]mean = [0.5,0.5,0.5]img = img*std+meanprint([labels[i] for i in range(64)])plt.imshow(img)# image channels = 1img_size = 28img_shape = (channels, img_size, img_size)## build model### generator# dimensionality of the latent space# latent vector를 추출하기 위한 noise 분포의 dimension (정규분포를 따름)latent_dim = 100class generator(nn.module):    def __init__(self):        super(generator, self).__init__()        def block(input_dim, output_dim, normalize=true):            layers = [nn.linear(input_dim, output_dim)]            if normalize:                layers.append(nn.batchnorm1d(output_dim, 0.8))            layers.append(nn.leakyrelu(0.2, inplace=true))            return layers        # generater의 model은 여러개의 block을 쌓아서 만들어짐        self.model = nn.sequential(            *block(latent_dim, 128, normalize=false),            *block(128, 256),            *block(256, 512),            *block(512, 1024),            nn.linear(1024, int(np.prod(img_shape))),            nn.tanh()         )    def forward(self, z):         # z : input noise vector         img = self.model(z)        img = img.view(img.size(0), *img_shape)        return img### discriminatorclass discriminator(nn.module):    def __init__(self):        super(discriminator, self).__init__()        self.model = nn.sequential(            nn.linear(int(np.prod(img_shape)), 512),            nn.leakyrelu(0.2, inplace=true),            nn.linear(512, 256),            nn.leakyrelu(0.2, inplace=true),            nn.linear(256, 1),            nn.sigmoid(),        )    # 이미지에 대한 판별 결과를 반환    def forward(self, img):        img_flat = img.view(img.size(0), -1)        validity = self.model(img_flat)        return validity### loss function & optimizer- 손실 함수로는 binary cross entropy를, 최적화 함수로는 adam을 사용합니다.''' hyper parameter '''# learning ratelr = 0.0002# decay of first order momentum of gradientb1 = 0.5b2 = 0.999# initialize generator and discriminatorgenerator = generator()discriminator = discriminator()# loss functionadversarial_loss = nn.bceloss()# adam optimizeroptimizer_g = torch.optim.adam(generator.parameters(), lr=lr, betas=(b1, b2))optimizer_d = torch.optim.adam(discriminator.parameters(), lr=lr, betas=(b1, b2))# gpucuda = true if torch.cuda.is_available() else falseif cuda :   generator.cuda()  discriminator.cuda()  adversarial_loss.cuda()## training- gan model에서는 근사적인 추론이나 markov chains을 사용하지 않고, back-propagation만을 이용하여 gradient를 업데이트합니다.import time# number of epochs of trainingn_epochs = 200 # interval between image samplessample_interval = 2000 start_time = time.time()tensor = torch.cuda.floattensor if cuda else torch.floattensorfor epoch in range(n_epochs):    for i, (imgs, _) in enumerate(dataloader):        # adversarial ground truths        ## 실제 이미지는 1로, 가짜 이미지는 0으로 label됩니다.         real = variable(tensor(imgs.size(0), 1).fill_(1.0), requires_grad=false)        fake = variable(tensor(imgs.size(0), 1).fill_(0.0), requires_grad=false)        # configure input        real_imgs = variable(imgs.type(tensor))        # -----------------        #  train generator        # -----------------        optimizer_g.zero_grad()        # sample noise as generator input        z = variable(tensor(np.random.normal(0, 1, (imgs.shape[0], latent_dim))))        # generate a batch of images        ## random sampling한 값인 z를 생성자에 넣어 이미지를 생성합니다.        generated_imgs = generator(z)        # loss measures generator's ability to fool the discriminator        ## 생성된 이미지를 discriminator가 판별하게 한 후, loss값을 계산합니다.        g_loss = adversarial_loss(discriminator(generated_imgs), real)        # 생성자(generator) 업데이트        g_loss.backward()        optimizer_g.step()        # ---------------------        #  train discriminator        # ---------------------        optimizer_d.zero_grad()        # measure discriminator's ability to classify real from generated samples        ## 실제 이미지는 real(1)로, 가짜 이미지는 fake(0)으로 판별하도록 계산합니다.        real_loss = adversarial_loss(discriminator(real_imgs), real)        fake_loss = adversarial_loss(discriminator(generated_imgs.detach()), fake)        d_loss = (real_loss + fake_loss) / 2        # 판별자(discriminator) 업데이트        d_loss.backward()        optimizer_d.step()        done = epoch * len(dataloader) + i        if done % sample_interval == 0:            # 생성된 이미지 중에서 25개만 선택하여 5 x 5 격자 이미지에 출력            save_image(generated_imgs.data[:25], f"data{epoch}.png", nrow=5, normalize=true)    # 하나의 epoch이 끝날 때마다 로그(log) 출력    print(f"[epoch {epoch}/{n_epochs}] [d loss: {d_loss.item():.6f}] [g loss: {g_loss.item():.6f}] [elapsed time: {time.time() - start_time:.2f}s]")![](/content/data0.png)## reference- https://hyeongminlee.github.io/post/gan001_gan/