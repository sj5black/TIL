LLM이란? 강의소개!📕 LLM & RAG를 활용한 AI 서비스 만들기/📘 LLM & RAG를 활용한 AI 서비스 만들기 - 1주차/📕LLM이란? 강의소개!Made with📕LLM이란? 강의소개!수업 목표LLM이 무엇인지, 그 동작 원리에 대해 알아봅니다.LLM을 실무 프로젝트에서 어떻게 활용할 수 있는지 배웁니다.RAG, Vector DB, LangChain 등 최신 기술을 이해하고 이를 활용한 프로젝트를 진행하는 방법을 학습합니다.목차강좌 소개LLM이란?LLM 동작 원리LLM의 랜덤성과 조건성왜 LLM의 원리를 알아야 할까?LLM의 원리 요약추가적으로 알아두면 좋은 것!정리강좌 소개❗이번 강좌에서는 대형 언어 모델(LLM, Large Language Model)이 무엇인지, 그리고 그 동작 원리가 어떻게 되는지를 간단하게 배웁니다. 이를 통해 LLM을 활용한 다양한 프로젝트에서 효과적으로 활용할 수 있는 기초 개념을 다질 거예요.기대 효과LLM의 기본 개념을 이해하고 설명할 수 있다.LLM의 동작 방식을 알고, 관련된 기술적 요소들을 학습할 준비가 된다.RAG, Vector DB, LangChain 같은 최신 기술 트렌드에 대한 이해도를 높인다.최신 기술을 활용한 자신만의 Chat Service를 만들 수 있다!대상 수강생최신 AI에 관심 있는 사람들LLM을 프로젝트에 도입하고 싶은 사람!언어형 모델의 실제 동작 원리가 궁금한 분들RAG, LangChain과 같은 최신 기술을 배우고 싶은 분들LLM이란?📚LLMLLM(Large Language Model)은 대규모 텍스트 데이터를 학습하여 자연어를 이해하고 생성할 수 있는 AI 모델입니다. 기본적으로 자연어 처리(NLP)의 다양한 작업, 예를 들면 번역, 질문 응답, 텍스트 생성 등을 할 수 있습니다.간단한 정의대형 언어 모델(LLM)은 수십억 개의 파라미터를 기반으로 한 인공지능입니다. 이를 통해, 마치 사람처럼 문맥을 파악하고 자연스럽게 대답할 수 있는 능력을 갖췄습니다.LLM 동작 원리📢LLM의 동작은 크게 세 가지 단계로 나뉩니다.1️⃣학습(Training)LLM은 대규모 텍스트 데이터셋을 이용해 학습합니다.여기서 중요한 개념은 "패턴 인식"이에요. 수많은 텍스트에서 단어와 문장의 패턴을 찾아내어, 새로운 문장이나 답변을 생성할 때 그 패턴을 적용하죠.2️⃣추론(Inference)학습된 LLM은 질문이나 입력을 받으면, 그에 맞는 추론을 통해 답변을 생성합니다.이때, 이전의 맥락을 기억하고 활용하면서 답을 만들어내죠.3️⃣미세 조정(Fine-tuning)LLM은 특정 도메인이나 용도에 맞춰 추가 학습(미세 조정)할 수 있습니다.예를 들어, 의료나 법률과 같은 특수한 분야에 맞는 데이터를 추가로 학습시키면 해당 분야에 대한 답변의 정확성이 높아집니다.LLM을 개인이 바닥부터 만들기란..?LLM의 랜덤성과 조건성📢LLM이 문장을 생성할 때는 랜덤성(randomness)과 조건성(conditioning)이 중요한 역할을 합니다.1️⃣랜덤성 (Randomness)LLM은 기본적으로 확률에 기반하여 문장을 생성합니다.즉, 같은 질문을 하더라도 매번 동일한 답변을 주지 않을 수 있어요.이 랜덤성은 모델이 새로운 문장을 만들어내는 능력을 키워주는 핵심 요소입니다.LLM이 결과를 생성할 때, 토큰의 확률 분포를 계산하여 그 중에서 높은 확률을 가진 토큰을 선택해 문장을 만듭니다. 이때 "온도(temperature)"라는 매개변수가 랜덤성에 영향을 미치는데,온도 값이 낮으면: 모델은 더 일관되고 예측 가능한 답변을 생성합니다. (더 적은 랜덤성)온도 값이 높으면: 답변이 창의적이고 예측하기 어려운 결과가 나올 수 있습니다. (더 많은 랜덤성)✔️ 예시질문: "오늘 날씨는 어때?"온도 낮음: "오늘 날씨는 맑습니다."온도 높음: "오늘은 하늘이 쾌청하고, 약간의 바람이 불어요."2️⃣조건성 (Conditioning)LLM은 조건부 확률을 기반으로 결과를 만들어 냅니다.즉, 모델은 이전의 입력 내용에 따라 문장을 조건부로 생성하게 되는데, 이를 컨텍스트라고도 합니다.이 과정에서 중요한 두 가지 요소는 다음과 같습니다:프롬프트: 입력된 문장이나 질문이 무엇인지에 따라 결과가 달라집니다.맥락 기억: LLM은 대화를 나누는 동안 이전 문장이나 대화 흐름을 기억하고 그에 맞춰 답변을 생성합니다.✔️ 예시프롬프트에 따른 차이: "고양이에 대해 말해줘." → "고양이는 애완동물로서 인기가 많습니다.""고양이의 장점에 대해 말해줘." → "고양이는 혼자서도 잘 지내는 동물이어서 바쁜 사람들에게 적합합니다."왜 LLM의 원리를 알아야 할까?LLM을 단순히 사용하기만 해도 좋지만, 그 동작 원리를 이해하면 더 효율적으로 사용할 수 있습니다.정확한 프롬프트를 작성할 수 있게 되어, 원하는 답변을 더 쉽게 얻을 수 있죠.LLM의 한계를 알면, 적절한 상황에서 더 나은 도구를 선택할 수 있어요.성능 개선을 위한 기술 요소들(RAG, LangChain 등)을 효과적으로 도입할 수 있습니다.LLM의 원리 요약1️⃣대규모 데이터 학습많은 데이터를 바탕으로 언어 패턴을 학습.2️⃣문맥 기반 추론입력된 텍스트의 맥락을 파악해 가장 적절한 답변을 생성.