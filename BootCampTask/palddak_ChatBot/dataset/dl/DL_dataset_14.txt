[ìŠ¤íŒŒë¥´íƒ€ì½”ë”©í´ëŸ½] 14. ê³¼ì í•© ë°©ì§€ ê¸°ë²•ğŸ“˜[SCC] ê¸°ì´ˆê°€ íƒ„íƒ„í•œ ë”¥ëŸ¬ë‹/ğŸ“š[ìŠ¤íŒŒë¥´íƒ€ì½”ë”©í´ëŸ½] ê¸°ì´ˆê°€ íƒ„íƒ„í•œ ë”¥ëŸ¬ë‹ - 6ì£¼ì°¨/ğŸ“•[ìŠ¤íŒŒë¥´íƒ€ì½”ë”©í´ëŸ½] 14. ê³¼ì í•© ë°©ì§€ ê¸°ë²•Made withğŸ“•[ìŠ¤íŒŒë¥´íƒ€ì½”ë”©í´ëŸ½] 14. ê³¼ì í•© ë°©ì§€ ê¸°ë²•[ìˆ˜ì—… ëª©í‘œ]ì—¬ëŸ¬ ê³¼ì í•© ë°©ì§€ ê¸°ë²•ì— ëŒ€í•´ì„œ ì•Œì•„ë´…ì‹œë‹¤.Pytorchë¡œ  ê³¼ì í•© ë°©ì§€ ê¸°ë²•ì— ëŒ€í•œ ì‹¤ìŠµ ì˜ˆì‹œ![ëª©ì°¨]01. ê³¼ì í™” ë°©ì§€ ê¸°ë²•02. ê³¼ì í•© ë°©ì§€ê¸°ë²• ì‹¤ìŠµ(Pytorch)import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
â€‹â˜‘ï¸ë°ì´í„°ì…‹ ë¡œë“œ ë° ì „ì²˜ë¦¬ë°ì´í„°ì…‹ ë¡œë“œ ë° ì „ì²˜ë¦¬ {5px}ë°ì´í„°ì…‹ ë¡œë“œ ë° ì „ì²˜ë¦¬ ï»¿â€‹PythonCopy# ë°ì´í„°ì…‹ ì „ì²˜ë¦¬
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])
# CIFAR-10 ë°ì´í„°ì…‹ ë¡œë“œ
trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)

testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)
testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)
â€‹â˜‘ï¸  ë“œë¡­ì•„ì›ƒê³¼ ë°°ì¹˜ ì •ê·œí™”ë¥¼ ì ìš©í•œ ëª¨ë¸ ì •ì˜ ë“œë¡­ì•„ì›ƒê³¼ ë°°ì¹˜ ì •ê·œí™”ë¥¼ ì ìš©í•œ ëª¨ë¸ ì •ì˜ {5px} ë“œë¡­ì•„ì›ƒê³¼ ë°°ì¹˜ ì •ê·œí™”ë¥¼ ì ìš©í•œ ëª¨ë¸ ì •ì˜ ï»¿â€‹PythonCopyclass CNNWithDropoutAndBatchNorm(nn.Module):
def __init__(self):
super(CNNWithDropoutAndBatchNorm, self).__init__()
        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)
        self.bn1 = nn.BatchNorm2d(64)
        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)
        self.bn2 = nn.BatchNorm2d(128)
        self.fc1 = nn.Linear(128 * 56 * 56, 256)
        self.dropout = nn.Dropout(0.5)
        self.fc2 = nn.Linear(256, 10)
def forward(self, x):
        x = torch.relu(self.bn1(self.conv1(x)))
        x = torch.max_pool2d(x, 2)
        x = torch.relu(self.bn2(self.conv2(x)))
        x = torch.max_pool2d(x, 2)
        x = x.view(x.size(0), -1)
        x = torch.relu(self.fc1(x))
        x = self.dropout(x)
        x = self.fc2(x)
return x

model = CNNWithDropoutAndBatchNorm()
â€‹nn.Conv2d: 2ì°¨ì› í•©ì„±ê³± ì¸µì„ ì •ì˜í•©ë‹ˆë‹¤. nn.Conv2d(in_channels, out_channels, kernel_size, padding)ì€ ì…ë ¥ ì±„ë„ ìˆ˜, ì¶œë ¥ ì±„ë„ ìˆ˜, ì»¤ë„ í¬ê¸°, íŒ¨ë”©ì„ ì§€ì •.Conv2d(in_channels, out_channels, kernel_size, padding)ì€ ì…ë ¥ ì±„ë„ ìˆ˜, ì¶œë ¥ ì±„ë„ ìˆ˜, ì»¤ë„ í¬ê¸°, íŒ¨ë”©ì„ ì§€ì •ï»¿â€‹nn.BatchNorm2d: 2ì°¨ì› ë°°ì¹˜ ì •ê·œí™” ì¸µì„ ì •ì˜í•©ë‹ˆë‹¤.nn.Dropout: ë“œë¡­ì•„ì›ƒ ì¸µì„ ì •ì˜í•©ë‹ˆë‹¤. nn.Dropout(p)ì€ ë“œë¡­ì•„ì›ƒ í™•ë¥ ì„ ì§€ì •í•©ë‹ˆë‹¤..Dropout(p)ì€ ë“œë¡­ì•„ì›ƒ í™•ë¥ ì„ ì§€ì •í•©ë‹ˆë‹¤.ï»¿â€‹torch.max_pool2d: 2ì°¨ì› ìµœëŒ€ í’€ë§ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.â˜‘ï¸ ì†ì‹¤ í•¨ìˆ˜ì™€ ìµœì í™” ì•Œê³ ë¦¬ì¦˜ ì •ì˜ì†ì‹¤ í•¨ìˆ˜ì™€ ìµœì í™” ì•Œê³ ë¦¬ì¦˜ ì •ì˜ {5px}ì†ì‹¤ í•¨ìˆ˜ì™€ ìµœì í™” ì•Œê³ ë¦¬ì¦˜ ì •ì˜ ï»¿â€‹PythonCopycriterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)
â€‹nn.CrossEntropyLoss: êµì°¨ ì—”íŠ¸ë¡œí”¼ ì†ì‹¤ í•¨ìˆ˜ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.optim.Adam: Adam ìµœì í™” ì•Œê³ ë¦¬ì¦˜ì„ ì •ì˜í•©ë‹ˆë‹¤. lrì€ í•™ìŠµë¥ ì„ ì§€ì •í•©ë‹ˆë‹¤.ì€ í•™ìŠµë¥ ì„ ì§€ì •í•©ë‹ˆë‹¤.ï»¿â€‹â˜‘ï¸ ëª¨ë¸ í•™ìŠµëª¨ë¸ í•™ìŠµ {5px}ëª¨ë¸ í•™ìŠµ ï»¿â€‹PythonCopynum_epochs = 10
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = model.to(device)
for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0
for i, (inputs, labels) in enumerate(trainloader):
        inputs, labels = inputs.to(device), labels.to(device)

        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()
if i % 100 == 99: # ë§¤ 100 ë¯¸ë‹ˆë°°ì¹˜ë§ˆë‹¤ ì¶œë ¥
print(f'[Epoch {epoch + 1}, Batch {i + 1}] loss: {running_loss / 100:.3f}')
            running_loss = 0.0
print('Finished Training')
â€‹model.train(): ëª¨ë¸ì„ í•™ìŠµ ëª¨ë“œë¡œ ì „í™˜í•©ë‹ˆë‹¤.optimizer.zero_grad(): ì´ì „ ë‹¨ê³„ì—ì„œ ê³„ì‚°ëœ ê¸°ìš¸ê¸°ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.loss.backward(): ì—­ì „íŒŒë¥¼ í†µí•´ ê¸°ìš¸ê¸°ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.optimizer.step(): ê³„ì‚°ëœ ê¸°ìš¸ê¸°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê°€ì¤‘ì¹˜ë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.â˜‘ï¸ ëª¨ë¸ í‰ê°€ëª¨ë¸ í‰ê°€ {5px}ëª¨ë¸ í‰ê°€ ï»¿â€‹PythonCopymodel.eval()
correct = 0
total = 0
with torch.no_grad():
for inputs, labels in testloader:
        inputs, labels = inputs.to(device), labels.to(device)
        outputs = model(inputs)
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()
print(f'Accuracy of the network on the 10000 test images: {100 * correct / total:.2f}%')
â€‹model.eval(): ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì „í™˜í•©ë‹ˆë‹¤.torch.no_grad(): í‰ê°€ ë‹¨ê³„ì—ì„œëŠ” ê¸°ìš¸ê¸°ë¥¼ ê³„ì‚°í•  í•„ìš”ê°€ ì—†ìœ¼ë¯€ë¡œ, ì´ë¥¼ ë¹„í™œì„±í™”í•˜ì—¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ì„ ì¤„ì…ë‹ˆë‹¤.torch.max: í…ì„œì˜ ìµœëŒ€ ê°’ì„ ì°¾ìŠµë‹ˆë‹¤. torch.max(outputs.data, 1)ì€ ê° ìƒ˜í”Œì— ëŒ€í•´ ê°€ì¥ ë†’ì€ í™•ë¥ ì„ ê°€ì§„ í´ë˜ìŠ¤ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤..max(outputs.data, 1)ì€ ê° ìƒ˜í”Œì— ëŒ€í•´ ê°€ì¥ ë†’ì€ í™•ë¥ ì„ ê°€ì§„ í´ë˜ìŠ¤ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.ï»¿â€‹labels.size(0): ë°°ì¹˜ í¬ê¸°ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.(predicted == labels).sum().item(): ì˜ˆì¸¡ ê°’ê³¼ ì‹¤ì œ ê°’ì´ ì¼ì¹˜í•˜ëŠ” ìƒ˜í”Œì˜ ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.2)  ë°ì´í„° ì¦ê°•ì„ í†µí•œ ëª¨ë¸ ì„±ëŠ¥ í–¥ìƒ ì‹¤ìŠµâ˜‘ï¸ë°ì´í„°ì…‹ ë¡œë“œ ë° ì „ì²˜ë¦¬ë°ì´í„°ì…‹ ë¡œë“œ ë° ì „ì²˜ë¦¬ {5px}ë°ì´í„°ì…‹ ë¡œë“œ ë° ì „ì²˜ë¦¬ ï»¿â€‹PythonCopy# ë°ì´í„° ì¦ê°• ì ìš©
transform_train = transforms.Compose([
    transforms.RandomHorizontalFlip(),
    transforms.RandomCrop(32, padding=4),
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])

transform_test = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])
# CIFAR-10 ë°ì´í„°ì…‹ ë¡œë“œ
trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)

testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)
testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)
â€‹transforms.RandomHorizontalFlip(): ì´ë¯¸ì§€ë¥¼ ë¬´ì‘ìœ„ë¡œ ìˆ˜í‰ ë°˜ì „í•©ë‹ˆë‹¤.transforms.RandomCrop(size, padding): ì´ë¯¸ì§€ë¥¼ ë¬´ì‘ìœ„ë¡œ ìë¥´ê³ , íŒ¨ë”©ì„ ì¶”ê°€í•©ë‹ˆë‹¤.â˜‘ï¸  ë“œë¡­ì•„ì›ƒê³¼ ë°°ì¹˜ ì •ê·œí™”ë¥¼ ì ìš©í•œ ëª¨ë¸ ì •ì˜ì²«ë²ˆì§¸ ì‹¤ìŠµì—ì„œ ì •ì˜í•œ ëª¨ë¸ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤. ë“œë¡­ì•„ì›ƒê³¼ ë°°ì¹˜ ì •ê·œí™”ë¥¼ ì ìš©í•œ ëª¨ë¸ ì •ì˜ {5px} ë“œë¡­ì•„ì›ƒê³¼ ë°°ì¹˜ ì •ê·œí™”ë¥¼ ì ìš©í•œ ëª¨ë¸ ì •ì˜ ï»¿â€‹PythonCopyclass CNNWithDropoutAndBatchNorm(nn.Module):
def __init__(self):
super(CNNWithDropoutAndBatchNorm, self).__init__()
        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)
        self.bn1 = nn.BatchNorm2d(64)
        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)
        self.bn2 = nn.BatchNorm2d(128)
        self.fc1 = nn.Linear(128 * 56 * 56, 256)
        self.dropout = nn.Dropout(0.5)
        self.fc2 = nn.Linear(256, 10)
def forward(self, x):
        x = torch.relu(self.bn1(self.conv1(x)))
        x = torch.max_pool2d(x, 2)
        x = torch.relu(self.bn2(self.conv2(x)))
        x = torch.max_pool2d(x, 2)
        x = x.view(x.size(0), -1)
        x = torch.relu(self.fc1(x))
        x = self.dropout(x)
        x = self.fc2(x)
return x

model = CNNWithDropoutAndBatchNorm()
â€‹â˜‘ï¸ ì†ì‹¤ í•¨ìˆ˜ì™€ ìµœì í™” ì•Œê³ ë¦¬ì¦˜ ì •ì˜ì²«ë²ˆì§¸ ì‹¤ìŠµì—ì„œ ì •ì˜í•œ ì†ì‹¤í•¨ìˆ˜ì™€ ìµœì í™” ì•Œê³ ë¦¬ì¦˜ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.ì†ì‹¤ í•¨ìˆ˜ì™€ ìµœì í™” ì•Œê³ ë¦¬ì¦˜ ì •ì˜ {5px}ì†ì‹¤ í•¨ìˆ˜ì™€ ìµœì í™” ì•Œê³ ë¦¬ì¦˜ ì •ì˜ ï»¿â€‹PythonCopycriterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)
â€‹â˜‘ï¸ ëª¨ë¸ í•™ìŠµì²«ë²ˆì§¸ ì‹¤ìŠµì—ì„œ ì •ì˜í•œ ëª¨ë¸ í•™ìŠµ ì½”ë“œë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.ëª¨ë¸ í•™ìŠµ {5px}ëª¨ë¸ í•™ìŠµ ï»¿â€‹PythonCopynum_epochs = 10
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = model.to(device)
for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0
for i, (inputs, labels) in enumerate(trainloader):
        inputs, labels = inputs.to(device), labels.to(device)

        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()
if i % 100 == 99: # ë§¤ 100 ë¯¸ë‹ˆë°°ì¹˜ë§ˆë‹¤ ì¶œë ¥
print(f'[Epoch {epoch + 1}, Batch {i + 1}] loss: {running_loss / 100:.3f}')
            running_loss = 0.0
print('Finished Training')
â€‹â˜‘ï¸ ëª¨ë¸ í‰ê°€ì²«ë²ˆì§¸ ì‹¤ìŠµì—ì„œ ì •ì˜í•œ ëª¨ë¸ í‰ê°€ ì½”ë“œë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.ëª¨ë¸ í‰ê°€ {5px}ëª¨ë¸ í‰ê°€ ï»¿â€‹PythonCopymodel.eval()
correct = 0
total = 0
with torch.no_grad():
for inputs, labels in testloader:
        inputs, labels = inputs.to(device), labels.to(device)
        outputs = model(inputs)
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()
print(f'Accuracy of the network on the 10000 test images: {100 * correct / total:.2f}%')
â€‹Copyright â“’ TeamSparta All rights reserved.