[스파르타코딩클럽] 15. 하이퍼파라미터 튜닝📘[SCC] 기초가 탄탄한 딥러닝/📚[스파르타코딩클럽] 기초가 탄탄한 딥러닝 - 6주차/📕[스파르타코딩클럽] 15. 하이퍼파라미터 튜닝Made with📕[스파르타코딩클럽] 15. 하이퍼파라미터 튜닝[수업 목표]주요 하이퍼파라미터 종류와 자동화 튜닝방법에 대해 배워봅시다[목차]01. 하이퍼파라미터 튜닝 방법💡모든 토글을 열고 닫는 단축키
Windows : Ctrl + alt + t 
Mac : ⌘ + ⌥ + t 01. 하이퍼파라미터 튜닝 방법✔️하이퍼파라미터란 무엇인지, 주요 하이퍼파라미터엔 어떤것들이 있는지 알아보고, 자동 튜닝기법에 대해 배워봅시다.1) 주요 하이퍼파라미터와 튜닝 방법☑️ 하이퍼파라미터란?하이퍼파라미터는 모델 학습 과정에서 사용자가 설정해야 하는 값으로, 모델의 성능에 큰 영향을 미칩니다.ALT☑️ 학습률 (Learning Rate)학습률은 모델의 가중치를 업데이트하는 속도를 결정합니다.너무 크면 학습이 불안정해지고, 너무 작으면 학습이 느려집니다.일반적으로 0.1, 0.01, 0.001 등의 값을 시도해볼 수 있습니다.☑️ 배치 크기 (Batch Size)배치 크기는 한 번의 업데이트에 사용되는 데이터 샘플의 수를 결정합니다.큰 배치 크기는 학습 속도를 높이지만, 메모리 사용량이 증가합니다.일반적으로 32, 64, 128 등의 값을 시도해볼 수 있습니다.☑️ 에포크 수 (Number of Epochs)에포크 수는 전체 데이터셋을 몇 번 반복하여 학습할지를 결정합니다.너무 적으면 과소적합이 발생하고, 너무 많으면 과적합이 발생할 수 있습니다.조기 종료(Early Stopping) 기법을 사용하여 적절한 에포크 수를 결정할 수 있습니다.☑️ 모멘텀 (Momentum)모멘텀은 이전 기울기를 현재 기울기에 반영하여, 학습 속도를 높이고 진동을 줄입니다.일반적으로 0.9, 0.99 등의 값을 시도해볼 수 있습니다.☑️ 가중치 초기화 (Weight Initialization)가중치 초기화는 모델의 가중치를 초기화하는 방법을 결정합니다.일반적으로 Xavier 초기화, He 초기화 등을 사용합니다.2) 하이퍼파라미터 자동 튜닝 기법☑️ Grid Search하이퍼파라미터의 모든 조합을 시도하여 최적의 값을 찾습니다.계산 비용이 많이 들지만, 모든 조합을 탐색할 수 있습니다.☑️ Random Search하이퍼파라미터 공간에서 무작위로 값을 선택하여 최적의 값을 찾습니다.Grid Search보다 계산 비용이 적고, 더 넓은 하이퍼파라미터 공간을 탐색할 수 있습니다.☑️ Bayesian Optimization베이지안 최적화는 이전 평가 결과를 바탕으로, 다음 평가할 하이퍼파라미터를 선택합니다.계산 비용이 적고, 효율적으로 최적의 값을 찾을 수 있습니다.Copyright ⓒ TeamSparta All rights reserved.