Vector DB 개념 및 RAG (Retrieval-Augmented Generation) 개념📕 LLM & RAG를 활용한 AI 서비스 만들기/📘 LLM & RAG를 활용한 AI 서비스 만들기 - 5주차/📕Vector DB 개념 및 RAG (Retrieval-Augmented Generation) 개념Made with📕Vector DB 개념 및 RAG (Retrieval-Augmented Generation) 개념수업 목표vectorDB와 RAG의 개념에 대해서 학습하고, 한국어 임베딩 실습을 진행합니다.목차Vector DB 개념 Vector DB란?Faiss란?임베딩(Embedding) 개념 임베딩이란?RAG (Retrieval-Augmented Generation) 개념RAG의 동작 원리Retrieval (검색) 단계Generation (생성) 단계RAG의 장점Vector DB와 RAG의 결합동작 흐름한국어 임베딩 실습한국어 데이터 임베딩Vector DB와 RAG로 LLM 시스템 구축하기Vector DB 개념 Vector DB란?❗Vector DB는 데이터를 벡터 형식으로 저장하고, 그 벡터들을 효율적으로 검색할 수 있는 데이터베이스에요. 일반적인 데이터베이스는 정확한 일치를 바탕으로 데이터를 검색하지만, Vector DB는 유사한 벡터 간의 검색을 지원하죠.벡터(임베딩)의 역할텍스트나 이미지 등의 비정형 데이터를 벡터화(임베딩)해서 저장해요.
이 벡터는 데이터의 의미나 특징을 수치로 표현한 것이며, 이를 바탕으로 유사도를 계산해 관련성이 높은 항목을 찾습니다.예를 들어, "강아지"라는 텍스트는 벡터로 변환되며, 비슷한 의미를 가진 "반려견"도 벡터화되어 유사도가 높은 항목으로 검색될 수 있어요.Faiss란?💡Faiss는 Facebook AI Research에서 개발한 벡터 검색 엔진으로, Vector DB를 구현할 때 자주 사용돼요. 대규모 벡터를 효율적으로 검색하고, 유사도를 계산하는 데 탁월한 성능을 발휘합니다. 특히 빠른 속도와 확장성이 필요한 애플리케이션에서 많이 쓰이죠.임베딩(Embedding) 개념 임베딩이란?💡임베딩은 텍스트, 이미지 등의 데이터를 고차원 공간에서 벡터(숫자 배열)로 변환하는 작업이에요. LLM(대규모 언어 모델)이 문장을 이해하기 위해서는 단어와 문장을 벡터로 변환해야, 컴퓨터가 의미적 유사성을 기반으로 데이터를 처리할 수 있습니다.임베딩의 작동 방식임베딩은 단어 간의 의미적 관계를 벡터 공간에 투영해요.
예를 들어, "고양이"와 "개"는 비슷한 의미를 가지므로 벡터 공간에서도 서로 가까운 위치에 존재하게 됩니다. 
반대로 "사과"와 "자동차"처럼 전혀 다른 의미를 가진 단어들은 벡터 공간에서 멀리 떨어진 위치에 놓이게 되죠.RAG (Retrieval-Augmented Generation) 개념❗RAG는 Retrieval-Augmented Generation의 약자로, 
LLM(대규모 언어 모델)과 검색 시스템을 결합한 개념이에요.
RAG는 기존의 LLM만으로는 해결할 수 없는 문제를, 외부 정보 검색을 통해 보완할 수 있어요. 
최신 정보를 포함한 답변을 제공하는 데 매우 유리하죠.RAG의 동작 원리1️⃣Retrieval (검색) 단계사용자가 질문을 하면, 벡터 DB에서 질문과 유사한 문서나 데이터를 검색해요. 이때 임베딩 모델을 사용해 질문을 벡터로 변환하고, 벡터 간의 유사도를 계산해 관련 데이터를 찾아냅니다.2️⃣Generation (생성) 단계검색된 문서를 LLM에 전달하고, 이를 바탕으로 자연스러운 답변을 생성합니다. 검색된 문서를 참조해 최신 정보를 포함한 정확한 답변을 제공하죠.RAG의 장점최신 정보 제공: LLM이 학습한 데이터 외의 최신 문서를 검색해 정보의 정확도를 높일 수 있어요.유연성: LLM이 모르는 정보도 외부 검색을 통해 답변할 수 있어 지식의 확장성이 뛰어납니다.지식의 한계 극복: 학습 데이터에만 의존하지 않고, 외부 데이터베이스에서 실시간 정보를 제공받아 더욱 풍부한 답변을 할 수 있어요.Vector DB와 RAG의 결합💡Vector DB와 RAG의 결합은 매우 강력해요. Vector DB는 유사한 문서를 검색해주고, RAG는 검색된 문서를 바탕으로 정확한 답변을 생성하는 과정이죠.동작 흐름ALT한국어 임베딩 실습한국어 데이터 임베딩한국어 문장을 임베딩하려면 사전 학습된 한국어 임베딩 모델이 필요해요. [코드스니펫] 한국어 임베딩 실습 코드PythonCopyfrom sentence_transformers import SentenceTransformer
import numpy as np

# Multilingual-E5-large-instruct 모델 로드
model = SentenceTransformer('intfloat/multilingual-e5-large')
# 문장 리스트
sentences = [
"참새는 짹짹하고 웁니다.",
"LangChain과 Faiss를 활용한 예시입니다.",
"자연어 처리를 위한 임베딩 모델 사용법을 배워봅시다.",
"유사한 문장을 검색하는 방법을 살펴보겠습니다.",
"강좌를 수강하시는 수강생 여러분 감사합니다!"
]
# 문장들을 임베딩으로 변환
embeddings = model.encode(sentences)
# 임베딩 벡터 출력
print(embeddings.shape) # (4, 1024) - 4개의 문장이 1024 차원의 벡터로 변환됨
​PythonCopyfrom sentence_transformers import SentenceTransformer
import numpy as np

# Multilingual-E5-large-instruct 모델 로드
model = SentenceTransformer('intfloat/multilingual-e5-large')
# 문장 리스트
sentences = [
"참새는 짹짹하고 웁니다.",
"LangChain과 Faiss를 활용한 예시입니다.",
"자연어 처리를 위한 임베딩 모델 사용법을 배워봅시다.",
"유사한 문장을 검색하는 방법을 살펴보겠습니다.",
"강좌를 수강하시는 수강생 여러분 감사합니다!"
]
# 문장들을 임베딩으로 변환
embeddings = model.encode(sentences)
# 임베딩 벡터 출력
print(embeddings.shape) # (4, 1024) - 4개의 문장이 1024 차원의 벡터로 변환됨
​Vector DB와 RAG로 LLM 시스템 구축하기1️⃣질문을 임베딩
사용자의 질문을 벡터로 변환합니다.2️⃣벡터 DB에서 검색
벡터 DB에서 질문과 관련된 문서를 검색합니다.3️⃣검색된 문서를 기반으로 LLM이 답변 생성
검색된 문서를 LLM에 전달하고, 답변을 생성합니다.😀이러한 과정을 통해 RAG와 Vector DB는 최신 정보 기반의 대화형 AI 시스템을 구축하는 데 매우 유용해요!
Vector DB와 RAG 개념을 기반으로 LLM 시스템을 구축할 때, 더 나은 정보 검색과 답변 생성을 할 수 있습니다.