[ìŠ¤íŒŒë¥´íƒ€ì½”ë”©í´ëŸ½] 9. ResNetğŸ“˜[SCC] ê¸°ì´ˆê°€ íƒ„íƒ„í•œ ë”¥ëŸ¬ë‹/ğŸ“š[ìŠ¤íŒŒë¥´íƒ€ì½”ë”©í´ëŸ½] ê¸°ì´ˆê°€ íƒ„íƒ„í•œ ë”¥ëŸ¬ë‹ - 4ì£¼ì°¨/ğŸ“•[ìŠ¤íŒŒë¥´íƒ€ì½”ë”©í´ëŸ½] 9. ResNetMade withğŸ“•[ìŠ¤íŒŒë¥´íƒ€ì½”ë”©í´ëŸ½] 9. ResNet[ìˆ˜ì—… ëª©í‘œ]ë¹„ì „ ëª¨ë¸ì˜ ê¸¸ì„ ì—´ì–´ì¤€ ResNet!ì™œ ì¢‹ì€ ì§€ í•œë²ˆ ì•Œì•„ë´…ì‹œë‹¤[ëª©ì°¨]01. ê°œë…import torch.nn as nn
import torch.nn.functional as F

class Block(nn.Module):
def __init__(self, in_ch, out_ch, stride=1):
super(Block, self).__init__()
# ì²« ë²ˆì§¸ ì»¨ë³¼ë£¨ì…˜ ë ˆì´ì–´
        self.conv1 = nn.Conv2d(in_ch, out_ch, kernel_size=3, stride=stride, padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(out_ch) # ë°°ì¹˜ ì •ê·œí™”
# ë‘ ë²ˆì§¸ ì»¨ë³¼ë£¨ì…˜ ë ˆì´ì–´
        self.conv2 = nn.Conv2d(out_ch, out_ch, kernel_size=3, stride=1, padding=1, bias=False)
        self.bn2 = nn.BatchNorm2d(out_ch) # ë°°ì¹˜ ì •ê·œí™”
# ì…ë ¥ê³¼ ì¶œë ¥ì˜ ì°¨ì›ì´ ë‹¤ë¥¼ ê²½ìš° shortcut ê²½ë¡œ ì •ì˜
        self.skip_connection = nn.Sequential()
if stride != 1 or in_ch != out_ch:
            self.skip_connection = nn.Sequential(
                nn.Conv2d(in_ch, out_ch, kernel_size=1, stride=stride, bias=False), # ì°¨ì› ë§ì¶”ê¸° ìœ„í•œ 1x1 ì»¨ë³¼ë£¨ì…˜
                nn.BatchNorm2d(out_ch) # ë°°ì¹˜ ì •ê·œí™”
)
def forward(self, x):
# ì²« ë²ˆì§¸ ì»¨ë³¼ë£¨ì…˜ + ReLU í™œì„±í™” í•¨ìˆ˜
        output = F.relu(self.bn1(self.conv1(x)))
# ë‘ ë²ˆì§¸ ì»¨ë³¼ë£¨ì…˜ í›„ ë°°ì¹˜ ì •ê·œí™”
        output = self.bn2(self.conv2(output))
# shortcut ê²½ë¡œ ì¶œë ¥ê³¼ í˜„ì¬ ë¸”ë¡ì˜ ì¶œë ¥ ë”í•˜ê¸°
        output += self.skip_connection(x)
# ìµœì¢… ReLU í™œì„±í™” í•¨ìˆ˜ ì ìš©
        output = F.relu(output)
return output

# ResNet ëª¨ë¸ ì •ì˜
class CustomResNet(nn.Module):
def __init__(self, block, layers, num_classes=10):
super(CustomResNet, self).__init__()
        self.initial_channels = 64 # ì²« ë²ˆì§¸ ë ˆì´ì–´ì˜ ì…ë ¥ ì±„ë„ ìˆ˜ ì •ì˜
# ì²« ë²ˆì§¸ ì»¨ë³¼ë£¨ì…˜ ë ˆì´ì–´
        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(64) # ë°°ì¹˜ ì •ê·œí™”
# ResNetì˜ ê° ë ˆì´ì–´ ìƒì„±
        self.layer1 = self._create_layer(block, 64, layers[0], stride=1)
        self.layer2 = self._create_layer(block, 128, layers[1], stride=2)
        self.layer3 = self._create_layer(block, 256, layers[2], stride=2)
        self.layer4 = self._create_layer(block, 512, layers[3], stride=2)
# í‰ê·  í’€ë§ ë ˆì´ì–´
        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
# ìµœì¢… ì™„ì „ ì—°ê²° ë ˆì´ì–´
        self.fc = nn.Linear(512, num_classes)
# ResNetì˜ ê° ë ˆì´ì–´ë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜
def _create_layer(self, block, out_ch, num_layers, stride):
        layer_list = []
# ì²« ë²ˆì§¸ ë¸”ë¡ì€ strideë¥¼ ë°›ì„ ìˆ˜ ìˆìŒ
        layer_list.append(block(self.initial_channels, out_ch, stride))
        self.initial_channels = out_ch  # ë‹¤ìŒ ë¸”ë¡ì„ ìœ„í•´ ì±„ë„ ìˆ˜ ì—…ë°ì´íŠ¸
# ë‚˜ë¨¸ì§€ ë¸”ë¡ë“¤ì€ ê¸°ë³¸ strideë¥¼ ì‚¬ìš©
for _ in range(1, num_layers):
            layer_list.append(block(out_ch, out_ch))
return nn.Sequential(*layer_list)
def forward(self, x):
# ì²« ë²ˆì§¸ ì»¨ë³¼ë£¨ì…˜ + ReLU í™œì„±í™” í•¨ìˆ˜
        x = F.relu(self.bn1(self.conv1(x)))
# ê° ë ˆì´ì–´ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ í†µê³¼
        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)
        x = self.layer4(x)
# í‰ê·  í’€ë§ ë° í…ì„œì˜ ì°¨ì› ì¶•ì†Œ
        x = self.avgpool(x)
        x = torch.flatten(x, 1)
# ìµœì¢… ì™„ì „ ì—°ê²° ë ˆì´ì–´ë¥¼ í†µí•´ í´ë˜ìŠ¤ë³„ ì˜ˆì¸¡ê°’ ì¶œë ¥
        x = self.fc(x)
return x

# Custom ResNet-18 ëª¨ë¸ ìƒì„± (ê° ë ˆì´ì–´ì˜ ë¸”ë¡ ìˆ˜ëŠ” 2ê°œì”©)
model = CustomResNet(Block, [2, 2, 2, 2], num_classes=10)

â€‹Copyright â“’ TeamSparta All rights reserved.