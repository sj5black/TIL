[ìŠ¤íŒŒë¥´íƒ€ì½”ë”©í´ëŸ½] 6. ìˆœí™˜ ì‹ ê²½ë§(RNN)ğŸ“˜[SCC] ê¸°ì´ˆê°€ íƒ„íƒ„í•œ ë”¥ëŸ¬ë‹/ğŸ“š[ìŠ¤íŒŒë¥´íƒ€ì½”ë”©í´ëŸ½] ê¸°ì´ˆê°€ íƒ„íƒ„í•œ ë”¥ëŸ¬ë‹ - 2ì£¼ì°¨/ğŸ“•[ìŠ¤íŒŒë¥´íƒ€ì½”ë”©í´ëŸ½] 6. ìˆœí™˜ ì‹ ê²½ë§(RNN)Made withğŸ“•[ìŠ¤íŒŒë¥´íƒ€ì½”ë”©í´ëŸ½] 6. ìˆœí™˜ ì‹ ê²½ë§(RNN)[ìˆ˜ì—… ëª©í‘œ]ìˆœí™˜ ì‹ ê²½ë§(RNN) ê°œë…ì— ëŒ€í•´ì„œ ë°°ì›Œë³´ê³  ì–´ë–¤ ì›ë¦¬ë¡œ ë™ì‘í•˜ëŠ”ì§€ ì•Œì•„ë´…ì‹œë‹¤Pytorchë¡œ ê°„ë‹¨í•œ RNN ëª¨ë¸ êµ¬í˜„ ì‹¤ìŠµì„ ì§„í–‰í•´ ë´…ì‹œë‹¤[ëª©ì°¨]01. RNNì˜ ê¸°ë³¸ êµ¬ì¡°ì™€ ë™ì‘ ì›ë¦¬02. RNNê³¼ LSTMì„ ì´ìš©í•œ ì‹œê³„ì—´ ë°ì´í„° ì˜ˆì¸¡ (PyTorch)import torch.nn as nn
import torch.optim as optim
import numpy as np
import matplotlib.pyplot as plt
â€‹â˜‘ï¸ë°ì´í„°ì…‹ ìƒì„± ë° ì „ì²˜ë¦¬ë°ì´í„°ì…‹ ìƒì„± ë° ì „ì²˜ë¦¬ {5px}ë°ì´í„°ì…‹ ìƒì„± ë° ì „ì²˜ë¦¬ ï»¿â€‹PythonCopy# Sine íŒŒí˜• ë°ì´í„° ìƒì„±
def create_sine_wave_data(seq_length, num_samples):
    X = []
    y = []
for _ in range(num_samples):
        start = np.random.rand()
        x = np.linspace(start, start + 2 * np.pi, seq_length)
        X.append(np.sin(x))
        y.append(np.sin(x + 0.1))
return np.array(X), np.array(y)

seq_length = 50
num_samples = 1000
X, y = create_sine_wave_data(seq_length, num_samples)
# ë°ì´í„°ì…‹ì„ PyTorch í…ì„œë¡œ ë³€í™˜
X = torch.tensor(X, dtype=torch.float32).unsqueeze(-1)
y = torch.tensor(y, dtype=torch.float32).unsqueeze(-1)
â€‹â˜‘ï¸ ê°„ë‹¨í•œ RNN ëª¨ë¸ ì •ì˜ê°„ë‹¨í•œ RNN ëª¨ë¸ ì •ì˜ {5px}ê°„ë‹¨í•œ RNN ëª¨ë¸ ì •ì˜ ï»¿â€‹PythonCopyclass SimpleRNN(nn.Module):
def __init__(self, input_size, hidden_size, output_size):
super(SimpleRNN, self).__init__()
        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)
        self.fc = nn.Linear(hidden_size, output_size)
def forward(self, x):
        h0 = torch.zeros(1, x.size(0), hidden_size) # ì´ˆê¸° ì€ë‹‰ ìƒíƒœ
        out, _ = self.rnn(x, h0)
        out = self.fc(out[:, -1, :]) # ë§ˆì§€ë§‰ ì‹œê°„ ë‹¨ê³„ì˜ ì¶œë ¥
return out

input_size = 1
hidden_size = 32
output_size = 1
model = SimpleRNN(input_size, hidden_size, output_size)
â€‹nn.RNN: ìˆœí™˜ ì‹ ê²½ë§(RNN) ì¸µì„ ì •ì˜í•©ë‹ˆë‹¤.nn.RNN(input_size, hidden_size, batch_first)ëŠ” ì…ë ¥ í¬ê¸°, ì€ë‹‰ ìƒíƒœ í¬ê¸°, ë°°ì¹˜ ì°¨ì›ì„ ì²« ë²ˆì§¸ë¡œ ì„¤ì •í•©ë‹ˆë‹¤..RNN(input_size, hidden_size, batch_first)ëŠ” ì…ë ¥ í¬ê¸°, ì€ë‹‰ ìƒíƒœ í¬ê¸°, ë°°ì¹˜ ì°¨ì›ì„ ì²« ë²ˆì§¸ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.ï»¿â€‹nn.Linear: ì„ í˜• ë³€í™˜ì„ ì ìš©í•˜ëŠ” ì™„ì „ ì—°ê²°(fully connected) ë ˆì´ì–´ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.nn.Linear(in_features, out_features)ëŠ” ì…ë ¥ íŠ¹ì§•ì˜ ìˆ˜ì™€ ì¶œë ¥ íŠ¹ì§•ì˜ ìˆ˜ë¥¼ ì§€ì •í•©ë‹ˆë‹¤..Linear(in_features, out_features)ëŠ” ì…ë ¥ íŠ¹ì§•ì˜ ìˆ˜ì™€ ì¶œë ¥ íŠ¹ì§•ì˜ ìˆ˜ë¥¼ ì§€ì •í•©ë‹ˆë‹¤.ï»¿â€‹â˜‘ï¸ ê°„ë‹¨í•œ LSTM ëª¨ë¸ ì •ì˜ê°„ë‹¨í•œ LSTM ëª¨ë¸ ì •ì˜ {5px}ê°„ë‹¨í•œ LSTM ëª¨ë¸ ì •ì˜ ï»¿â€‹PythonCopyclass SimpleLSTM(nn.Module):
def __init__(self, input_size, hidden_size, output_size):
super(SimpleLSTM, self).__init__()
        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)
        self.fc = nn.Linear(hidden_size, output_size)
def forward(self, x):
        h0 = torch.zeros(1, x.size(0), hidden_size) # ì´ˆê¸° ì€ë‹‰ ìƒíƒœ
        c0 = torch.zeros(1, x.size(0), hidden_size) # ì´ˆê¸° ì…€ ìƒíƒœ
        out, _ = self.lstm(x, (h0, c0))
        out = self.fc(out[:, -1, :]) # ë§ˆì§€ë§‰ ì‹œê°„ ë‹¨ê³„ì˜ ì¶œë ¥
return out

model = SimpleLSTM(input_size, hidden_size, output_size)
â€‹nn.LSTM: ì¥ë‹¨ê¸° ë©”ëª¨ë¦¬(LSTM) ì¸µì„ ì •ì˜í•©ë‹ˆë‹¤.nn.LSTM(input_size, hidden_size, batch_first)ëŠ” ì…ë ¥ í¬ê¸°, ì€ë‹‰ ìƒíƒœ í¬ê¸°, ë°°ì¹˜ ì°¨ì›ì„ ì²« ë²ˆì§¸ë¡œ ì„¤ì •í•©ë‹ˆë‹¤..LSTM(input_size, hidden_size, batch_first)ëŠ” ì…ë ¥ í¬ê¸°, ì€ë‹‰ ìƒíƒœ í¬ê¸°, ë°°ì¹˜ ì°¨ì›ì„ ì²« ë²ˆì§¸ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.ï»¿â€‹â˜‘ï¸ ëª¨ë¸ í•™ìŠµëª¨ë¸ í•™ìŠµ {5px}ëª¨ë¸ í•™ìŠµ ï»¿â€‹PythonCopy# ì†ì‹¤ í•¨ìˆ˜ì™€ ìµœì í™” ì•Œê³ ë¦¬ì¦˜ ì •ì˜
criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=0.01)
# ëª¨ë¸ í•™ìŠµ
num_epochs = 100
for epoch in range(num_epochs):
    outputs = model(X)
    optimizer.zero_grad()
    loss = criterion(outputs, y)
    loss.backward()
    optimizer.step()
if (epoch + 1) % 10 == 0:
print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')
print('Finished Training')
â€‹nn.MSELoss: í‰ê·  ì œê³± ì˜¤ì°¨(MSE) ì†ì‹¤ í•¨ìˆ˜ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.optim.Adam: Adam ìµœì í™” ì•Œê³ ë¦¬ì¦˜ì„ ì •ì˜í•©ë‹ˆë‹¤. lrì€ í•™ìŠµë¥ ì„ ì§€ì •í•©ë‹ˆë‹¤.optimizer.zero_grad(): ì´ì „ ë‹¨ê³„ì—ì„œ ê³„ì‚°ëœ ê¸°ìš¸ê¸°ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.loss.backward(): ì—­ì „íŒŒë¥¼ í†µí•´ ê¸°ìš¸ê¸°ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.optimizer.step(): ê³„ì‚°ëœ ê¸°ìš¸ê¸°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê°€ì¤‘ì¹˜ë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.â˜‘ï¸ ëª¨ë¸ í‰ê°€ ë° ì‹œê°í™”ëª¨ë¸ í‰ê°€ ë° ì‹œê°í™” {5px}ëª¨ë¸ í‰ê°€ ë° ì‹œê°í™” ï»¿â€‹PythonCopy# ëª¨ë¸ í‰ê°€
model.eval()
with torch.no_grad():
    predicted = model(X).detach().numpy()
# ì‹œê°í™”
plt.figure(figsize=(10, 5))
plt.plot(y.numpy().flatten(), label='True')
plt.plot(predicted.flatten(), label='Predicted')
plt.legend()
plt.show()
â€‹model.eval(): ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì „í™˜í•©ë‹ˆë‹¤.torch.no_grad(): í‰ê°€ ë‹¨ê³„ì—ì„œëŠ” ê¸°ìš¸ê¸°ë¥¼ ê³„ì‚°í•  í•„ìš”ê°€ ì—†ìœ¼ë¯€ë¡œ, ì´ë¥¼ ë¹„í™œì„±í™”í•˜ì—¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ì„ ì¤„ì…ë‹ˆë‹¤.detach(): í…ì„œë¥¼ ê³„ì‚° ê·¸ë˜í”„ì—ì„œ ë¶„ë¦¬í•©ë‹ˆë‹¤.Copyright â“’ TeamSparta All rights reserved.