[스파르타코딩클럽] 5. 합성곱 신경망(CNN)📘[SCC] 기초가 탄탄한 딥러닝/📚[스파르타코딩클럽] 기초가 탄탄한 딥러닝 - 2주차/📕[스파르타코딩클럽] 5. 합성곱 신경망(CNN)Made with📕[스파르타코딩클럽] 5. 합성곱 신경망(CNN)[수업 목표]합성곱 신경망의 개념에 대해서 배워보고 어떤 원리로 동작하는지 알아봅시다Pytorch로 간단한 CNN 모델 구현 실습을 진행해 봅시다[목차]01. CNN의 기본 구조와 동작 원리02. 실습: CNN을 이용한 이미지 분류 (PyTorch) - 입력 이미지에 필터(커널)를 적용하여 특징 맵(feature map)을 생성합니다. - 입력 이미지에 필터(커널)를 적용하여 특징 맵(feature map)을 생성합니다.﻿
 - 필터는 이미지의 국소적인 패턴을 학습합니다. - 필터는 이미지의 국소적인 패턴을 학습합니다.﻿
풀링 층 (Pooling Layer)
 - 특징 맵의 크기를 줄이고, 중요한 특징을 추출합니다. - 특징 맵의 크기를 줄이고, 중요한 특징을 추출합니다.﻿
 - 주로 Max Pooling과 Average Pooling이 사용됩니다. - 주로 Max Pooling과 Average Pooling이 사용됩니다.﻿
완전 연결 층 (Fully Connected Layer)
 - 추출된 특징을 바탕으로 최종 예측을 수행합니다. - 추출된 특징을 바탕으로 최종 예측을 수행합니다.﻿
 - CNN이라는 분석레이어를 통해 추출한 특성을 바탕으로 결론을 내리는 부분 - CNN이라는 분석레이어를 통해 추출한 특성을 바탕으로 결론을 내리는 부분﻿​2) 합성곱 연산과 필터☑️ 합성곱 연산의 원리와 필터의 역할합성곱 연산은 입력 이미지에 필터(커널)를 적용하여 특징 맵을 생성하는 과정입니다. 필터는 작은 크기의 행렬로, 이미지의 국소적인 패턴을 학습합니다.합성곱 연산:필터를 이미지의 각 위치에 슬라이딩하며, 필터와 이미지의 해당 부분 간의 점곱(dot product)을 계산합니다.계산된 값은 특징 맵의 해당 위치에 저장됩니다.필터의 역할:필터는 이미지의 에지(edge), 코너(corner), 텍스처(texture) 등 다양한 국소적인 패턴을 학습합니다.여러 개의 필터를 사용하여 다양한 특징 맵을 생성할 수 있습니다.3) 풀링 레이어, 플래튼☑️ 풀링 레이어의 필요성과 종류풀링 층은 특징 맵의 크기를 줄이고, 중요한 특징을 추출하는 역할을 합니다. 풀링 층은 주로 Max Pooling과 Average Pooling이 사용됩니다.Max Pooling:필터 크기 내에서 최대 값을 선택합니다.중요한 특징을 강조하고, 불필요한 정보를 제거합니다.Average Pooling:필터 크기 내에서 평균 값을 계산합니다.특징 맵의 크기를 줄이면서, 정보의 손실을 최소화합니다.☑️ 플래튼 레이어의 역할플래튼 층(Flatten Layer)은 2차원 특징 맵을 1차원 벡터로 변환하는 역할을 합니다. 이는 완전 연결 층에 입력으로 사용하기 위해 필요합니다.4) CNN 구조와 응용☑️ 다양한 CNN 아키텍처LeNet:최초의 CNN 아키텍처 중 하나로, 손글씨 숫자 인식에 사용되었습니다.합성곱 층과 풀링 층을 반복한 후, 완전 연결 층을 사용합니다.AlexNet:2012년 이미지넷 대회에서 우승한 아키텍처로, 딥러닝의 가능성을 입증했습니다.ReLU 활성화 함수와 드롭아웃(dropout)을 도입하여 성능을 향상시켰습니다.VGG:깊고 규칙적인 구조를 가진 아키텍처로, 작은 3x3 필터를 사용하여 깊이를 증가시켰습니다.VGG16과 VGG19가 대표적인 모델입니다.02. 실습: CNN을 이용한 이미지 분류 (PyTorch)✔️ 이제 PyTorch를 사용하여 간단한 CNN 모델을 구축하고, CIFAR-10 데이터셋을 사용하여 이미지 분류를 수행해보겠습니다1)  간단한 CNN 모델을 이용한 이미지 분류 실습☑️ PyTorch 및 필요한 라이브러리 임포트PyTorch 및 필요한 라이브러리 임포트 {5px}PyTorch 및 필요한 라이브러리 임포트 ﻿​PythonCopyimport torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
​☑️데이터셋 로드 및 전처리데이터셋 로드 및 전처리 {5px}데이터셋 로드 및 전처리 ﻿​PythonCopy# 데이터셋 전처리
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])
# CIFAR-10 데이터셋 로드
trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)

testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)
testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)
​☑️ 간단한 CNN 모델 정의간단한 CNN 모델 정의 {5px}간단한 CNN 모델 정의 ﻿​PythonCopyclass SimpleCNN(nn.Module):
def __init__(self):
super(SimpleCNN, self).__init__()
        self.conv1 = nn.Conv2d(3, 32, 3, padding=1) # 입력 채널 3, 출력 채널 32, 커널 크기 3x3
        self.pool = nn.MaxPool2d(2, 2) # 풀링 크기 2x2
        self.conv2 = nn.Conv2d(32, 64, 3, padding=1) # 입력 채널 32, 출력 채널 64, 커널 크기 3x3
        self.fc1 = nn.Linear(64 * 8 * 8, 512) # 완전 연결 층
        self.fc2 = nn.Linear(512, 10) # 출력 층 (10개의 클래스)
def forward(self, x):
        x = self.pool(torch.relu(self.conv1(x)))
        x = self.pool(torch.relu(self.conv2(x)))
        x = x.view(-1, 64 * 8 * 8) # 플래튼
        x = torch.relu(self.fc1(x))
        x = self.fc2(x)
return x
​nn.Conv2d: 2차원 합성곱 층을 정의합니다. nn.Conv2d(in_channels, out_channels, kernel_size, padding)은 입력 채널 수, 출력 채널 수, 커널 크기, 패딩을 지정.Conv2d(in_channels, out_channels, kernel_size, padding)은 입력 채널 수, 출력 채널 수, 커널 크기, 패딩을 지정﻿​nn.MaxPool2d: 2차원 최대 풀링 층을 정의합니다.nn.MaxPool2d(kernel_size, stride)은 풀링 크기와 스트라이드를 지정합니다..MaxPool2d(kernel_size, stride)은 풀링 크기와 스트라이드를 지정합니다.﻿​view: 텐서의 크기를 변경합니다.x.view(-1, 64 * 8 * 8)은 특징 맵을 1차원 벡터로 변환합니다..view(-1, 64 * 8 * 8)은 특징 맵을 1차원 벡터로 변환합니다.﻿​☑️ 모델 학습모델 학습 {5px}모델 학습 ﻿​PythonCopy# 모델 초기화
model = SimpleCNN()
# 손실 함수와 최적화 알고리즘 정의
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)
# 모델 학습
for epoch in range(10): # 10 에포크 동안 학습
    running_loss = 0.0
for i, data in enumerate(trainloader, 0):
        inputs, labels = data

        # 기울기 초기화
        optimizer.zero_grad()
# 순전파 + 역전파 + 최적화
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
# 손실 출력
        running_loss += loss.item()
if i % 100 == 99: # 매 100 미니배치마다 출력
print(f'[Epoch {epoch + 1}, Batch {i + 1}] loss: {running_loss / 100:.3f}')
            running_loss = 0.0
print('Finished Training')
​nn.CrossEntropyLoss: 다중 클래스 분류 문제에서 주로 사용되는 손실 함수입니다. 예측 값과 실제 값 사이의 교차 엔트로피 손실을 계산합니다.optim.SGD: 확률적 경사 하강법(Stochastic Gradient Descent) 최적화 알고리즘을 정의합니다.  lr은 학습률, momentum은 모멘텀 값을 지정합니다.은 학습률, momentum은 모멘텀 값을 지정합니다.﻿​optimizer.zero_grad(): 이전 단계에서 계산된 기울기를 초기화합니다.loss.backward(): 역전파를 통해 기울기를 계산합니다.optimizer.step(): 계산된 기울기를 바탕으로 가중치를 업데이트합니다.☑️ 모델  평가모델 평가 {5px}모델 평가 ﻿​PythonCopycorrect = 0
total = 0
with torch.no_grad():
for data in testloader:
        images, labels = data
        outputs = model(images)
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()
print(f'Accuracy of the network on the 10000 test images: {100 * correct / total:.2f}%')

​torch.no_grad(): 평가 단계에서는 기울기를 계산할 필요가 없으므로, 이를 비활성화하여 메모리 사용을 줄입니다.torch.max: 텐서의 최대 값을 찾습니다. torch.max(outputs.data, 1)은 각 샘플에 대해 가장 높은 확률을 가진 클래스를 반환합니다..max(outputs.data, 1)은 각 샘플에 대해 가장 높은 확률을 가진 클래스를 반환합니다.﻿​labels.size(0): 배치 크기를 반환합니다.(predicted == labels).sum().item(): 예측 값과 실제 값이 일치하는 샘플의 수를 계산합니다.Copyright ⓒ TeamSparta All rights reserved.