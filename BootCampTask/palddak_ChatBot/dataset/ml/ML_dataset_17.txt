[스파르타코딩클럽] 17강. 비지도학습 : 차원축소 - PCA 📘[SCC] 바닥부터 시작하는 머신러닝/📚[스파르타코딩클럽] 바닥부터 시작하는 머신러닝 - 4주차 /📕[스파르타코딩클럽] 17강. 비지도학습 : 차원축소 - PCA Made with📕[스파르타코딩클럽] 17강. 비지도학습 : 차원축소 - PCA [수업 목표]비지도학습 차원축소 중 PCA 에 대한 개념을 배우고, 데이터를 이용해 실습해 봅니다[목차]01. PCA 개념02. PCA 실습import pandas as pd

# MNIST 데이터셋 불러오기
mnist = fetch_openml('mnist_784', version=1)
# 데이터와 레이블 분리
X = mnist.data
y = mnist.target

# 데이터 프레임의 첫 5행 출력
print(X.head())
print(y.head())
​☑️ 데이터 표준화PCA를 수행하기 전에 데이터를 표준화합니다.데이터 표준화 {5px}데이터 표준화 ﻿​PythonCopyfrom sklearn.preprocessing import StandardScaler

# 데이터 표준화
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
​☑️ PCA 수행Scikit-learn의 PCA를 사용하여 PCA를 수행합니다.PCA수행 {5px}PCA수행 ﻿​PythonCopyfrom sklearn.decomposition import PCA

# PCA 모델 생성
pca = PCA(n_components=0.95) # 전체 분산의 95%를 설명하는 주성분 선택
# PCA 학습 및 변환
X_pca = pca.fit_transform(X_scaled)
# 변환된 데이터의 크기 확인
print(X_pca.shape)
​☑️ 주성분 확인선택된 주성분의 수와 각 주성분이 설명하는 분산 비율을 확인합니다.주성분 확인 {5px}주성분 확인 ﻿​PythonCopy# 선택된 주성분의 수
print(f'선택된 주성분의 수: {pca.n_components_}')
# 각 주성분이 설명하는 분산 비율
print(f'각 주성분이 설명하는 분산 비율: {pca.explained_variance_ratio_}')
# 누적 분산 비율
print(f'누적 분산 비율: {pca.explained_variance_ratio_.cumsum()}')
​☑️ PCA 결과 시각화PCA 결과를 2차원 또는 3차원으로 시각화합니다.PCA 결과 시각화 {5px}PCA 결과 시각화 ﻿​PythonCopyimport matplotlib.pyplot as plt
import seaborn as sns

# 2차원 시각화
plt.figure(figsize=(10, 7))
sns.scatterplot(x=X_pca[:, 0], y=X_pca[:, 1], hue=y, palette='viridis', legend=None)
plt.title('PCA of MNIST Dataset (2D)')
plt.xlabel('Principal Component 1')
plt.ylabel('Principal Component 2')
plt.show()

​Copyright ⓒ TeamSparta All rights reserved.