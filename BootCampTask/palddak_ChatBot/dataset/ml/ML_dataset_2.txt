[스파르타코딩클럽] 2강. 머신러닝 개요와 구성요소📘[SCC] 바닥부터 시작하는 머신러닝/📚[스파르타코딩클럽] 바닥부터 시작하는 머신러닝 - 1주차/📕[스파르타코딩클럽] 2강. 머신러닝 개요와 구성요소Made with📕[스파르타코딩클럽] 2강. 머신러닝 개요와 구성요소[수업 목표]머신러닝의 기본적인 구성요소, 학습과정을 알려 드립니다.다양한 머신러닝의 학습방법을 소개합니다.[목차]01. 머신러닝 구성 요소02. 머신러닝의 학습💡모든 토글을 열고 닫는 단축키
Windows : Ctrl + alt + t 
Mac : ⌘ + ⌥ + t 01. 머신러닝 구성 요소✔️머신러닝의 필수 구성요소를 학습합니다1) 머신러닝의 구성요소☑️ 데이터셋머신러닝은 데이터셋을 통해서 학습하며, 일반적으로 데이터셋은 입력/출력 데이터로 구성됩니다.입력 데이터 : 모델이 학습할 수 있는 정보출력 데이터(레이블) : 모델이 예측해야 하는 목표 값☑️ Feature(특징)데이터에서 모델이 학습할 수 있는 개별 속성주택가격예측을 예시로 들 경우 주택의 크기, 위치, 방의 개수 등이 Feature에 해당합니다주택가격예측을 예시로 들 경우 주택의 크기, 위치, 방의 개수 등이 Feature에 해당합니다﻿​☑️ 레이블예측하고자 하는 목표 변수지도학습 모델에서는 레이블이 있는 데이터셋을 이용하여 모델을 학습 시킵니다☑️ 모델데이터의 특징으로 부터 정답(레이블)을 예측할 수 있는 지식을 학습할 수 있는 프로그램/함수입력데이터와 출력 데이터간의 관계를 학습하여 새로운 데이터에 대한 예측 수행☑️ 학습모델이 데이터를 통해서 패턴을 인식하고, 이를 기반으로 예측을 수행 할 수 있도록 함수 내의 가중치를 조정하는 과정02. 머신러닝의 학습✔️머신러닝의 학습과정과 다양한 학습 종류에 대해서 학습합니다1) 머신러닝의 학습 과정머신러닝 학습 과정ALT데이터 수집 : 모델을 학습시키기 위한 필요 데이터 수집데이터 전처리 : 결측값 처리, 이상치 제거, 정규화 등등Feature 선택 : 중요 feature(특징)을 선택하고 불필요한 피쳐를 제거하여 학습효율 높임모델 선택 : 문제에 적합한 머신러닝 알고리즘을 선택모델 훈련 : 트레이닝 데이터셋을 사용해서 모델을 학습시킴모델 평가 : 테스트 데이터셋을 사용하여 모델 성능을 평가모델 배포 : 학습된 모델을 실제 환경에 배포하여 예측 수행2) 학습 방법☑️ 지도 학습 (Supervised Learning)레이블이 있는 데이터셋을 이용하여 모델을 학습시키는 방법회귀(Regression) : 연속적인 값을 예측하는 문제ex : 주택 가격 예측, 주식 가격예측 : 주택 가격 예측, 주식 가격예측﻿​분류(Classification) : 이산적인 값을 예측하는 문제ex : 이메일 스팸 필터링, 이미지 분류 : 이메일 스팸 필터링, 이미지 분류﻿​☑️ 비지도 학습 (Unsupervised Learning)레이블이 없는 데이터셋을 이용하려 모델을 학습시키는 방법군집화(Clustering) : 데이터를 유사한 그룹으로 묶는 문제 ex : 고객 세분화, 이미지 세그멘테이션 : 고객 세분화, 이미지 세그멘테이션﻿​차원축소 (Dimensionality Reduction) : 고차원 데이터를 저차원으로 변환ex : PCA, t-SNE : PCA, t-SNE﻿​☑️ 앙상블 학습 (Ensemble Learning)여러개의 머신러닝 모델을 결합하여 더 나은 성능을 얻는 방법배깅(Bagging) : 여러 모델을 독립적으로 학습시키고, 예측을 평균내거나 다수결 투표로 최종 예측ex : 랜덤포레스트 : 랜덤포레스트﻿​부스팅(Boosting) : 여러 모델을 순차적으로 학습시키고, 이전 모델의 오차를 보완하여 최종 예측을 수행ex : 그래디언트 부스팅, XGboost : 그래디언트 부스팅, XGboost﻿​스태킹(Stacking) : 여러 모델을 학습시키고 예측결과를 새로운 데이터로 사용하여 메타 모델을 학습⚠️ 과적합이란?과적합(Overfitting):모델이 훈련 데이터에 지나치게 적응하여 새로운 데이터에 대한 일반화 성능이 떨어지는 현상입니다. 모델이 너무 복잡하여 훈련 데이터의 노이즈까지 학습해버리는 경우 발생합니다. 📉방지 방법:더 많은 데이터 수집 📊교차 검증(Cross-validation) 사용 🔄정규화(Regularization) 기법 적용 🔧간단한 모델 사용 🚀🚫 머신러닝에서는 "절대로 좋다"라는 개념이 없다!모델의 성능:모든 데이터셋에 대해 완벽한 성능을 보이는 모델은 없습니다. 각 모델은 특정 데이터와 상황에서만 최적의 성능을 발휘합니다. 🎯트레이드오프:모델의 복잡성과 일반화 성능 사이에는 항상 균형이 필요합니다. 너무 복잡한 모델은 과적합의 위험이 있고, 너무 단순한 모델은 충분히 학습하지 못할 수 있습니다. ⚖️Copyright ⓒ TeamSparta All rights reserved.