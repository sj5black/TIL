{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 출처\n",
    "\n",
    "> RAG & LLM 오픈소스\n",
    "\n",
    "- RAG 기반 비구조화된 데이터를 기반으로 질문에 답변하는 오픈 소스 : https://huggingface.co/learn/cookbook/rag_with_unstructured_data\n",
    "\n",
    "- 다양한 유형의 소스 (PDF, YouTube 동영상) 로부터 데이터를 가공해 RAG 파이프 라인을 구현하는 예제의 컬럼 :  https://huggingface.co/blog/ngxson/make-your-own-rag\n",
    "\n",
    "---\n",
    "\n",
    "> DipLearning\n",
    "\n",
    "- ResNet을 이용한 개 고양이 분류기 : https://github.com/woodong11/Cat_vs_Dog_classifier/blob/main/train.ipynb\n",
    "\n",
    "- GAN을 이용한 MNIST 숫자 생성 모델 : https://github.com/happy-jihye/Awesome-GAN-Papers/blob/main/gan/gan.ipynb\n",
    "\n",
    "---\n",
    "\n",
    "> MachineLearning\n",
    "\n",
    "- ETF 예측 모델 (다중선형회귀, XGBoost, ARIMA) :  https://github.com/terri1102/Stock_price_prediction/blob/main/stock_price_prediction.ipynb\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "> Data anaysis\n",
    "\n",
    "- 서울시 공공 자전거 분석 : https://github.com/coding-Benny/data-visualization/blob/master/public_bicycle.ipynb\n",
    "\n",
    "- 무더위 쉼터 데이터 : https://github.com/coding-Benny/data-visualization/blob/master/heatwave_shelter_service.ipynb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. URL, user agent 전역 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "\n",
    "url_rag_1 = \"https://huggingface.co/learn/cookbook/rag_with_unstructured_data\"\n",
    "url_rag_2 = \"https://huggingface.co/blog/ngxson/make-your-own-rag\"\n",
    "url_dl_1 = \"https://github.com/woodong11/Cat_vs_Dog_classifier/blob/main/train.ipynb\"\n",
    "url_dl_2 = \"https://github.com/happy-jihye/Awesome-GAN-Papers/blob/main/gan/gan.ipynb\"\n",
    "url_ml_1 = \"https://github.com/terri1102/Stock_price_prediction/blob/main/stock_price_prediction.ipynb\"\n",
    "url_anaysis_1 = \"https://github.com/coding-Benny/data-visualization/blob/master/public_bicycle.ipynb\"\n",
    "url_anaysis_2 = \"https://github.com/coding-Benny/data-visualization/blob/master/heatwave_shelter_service.ipynb\"\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"yMozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36\"  \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-1. RAG & LLM 데이터 가공 1: code block과 본문을 분리해서 저장하는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code block만을 파싱하는 함수\n",
    "\n",
    "def get_code_block_from_huggingface(url:str, header:dict) -> list:\n",
    "    # 웹 페이지 요청\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # `pre` 태그 모두 찾기\n",
    "    pre_tags = soup.find_all('pre')\n",
    "\n",
    "    # pre 태그의 텍스트를 리스트로 추출\n",
    "    pre_texts = [pre.get_text() for pre in pre_tags]\n",
    "\n",
    "    return pre_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 본문만을 파싱하는 함수\n",
    "\n",
    "def get_content_from_huggingface(url:str, header:dict) -> list:\n",
    "    # 웹 페이지 요청\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # `pre` 태그 모두 찾기\n",
    "    pre_tags = soup.find_all('p')\n",
    "\n",
    "    # pre 태그의 텍스트를 리스트로 추출\n",
    "    pre_texts = [pre.get_text() for pre in pre_tags]\n",
    "\n",
    "    return pre_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RAG & LLM 전용 Json 타입으로 저장하는 메서드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# 기본 저장 경로\n",
    "root_path = \"open_source\"\n",
    "\n",
    "def get_partition_and_save_to_json(url: str, header: str, path: str, file_name: str):\n",
    "    try:\n",
    "        # Huggingface URL에서 코드블럭과 콘텐츠를 추출\n",
    "        code_block = get_code_block_from_huggingface(url, header)\n",
    "        content = get_content_from_huggingface(url, header)\n",
    "\n",
    "        # 저장 디렉토리 생성 (없으면 생성)\n",
    "        save_path = os.path.join(root_path, path)\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "        # 코드블럭 JSON 저장\n",
    "        code_file_path = os.path.join(save_path, f\"{file_name}_codeblock.json\")\n",
    "        with open(code_file_path, 'w', encoding='utf-8') as code_file:\n",
    "            json.dump(code_block, code_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "        # 콘텐츠 JSON 저장\n",
    "        content_file_path = os.path.join(save_path, f\"{file_name}_content.json\")\n",
    "        with open(content_file_path, 'w', encoding='utf-8') as content_file:\n",
    "            json.dump(content, content_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "        print(f\"JSON 파일 저장 완료:\\n- 코드블럭: {code_file_path}\\n- 콘텐츠: {content_file_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"JSON 저장 중 오류 발생: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON 파일 저장 완료:\n",
      "- 코드블럭: open_source/partition/llm_rag/unconstructed_data_codeblock.json\n",
      "- 콘텐츠: open_source/partition/llm_rag/unconstructed_data_content.json\n",
      "JSON 파일 저장 완료:\n",
      "- 코드블럭: open_source/partition/llm_rag/various_source_codeblock.json\n",
      "- 콘텐츠: open_source/partition/llm_rag/various_source_content.json\n"
     ]
    }
   ],
   "source": [
    "get_partition_and_save_to_json(url_rag_1, headers, \"partition/llm_rag\", \"unconstructed_data\")\n",
    "get_partition_and_save_to_json(url_rag_2, headers, \"partition/llm_rag\", \"various_source\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2. WebBaseLoader 이용 (codeblock + text 모두 포함됨) - RAW 한 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "\n",
    "def raw_preProcess(text):\n",
    "    # 2. 소문자 변환\n",
    "    text = text.lower()\n",
    "\n",
    "    # \\n과 \\t 공간 삭제\n",
    "    text = re.sub(r'[\\n\\t]', '', text)\n",
    "\n",
    "    # 5. 전처리된 텍스트 반환\n",
    "    return ''.join(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_webBaseLoader_and_save_to_text(url:str, path: str, file_name:str):\n",
    "\n",
    "    try:\n",
    "        loader = WebBaseLoader(\n",
    "            web_paths= [url]\n",
    "        )\n",
    "\n",
    "        docs = loader.load()\n",
    "        result = \"\"\n",
    "        for doc in docs:\n",
    "            result += raw_preProcess(doc.page_content)\n",
    "\n",
    "        # 저장 디렉토리 생성 (없으면 생성)\n",
    "        save_path = os.path.join(root_path, path)\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "        # 코드블럭 JSON 저장\n",
    "        raw_file_path = os.path.join(save_path, f\"{file_name}_raw.txt\")\n",
    "\n",
    "        with open(raw_file_path, 'w', encoding='utf-8') as content_file:\n",
    "            content_file.write(result)\n",
    "            \n",
    "        print(f\"JSON 파일 저장 완료:\\n- raw: {raw_file_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"JSON 저장 중 오류 발생: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON 파일 저장 완료:\n",
      "- raw: open_source/raw/llm_rag/unconstructed_data_raw.txt\n",
      "JSON 파일 저장 완료:\n",
      "- raw: open_source/raw/llm_rag/various_source_raw.txt\n"
     ]
    }
   ],
   "source": [
    "get_webBaseLoader_and_save_to_text(url_rag_1, \"raw/llm_rag\", \"unconstructed_data\")\n",
    "get_webBaseLoader_and_save_to_text(url_rag_1, \"raw/llm_rag\", \"various_source\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-3. github의 ipynb파일 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nbformat in /opt/anaconda3/envs/ai_model/lib/python3.12/site-packages (5.10.4)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in /opt/anaconda3/envs/ai_model/lib/python3.12/site-packages (from nbformat) (2.16.2)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /opt/anaconda3/envs/ai_model/lib/python3.12/site-packages (from nbformat) (4.23.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /opt/anaconda3/envs/ai_model/lib/python3.12/site-packages (from nbformat) (5.7.2)\n",
      "Requirement already satisfied: traitlets>=5.1 in /opt/anaconda3/envs/ai_model/lib/python3.12/site-packages (from nbformat) (5.14.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/anaconda3/envs/ai_model/lib/python3.12/site-packages (from jsonschema>=2.6->nbformat) (24.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/anaconda3/envs/ai_model/lib/python3.12/site-packages (from jsonschema>=2.6->nbformat) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/anaconda3/envs/ai_model/lib/python3.12/site-packages (from jsonschema>=2.6->nbformat) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/anaconda3/envs/ai_model/lib/python3.12/site-packages (from jsonschema>=2.6->nbformat) (0.10.6)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /opt/anaconda3/envs/ai_model/lib/python3.12/site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat) (3.10.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install nbformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_raw_url(github_url: str) -> str:\n",
    "    if \"github.com\" in github_url:\n",
    "        # 'blob'을 '/'로 바꾸고 'github.com'을 'raw.githubusercontent.com'으로 변환\n",
    "        raw_url = github_url.replace(\"github.com\", \"raw.githubusercontent.com\").replace(\"/blob\", \"\")\n",
    "        return raw_url\n",
    "    else:\n",
    "        raise ValueError(\"Invalid GitHub URL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import nbformat\n",
    "\n",
    "def get_code_ipynb_from_github(url: str, headers: dict = None) -> list:\n",
    "    response = requests.get(convert_to_raw_url(url), headers=headers)\n",
    "    result = []\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        try:\n",
    "            # 텍스트로 데이터를 가져온 뒤 JSON 파싱\n",
    "            notebook_content = response.text\n",
    "            notebook = nbformat.reads(notebook_content, as_version=4)\n",
    "\n",
    "            # Notebook 셀 확인\n",
    "            for cell in notebook.get('cells', []):\n",
    "                if cell.get('cell_type') == 'code':  # 코드 셀인지 확인\n",
    "                    result.append(cell.get('source', \"\"))\n",
    "                \n",
    "            return result\n",
    "        except Exception as e:\n",
    "            print(f\"Notebook 처리 중 오류 발생: {e}\")\n",
    "    else:\n",
    "        print(f\"Failed to fetch notebook: HTTP {response.status_code}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_markdown_ipynb_from_github(url:str, header:str) -> list:\n",
    "\n",
    "    response = requests.get(convert_to_raw_url(url))\n",
    "    result = []\n",
    "    if response.status_code == 200:\n",
    "        notebook_content = response.text\n",
    "        # JSON 형식의 notebook 파일 로드\n",
    "        notebook = nbformat.reads(notebook_content, as_version=4)\n",
    "        \n",
    "        # Notebook 셀 확인\n",
    "        for cell in notebook.get('cells', []):\n",
    "            # 이미지나 다른 데이터가 포함된 출력은 제외\n",
    "            if cell.get('cell_type') == 'markdown':\n",
    "                if 'image' not in cell.get('source', '').lower():\n",
    "                    result.append(cell.get('source', \"\"))\n",
    "                \n",
    "            elif 'outputs' in cell:\n",
    "                # 출력에 이미지가 포함되지 않도록 필터링\n",
    "                outputs = cell['outputs']\n",
    "                filtered_outputs = [\n",
    "                    output for output in outputs if output.output_type != 'display_data' or 'image' not in output.data\n",
    "                ]\n",
    "                if filtered_outputs:\n",
    "                    result.extend([output.get('text/plain', '') for output in filtered_outputs])\n",
    "                        \n",
    "        return result\n",
    "    else:\n",
    "        print(f\"Failed to fetch notebook: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# 기본 저장 경로\n",
    "root_path = \"open_source\"\n",
    "\n",
    "def save_to_json_github(url: str, header: str, path: str, file_name: str):\n",
    "    try:\n",
    "        # Huggingface URL에서 코드블럭과 콘텐츠를 추출\n",
    "        code_block = get_code_ipynb_from_github(url, header)\n",
    "        content = get_markdown_ipynb_from_github(url, header)\n",
    "\n",
    "        # 저장 디렉토리 생성 (없으면 생성)\n",
    "        save_path = os.path.join(root_path, path)\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "        # 코드블럭 JSON 저장\n",
    "        code_file_path = os.path.join(save_path, f\"{file_name}_codeblock.json\")\n",
    "        with open(code_file_path, 'w', encoding='utf-8') as code_file:\n",
    "            json.dump(code_block, code_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "        # 콘텐츠 JSON 저장\n",
    "        content_file_path = os.path.join(save_path, f\"{file_name}_content.json\")\n",
    "        with open(content_file_path, 'w', encoding='utf-8') as content_file:\n",
    "            json.dump(content, content_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "        print(f\"JSON 파일 저장 완료:\\n- 코드블럭: {code_file_path}\\n- 콘텐츠: {content_file_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"JSON 저장 중 오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_json_github(url_dl_1, headers, \"partition/dl\", \"cat_and_dog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON 파일 저장 완료:\n",
      "- 코드블럭: open_source/partition/analysis/bicycle_codeblock.json\n",
      "- 콘텐츠: open_source/partition/analysis/bicycle_content.json\n",
      "JSON 파일 저장 완료:\n",
      "- 코드블럭: open_source/partition/analysis/heatware_codeblock.json\n",
      "- 콘텐츠: open_source/partition/analysis/heatware_content.json\n"
     ]
    }
   ],
   "source": [
    "save_to_json_github(url_anaysis_1, headers, \"partition/analysis\", \"bicycle\")\n",
    "save_to_json_github(url_anaysis_2, headers, \"partition/analysis\", \"heatware\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_raw_ipynb_from_github(url: str, headers: dict = None) -> str:\n",
    "    response = requests.get(convert_to_raw_url(url), headers=headers)\n",
    "    result = \"\"  # 빈 문자열로 수정\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        try:\n",
    "            # 텍스트로 데이터를 가져온 뒤 JSON 파싱\n",
    "            notebook_content = response.text\n",
    "            notebook = nbformat.reads(notebook_content, as_version=4)\n",
    "\n",
    "            # Notebook 셀 확인\n",
    "            for cell in notebook.get('cells', []):\n",
    "                if cell.get('cell_type') == 'code':  # 코드 셀만 선택\n",
    "                    result += raw_preProcess(cell.get('source', \"\"))\n",
    "                \n",
    "                # 이미지나 다른 데이터가 포함된 출력은 제외\n",
    "                elif cell.get('cell_type') == 'markdown':\n",
    "                    if 'image' not in cell.get('source', '').lower():\n",
    "                        result += raw_preProcess(cell.get('source', \"\"))\n",
    "                \n",
    "                elif 'outputs' in cell:\n",
    "                    # 출력에 이미지가 포함되지 않도록 필터링\n",
    "                    outputs = cell['outputs']\n",
    "                    filtered_outputs = [\n",
    "                        output for output in outputs if output.output_type != 'display_data' or 'image' not in output.data\n",
    "                    ]\n",
    "                    if filtered_outputs:\n",
    "                        # `extend()`를 `+=`로 변경하여 문자열을 이어 붙이기\n",
    "                        result += \"\".join([output.get('text/plain', '') for output in filtered_outputs])\n",
    "\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            print(f\"Notebook 처리 중 오류 발생: {e}\")\n",
    "    else:\n",
    "        print(f\"Failed to fetch notebook: HTTP {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# 기본 저장 경로\n",
    "root_path = \"open_source\"\n",
    "\n",
    "def save_raw_to_text_github(url: str, header: str, path: str, file_name: str):\n",
    "    try:\n",
    "        # Huggingface URL에서 코드블럭과 콘텐츠를 추출\n",
    "        result = get_raw_ipynb_from_github(url, header)\n",
    "\n",
    "        # 저장 디렉토리 생성 (없으면 생성)\n",
    "        save_path = os.path.join(root_path, path)\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "        # 콘텐츠 JSON 저장\n",
    "        # 코드블럭 JSON 저장\n",
    "        raw_file_path = os.path.join(save_path, f\"{file_name}_raw.txt\")\n",
    "\n",
    "        with open(raw_file_path, 'w', encoding='utf-8') as content_file:\n",
    "            content_file.write(result)\n",
    "\n",
    "        print(f\"JSON 파일 저장 완료:\\n- raw: {raw_file_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"JSON 저장 중 오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON 파일 저장 완료:\n",
      "- raw: open_source/raw/dl/stock_raw.txt\n"
     ]
    }
   ],
   "source": [
    "save_raw_to_text_github(url_ml_1, headers, \"raw/dl\", \"stock\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_model",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
