{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ì½”ë“œ ìˆ˜ì •\n",
    "- ë¦¬ë·°ì— ì œê³µí•´ì£¼ì‹  ì½”ë“œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì½”ë“œë¥¼ ë‹¤ì‹œ ìˆ˜ì •í–ˆìŠµë‹ˆë‹¤.   \n",
    "```python\n",
    "quiz_list = []\n",
    "\n",
    "# ëŒ€í™” ì§„í–‰\n",
    "while True:\n",
    "    # 1. í€´ì¦ˆ ìƒì„±\n",
    "    quiz = rag_chain.invoke(\"í€´ì¦ˆë¥¼ ì‹œì‘í•˜ì„¸ìš”.\")\n",
    "# 'í€´ì¦ˆ:'ë¡œ ì‹œì‘í•˜ëŠ” ë‚´ìš©ë§Œ ì¶”ì¶œ\n",
    "    quiz_pattern = r\"í€´ì¦ˆ: .*\"\n",
    "    all_quizzes = \"\\n\".join(quiz_list)  # ë¦¬ìŠ¤íŠ¸ë¥¼ ë¬¸ìì—´ë¡œ ê²°í•©\n",
    "    quiz_onlys = re.findall(quiz_pattern, all_quizzes)  # ë¬¸ìì—´ì—ì„œ ê²€ìƒ‰\n",
    "```\n",
    "\n",
    "- ë‚´ìš©ì„ ì¶”ì¶œí•´ì˜¤ëŠ” ê³³ì„ previous_conversationì—ì„œ quiz_listë¡œ ë°”ê¿¨ìŠµë‹ˆë‹¤.\n",
    "```python\n",
    "# 'í€´ì¦ˆ:'ë¡œ ì‹œì‘í•˜ëŠ” ë‚´ìš©ë§Œ ì¶”ì¶œ\n",
    "quiz_pattern = r\"í€´ì¦ˆ: .*\"\n",
    "all_quizzes = \"\\n\".join(quiz_list)  # ë¦¬ìŠ¤íŠ¸ë¥¼ ë¬¸ìì—´ë¡œ ê²°í•©\n",
    "quiz_onlys = re.findall(quiz_pattern, all_quizzes)  # ë¬¸ìì—´ì—ì„œ ê²€ìƒ‰\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from pprint import pprint\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import re\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# .env íŒŒì¼ì—ì„œ í™˜ê²½ë³€ìˆ˜ ë¡œë“œ\n",
    "load_dotenv(\"C:/.env\")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# Selenium ì˜µì…˜ ì„¤ì • (í—¤ë“œë¦¬ìŠ¤ ëª¨ë“œë¡œ ì‹¤í–‰)\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")  # ë¸Œë¼ìš°ì € ì°½ì„ ë„ìš°ì§€ ì•ŠìŒ\n",
    "chrome_options.add_argument(\"--disable-gpu\")  # GPU ë¹„í™œì„±í™” (ì¼ë¶€ í™˜ê²½ì—ì„œ í•„ìš”)\n",
    "\n",
    "# WebDriver ê²½ë¡œ ì„¤ì • (ìë™ ì„¤ì¹˜)\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "\n",
    "url_list=[]\n",
    "txt_list=[]\n",
    "\n",
    "# í™˜ê²½ë³€ìˆ˜ì— ì €ì¥ëœ URL ë¡œë“œ\n",
    "for i in range(1, 17):  # URL_1 ~ URL_16\n",
    "    url = os.getenv(f\"URL_{i}\")\n",
    "    if url:  # í™˜ê²½ë³€ìˆ˜ê°€ ì¡´ì¬í•˜ë©´ ì¶”ê°€\n",
    "        url_list.append(url)\n",
    "\n",
    "# ì›¹í˜ì´ì§€ ìš”ì²­\n",
    "for url in url_list:\n",
    "    driver.get(url)  # í˜ì´ì§€ ë¡œë“œ\n",
    "\n",
    "    # íŠ¹ì • ìš”ì†Œê°€ ë¡œë“œë  ë•Œê¹Œì§€ ê¸°ë‹¤ë¦¼ (ì˜ˆ: Notion í˜ì´ì§€ì—ì„œ ì£¼ìš” ì½˜í…ì¸ ê°€ ë‹´ê¸¸ ìš”ì†Œ)\n",
    "    try:\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, \".notion-page-content\"))\n",
    "        )\n",
    "    except TimeoutException:\n",
    "        print(f\"í˜ì´ì§€ ë¡œë”© ì‹¤íŒ¨: {url}\")\n",
    "        continue\n",
    "    \n",
    "    # í† ê¸€ì´ ë‹«í˜€ ìˆìœ¼ë©´ í† ê¸€ì„ ì—´ê¸°\n",
    "    try:\n",
    "        # ëª¨ë“  í† ê¸€ ë²„íŠ¼ì„ ì°¾ìŒ (Ctrl+Alt+Tì— í•´ë‹¹í•˜ëŠ” í† ê¸€ì„ ì°¾ì•„ì„œ ì—´ê¸°)\n",
    "        toggle_buttons = driver.find_elements(By.XPATH, \"//div[@role='button' and contains(@aria-label, 'ì—´ê¸°')]\")\n",
    "        \n",
    "        # ê° í† ê¸€ì„ í´ë¦­í•˜ì—¬ ì—´ê¸°\n",
    "        for button in toggle_buttons:\n",
    "            button.click()\n",
    "            time.sleep(1)  # í† ê¸€ì´ ì—´ë¦¬ê¸° ì „ì— ì ê¹ ëŒ€ê¸°\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"í† ê¸€ì„ ì—¬ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}\")\n",
    "\n",
    "    # í˜ì´ì§€ì˜ HTML ê°€ì ¸ì˜¤ê¸°\n",
    "    html_code = driver.page_source\n",
    "\n",
    "    # BeautifulSoupìœ¼ë¡œ HTML íŒŒì‹±\n",
    "    soup = BeautifulSoup(html_code, 'html.parser')\n",
    "\n",
    "    txt = soup.get_text()\n",
    "\n",
    "    # 1. \\xa0ë¥¼ ê³µë°±ìœ¼ë¡œ ë³€í™˜\n",
    "    txt = txt.replace('\\xa0', ' ')\n",
    "\n",
    "    # 2. ì •ê·œì‹ì„ ì‚¬ìš©í•´ \\\\ë¡œ ì‹œì‘í•˜ëŠ” LaTeX ëª…ë ¹ì–´ ì œê±°\n",
    "    txt = re.sub(r'\\\\[a-zA-Z]+\\{.*?\\}', '', txt)  # \\command{...} í˜•ì‹ ì œê±°\n",
    "    txt = re.sub(r'\\\\[a-zA-Z]+', '', txt)        # \\command í˜•ì‹ ì œê±°\n",
    "\n",
    "    # 3. ë¶ˆí•„ìš”í•œ ê³µë°± ì œê±° (ì½”ë“œ ê°œí–‰ ìœ ì§€ë¥¼ ìœ„í•´ ì£¼ì„ì²˜ë¦¬)\n",
    "    # txt = re.sub(r'\\s+', ' ', txt).strip()\n",
    "\n",
    "    # í…ìŠ¤íŠ¸ë§Œ ê°€ì ¸ì˜¤ê¸°\n",
    "    txt_list.append(txt)\n",
    "\n",
    "\n",
    "driver.quit()  # ë¸Œë¼ìš°ì € ì¢…ë£Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('[ìŠ¤íŒŒë¥´íƒ€ì½”ë”©í´ëŸ½] 10ê°•. ì§€ë„í•™ìŠµ : ë¶„ë¥˜ëª¨ë¸ - SVM[SCC] ë°”ë‹¥ë¶€í„° ì‹œì‘í•˜ëŠ” ë¨¸ì‹ ëŸ¬ë‹/[ìŠ¤íŒŒë¥´íƒ€ì½”ë”©í´ëŸ½] ë°”ë‹¥ë¶€í„° ì‹œì‘í•˜ëŠ” '\n",
      " 'ë¨¸ì‹ ëŸ¬ë‹ - 3ì£¼ì°¨/[ìŠ¤íŒŒë¥´íƒ€ì½”ë”©í´ëŸ½] 10ê°•. ì§€ë„í•™ìŠµ : ë¶„ë¥˜ëª¨ë¸ - SVMì œì‘:[ìŠ¤íŒŒë¥´íƒ€ì½”ë”©í´ëŸ½] 10ê°•. ì§€ë„í•™ìŠµ : ë¶„ë¥˜ëª¨ë¸ - '\n",
      " 'SVM[ìˆ˜ì—… ëª©í‘œ]SVM(Support Vector Machine)ì— ëŒ€í•œ ê°œë…ì„ ë°°ìš°ê³ , ë°ì´í„°ë¥¼ ì´ìš©í•´ ì‹¤ìŠµí•´ ë´…ë‹ˆë‹¤[ëª©ì°¨]01. '\n",
      " 'SVM ê°œë…02. SVM ì‹¤ìŠµğŸ’¡ëª¨ë“  í† ê¸€ì„ ì—´ê³  ë‹«ëŠ” ë‹¨ì¶•í‚¤\\n'\n",
      " 'Windows : Ctrl + alt + t \\n'\n",
      " 'Mac : âŒ˜ + âŒ¥ + t 01. SVM ê°œë…âœ”ï¸SVMì´ ë¬´ì—‡ì¸ì§€ ì•Œì•„ë´…ì‹œë‹¤1) SVM SVMì´ë€?ì„œí¬íŠ¸ ë²¡í„° ë¨¸ì‹ (SVM)ì€ ë¶„ë¥˜ì™€ '\n",
      " 'íšŒê·€ ë¶„ì„ì— ì‚¬ìš©ë˜ëŠ” ê°•ë ¥í•œ ì§€ë„í•™ìŠµ ëª¨ë¸ë°ì´í„°ë¥¼ ë¶„ë¥˜í•˜ê¸° ìœ„í•´ ê²°ì • ê²½ê³„(ê²°ì • ì´ˆí‰ë©´, hyperplane)ë¥¼ ì°¾ì•„ ë¶„ë¥˜í•©ë‹ˆë‹¤.ì´ˆí‰ë©´ì€ '\n",
      " 'ë‘ í´ë˜ìŠ¤ ì‚¬ì´ì˜ ìµœëŒ€ ë§ˆì§„ì„ ë³´ì¥í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ì„ íƒí•©ë‹ˆë‹¤.ALTë§ˆì§„ : ë‘ í´ë˜ìŠ¤ ê°„ì˜ ê°€ì¥ ê°€ê¹Œìš´ ë°ì´í„° í¬ì¸íŠ¸ ì‚¬ì´ì˜ ê±°ë¦¬ë§ˆì§„ : '\n",
      " 'ë‘ í´ë˜ìŠ¤ ê°„ì˜ ê°€ì¥ ê°€ê¹Œìš´ ë°ì´í„° í¬ì¸íŠ¸ ì‚¬ì´ì˜ ê±°ë¦¬\\ufeff\\n'\n",
      " 'ì„œí¬íŠ¸ ë²¡í„° : ê²°ì • ì´ˆí‰ë©´ì— ê°€ì¥ ê°€ê¹Œì´ ìœ„ì¹˜í•œ ë°ì´í„° í¬ì¸íŠ¸ - ê²°ì • ì´ˆí‰ë©´ì„ ì •ì˜í•©ë‹ˆë‹¤ì„œí¬íŠ¸ ë²¡í„° : ê²°ì • ì´ˆí‰ë©´ì— ê°€ì¥ ê°€ê¹Œì´ '\n",
      " 'ìœ„ì¹˜í•œ ë°ì´í„° í¬ì¸íŠ¸ - ê²°ì • ì´ˆí‰ë©´ì„ ì •ì˜í•©ë‹ˆë‹¤\\ufeff\\n'\n",
      " 'ì»¤ë„ í•¨ìˆ˜ : ë°ì´í„°ë¥¼ ë” ë†’ì€ ì°¨ì›ìœ¼ë¡œ ë§¤í•‘í•˜ì—¬ ì„ í˜•ì ìœ¼ë¡œ ë¶„ë¦¬ í•  ìˆ˜ ì—†ëŠ” ë°ì´í„°ë¥¼ ë¶„ë¦¬í•˜ê²Œ í•©ë‹ˆë‹¤. ì»¤ë„ í•¨ìˆ˜ : ë°ì´í„°ë¥¼ ë” ë†’ì€ '\n",
      " 'ì°¨ì›ìœ¼ë¡œ ë§¤í•‘í•˜ì—¬ ì„ í˜•ì ìœ¼ë¡œ ë¶„ë¦¬ í•  ìˆ˜ ì—†ëŠ” ë°ì´í„°ë¥¼ ë¶„ë¦¬í•˜ê²Œ í•©ë‹ˆë‹¤. \\ufeff\\u200b SVMì˜ ëª©ì SVMì˜ ëª©í‘œëŠ” ë§ˆì§„ì„ '\n",
      " 'ìµœëŒ€í™”í•˜ë©´ì„œ ê²°ì • ì´ˆí‰ë©´ì„ ì°¾ì•„ ë°ì´í„° í¬ì¸íŠ¸ë¥¼ ì •í™•í•˜ê²Œ ë¶„ë¥˜í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ì´ëŠ” ì¼ë°˜í™” ì„±ëŠ¥ì„ ë†’ì´ëŠ” ë° ë„ì›€ì„ '\n",
      " 'ì¤ë‹ˆë‹¤.wâ‹…xâˆ’b=0   - b = 0 wâ‹…xâˆ’b=0ì—¬ê¸°ì„œ wëŠ” ê°€ì¤‘ì¹˜ ë²¡í„°, xëŠ” ì…ë ¥ ë²¡í„°, bëŠ” ì ˆí¸ì…ë‹ˆë‹¤.\\\\)ëŠ” ê°€ì¤‘ì¹˜ ë²¡í„°, '\n",
      " '\\\\(\\\\)ëŠ” ì…ë ¥ ë²¡í„°, \\\\(b\\\\)ëŠ” ì ˆí¸ì…ë‹ˆë‹¤.}ì—¬ê¸°ì„œ wëŠ” ê°€ì¤‘ì¹˜ ë²¡í„°, xëŠ” ì…ë ¥ ë²¡í„°, bëŠ” '\n",
      " 'ì ˆí¸ì…ë‹ˆë‹¤.\\ufeff\\u200b02. SVM ì‹¤ìŠµâœ”ï¸Scikit-learnì˜ ìœ ë°©ì•”ë°ì´í„°ì™€ Seabornì˜ íƒ€ì´íƒ€ë‹‰ ë°ì´í„°ë¡œ SVM '\n",
      " 'ì‹¤ìŠµì„ ì§„í–‰í•©ë‹ˆë‹¤1) ìœ ë°©ì•” ë°ì´í„° ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ìœ ë°©ì•” ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ {5px}ìœ ë°©ì•” ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ '\n",
      " '\\ufeff\\u200bPythonë³µì‚¬import numpy as np\\n'\n",
      " 'import pandas as pd\\n'\n",
      " 'from sklearn.datasets import load_breast_cancer\\n'\n",
      " 'from sklearn.model_selection import train_test_split\\n'\n",
      " 'from sklearn.preprocessing import StandardScaler\\n'\n",
      " '\\n'\n",
      " '# ë°ì´í„° ë¡œë“œ\\n'\n",
      " 'data = load_breast_cancer()\\n'\n",
      " 'X = data.data\\n'\n",
      " 'y = data.target\\n'\n",
      " '\\n'\n",
      " '# ë°ì´í„° ë¶„í• \\n'\n",
      " 'X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, '\n",
      " 'random_state=42)\\n'\n",
      " '# ë°ì´í„° ìŠ¤ì¼€ì¼ë§\\n'\n",
      " 'scaler = StandardScaler()\\n'\n",
      " 'X_train = scaler.fit_transform(X_train)\\n'\n",
      " 'X_test = scaler.transform(X_test)\\n'\n",
      " '\\u200bsklearn.datasets.load_breast_cancer: ìœ ë°©ì•” ë°ì´í„°ì…‹ ë¡œë“œreturn_X_y=False: ë°ì´í„°ì™€ '\n",
      " 'íƒ€ê²Ÿì„ í•¨ê»˜ ë°˜í™˜í• ì§€ ì—¬ë¶€. ê¸°ë³¸ê°’ì€ Falseì…ë‹ˆë‹¤._X_y=False: ë°ì´í„°ì™€ íƒ€ê²Ÿì„ í•¨ê»˜ ë°˜í™˜í• ì§€ ì—¬ë¶€. ê¸°ë³¸ê°’ì€ '\n",
      " 'Falseì…ë‹ˆë‹¤.\\ufeff\\u200bsklearn.model_selection.train_test_split: ë°ì´í„°ë¥¼ í›ˆë ¨ ì„¸íŠ¸/ '\n",
      " 'í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë¡œ ë¶„í• test_size=0.2: í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì˜ ë¹„ìœ¨ì„ 0.2ë¡œ ì„¤ì •í•©ë‹ˆë‹¤._size=0.2: í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì˜ ë¹„ìœ¨ì„ 0.2ë¡œ '\n",
      " 'ì„¤ì •í•©ë‹ˆë‹¤.\\ufeff\\u200brandom_state=42: ëœë¤ ì‹œë“œ ê°’ìœ¼ë¡œ, ë°ì´í„° ë¶„í• ì˜ ì¬í˜„ì„±ì„ ìœ„í•´ '\n",
      " 'ì‚¬ìš©ë©ë‹ˆë‹¤._state=42: ëœë¤ ì‹œë“œ ê°’ìœ¼ë¡œ, ë°ì´í„° ë¶„í• ì˜ ì¬í˜„ì„±ì„ ìœ„í•´ '\n",
      " 'ì‚¬ìš©ë©ë‹ˆë‹¤.\\ufeff\\u200bsklearn.preprocessing.StandardScaler: ë°ì´í„°ì˜ í‰ê· ì„ 0, ë¶„ì‚°ì„ 1ë¡œ '\n",
      " 'ìŠ¤ì¼€ì¼ë§fit_transform(X_train): í›ˆë ¨ ì„¸íŠ¸ë¥¼ ìŠ¤ì¼€ì¼ë§í•˜ê³  ë³€í™˜í•©ë‹ˆë‹¤._transform(X_train): í›ˆë ¨ ì„¸íŠ¸ë¥¼ '\n",
      " 'ìŠ¤ì¼€ì¼ë§í•˜ê³  ë³€í™˜í•©ë‹ˆë‹¤.\\ufeff\\u200btransform(X_test): í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë¥¼ ë³€í™˜í•©ë‹ˆë‹¤.(X_test): í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë¥¼ '\n",
      " 'ë³€í™˜í•©ë‹ˆë‹¤.\\ufeff\\u200b ëª¨ë¸ í•™ìŠµëª¨ë¸ í•™ìŠµ {5px}ëª¨ë¸ í•™ìŠµ \\ufeff\\u200bPythonë³µì‚¬from '\n",
      " 'sklearn.svm import SVC\\n'\n",
      " 'from sklearn.metrics import accuracy_score, classification_report, '\n",
      " 'confusion_matrix\\n'\n",
      " '\\n'\n",
      " '# ëª¨ë¸ ìƒì„± ë° í•™ìŠµ\\n'\n",
      " \"model = SVC(kernel='linear')\\n\"\n",
      " 'model.fit(X_train, y_train)\\n'\n",
      " '# ì˜ˆì¸¡\\n'\n",
      " 'y_pred = model.predict(X_test)\\n'\n",
      " '# í‰ê°€\\n'\n",
      " 'print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\\n'\n",
      " 'print(f\"Classification Report:\")\\n'\n",
      " 'print(f\"Confusion Matrix:\")\\n'\n",
      " '\\u200bsklearn.svm.SVC: ì„œí¬íŠ¸ ë²¡í„° ë¨¸ì‹  ë¶„ë¥˜ ëª¨ë¸ ìƒì„±kernel=â€™linearâ€™: ì„ í˜• ì»¤ë„ì„ ì‚¬ìš©í•˜ì—¬ SVMì„ '\n",
      " 'í•™ìŠµí•©ë‹ˆë‹¤.=â€™linearâ€™: ì„ í˜• ì»¤ë„ì„ ì‚¬ìš©í•˜ì—¬ SVMì„ í•™ìŠµí•©ë‹ˆë‹¤.\\ufeff\\u200bfit(X_train, y_train): '\n",
      " 'ëª¨ë¸ì„ í›ˆë ¨ ì„¸íŠ¸ì— ë§ì¶”ì–´ í•™ìŠµì‹œí‚µë‹ˆë‹¤(X_train, y_train): ëª¨ë¸ì„ í›ˆë ¨ ì„¸íŠ¸ì— ë§ì¶”ì–´ '\n",
      " 'í•™ìŠµì‹œí‚µë‹ˆë‹¤\\ufeff\\u200bpredict(X_test): í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì— ëŒ€í•´ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.(X_test): í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì— ëŒ€í•´ '\n",
      " 'ì˜ˆì¸¡ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\\ufeff\\u200bsklearn.metrics.accuracy_score: ì •í™•ë„ '\n",
      " 'ê³„ì‚°accuracy_score(y_test, y_pred): ì‹¤ì œ ê°’ê³¼ ì˜ˆì¸¡ ê°’ì„ ë¹„êµí•˜ì—¬ ì •í™•ë„ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤._score(y_test, '\n",
      " 'y_pred): ì‹¤ì œ ê°’ê³¼ ì˜ˆì¸¡ ê°’ì„ ë¹„êµí•˜ì—¬ ì •í™•ë„ë¥¼ '\n",
      " 'ë°˜í™˜í•©ë‹ˆë‹¤.\\ufeff\\u200bsklearn.metrics.classification_report: ë¶„ë¥˜ ë³´ê³ ì„œ '\n",
      " 'ìƒì„±classification_report(y_test, y_pred): ì •í™•ë„, ì •ë°€ë„, ì¬í˜„ìœ¨ ë“±ì˜ ë©”íŠ¸ë¦­ì„ í¬í•¨í•œ ë³´ê³ ì„œë¥¼ '\n",
      " 'ì¶œë ¥í•©ë‹ˆë‹¤._report(y_test, y_pred): ì •í™•ë„, ì •ë°€ë„, ì¬í˜„ìœ¨ ë“±ì˜ ë©”íŠ¸ë¦­ì„ í¬í•¨í•œ ë³´ê³ ì„œë¥¼ '\n",
      " 'ì¶œë ¥í•©ë‹ˆë‹¤.\\ufeff\\u200bsklearn.metrics.confusion_matrix: í˜¼ë™ í–‰ë ¬ '\n",
      " 'ìƒì„±confusion_matrix(y_test, y_pred): ì‹¤ì œ ê°’ê³¼ ì˜ˆì¸¡ ê°’ì˜ í˜¼ë™ í–‰ë ¬ì„ ë°˜í™˜í•©ë‹ˆë‹¤._matrix(y_test, '\n",
      " 'y_pred): ì‹¤ì œ ê°’ê³¼ ì˜ˆì¸¡ ê°’ì˜ í˜¼ë™ í–‰ë ¬ì„ ë°˜í™˜í•©ë‹ˆë‹¤.\\ufeff\\u200b2) íƒ€ì´íƒ€ë‹‰ ë°ì´í„° ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬íƒ€ì´íƒ€ë‹‰ '\n",
      " 'ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ {5px}íƒ€ì´íƒ€ë‹‰ ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ \\ufeff\\u200bPythonë³µì‚¬import seaborn as '\n",
      " 'sns\\n'\n",
      " '\\n'\n",
      " '# ë°ì´í„° ë¡œë“œ\\n'\n",
      " \"titanic = sns.load_dataset('titanic')\\n\"\n",
      " '# í•„ìš”í•œ ì—´ ì„ íƒ ë° ê²°ì¸¡ê°’ ì²˜ë¦¬\\n'\n",
      " \"titanic = titanic[['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', \"\n",
      " \"'fare', 'embarked']].dropna()\\n\"\n",
      " '# ì„±ë³„ê³¼ íƒ‘ìŠ¹í•œ ê³³ ì¸ì½”ë”©\\n'\n",
      " \"titanic['sex'] = titanic['sex'].map({'male': 0, 'female': 1})\\n\"\n",
      " \"titanic['embarked'] = titanic['embarked'].map({'C': 0, 'Q': 1, 'S': 2})\\n\"\n",
      " '# íŠ¹ì„±ê³¼ íƒ€ê²Ÿ ë¶„ë¦¬\\n'\n",
      " \"X = titanic.drop('survived', axis=1)\\n\"\n",
      " \"y = titanic['survived']\\n\"\n",
      " '# ë°ì´í„° ë¶„í• \\n'\n",
      " 'X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, '\n",
      " 'random_state=42)\\n'\n",
      " '# ë°ì´í„° ìŠ¤ì¼€ì¼ë§\\n'\n",
      " 'scaler = StandardScaler()\\n'\n",
      " 'X_train = scaler.fit_transform(X_train)\\n'\n",
      " 'X_test = scaler.transform(X_test)\\n'\n",
      " '\\u200bseaborn.load_dataset: seabornì˜ ë‚´ì¥ ë°ì´í„°ì…‹ ë¡œë“œâ€™titanicâ€™: íƒ€ì´íƒ€ë‹‰ ë°ì´í„°ì…‹ì„ '\n",
      " 'ë¡œë“œí•©ë‹ˆë‹¤.â€™titanicâ€™: íƒ€ì´íƒ€ë‹‰ ë°ì´í„°ì…‹ì„ ë¡œë“œí•©ë‹ˆë‹¤.\\ufeff\\u200b pandas.DataFrame.dropna: ê²°ì¸¡ê°’ì´ '\n",
      " 'ìˆëŠ” í–‰ ì œê±°pandas.DataFrame.map: ë°ì´í„° ê°’ì„ ë‹¤ë¥¸ ê°’ìœ¼ë¡œ ë§¤í•‘â€™maleâ€™: 0, â€™femaleâ€™: 1: ì„±ë³„ì„ ìˆ«ìë¡œ '\n",
      " 'ë§¤í•‘í•©ë‹ˆë‹¤.: ì„±ë³„ì„ ìˆ«ìë¡œ ë§¤í•‘í•©ë‹ˆë‹¤.}â€™maleâ€™: 0, â€™femaleâ€™: 1: ì„±ë³„ì„ ìˆ«ìë¡œ '\n",
      " 'ë§¤í•‘í•©ë‹ˆë‹¤.\\ufeff\\u200bâ€™Câ€™: 0, â€™Qâ€™: 1, â€™Sâ€™: 2: íƒ‘ìŠ¹í•œ ê³³ì„ ìˆ«ìë¡œ ë§¤í•‘í•©ë‹ˆë‹¤.: íƒ‘ìŠ¹í•œ ê³³ì„ ìˆ«ìë¡œ '\n",
      " 'ë§¤í•‘í•©ë‹ˆë‹¤.}â€™Câ€™: 0, â€™Qâ€™: 1, â€™Sâ€™: 2: íƒ‘ìŠ¹í•œ ê³³ì„ ìˆ«ìë¡œ ë§¤í•‘í•©ë‹ˆë‹¤.\\ufeff\\u200b ëª¨ë¸ í•™ìŠµëª¨ë¸ í•™ìŠµ '\n",
      " '{5px}ëª¨ë¸ í•™ìŠµ \\ufeff\\u200bPythonë³µì‚¬# ëª¨ë¸ ìƒì„± ë° í•™ìŠµ\\n'\n",
      " \"model = SVC(kernel='linear')\\n\"\n",
      " 'model.fit(X_train, y_train)\\n'\n",
      " '# ì˜ˆì¸¡\\n'\n",
      " 'y_pred = model.predict(X_test)\\n'\n",
      " '# í‰ê°€\\n'\n",
      " 'print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\\n'\n",
      " 'print(f\"Classification Report:\")\\n'\n",
      " 'print(f\"Confusion Matrix:\")\\n'\n",
      " '\\u200bCopyright â“’ TeamSparta All rights reserved.')\n"
     ]
    }
   ],
   "source": [
    "# ê²°ê³¼ ì¶œë ¥\n",
    "pprint(txt_list[9])  # ë‘ ë²ˆì§¸ URLì˜ í…ìŠ¤íŠ¸ ë‚´ìš© ì¶œë ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì²­í¬ë¡œ ë‚˜ëˆ ì§„ í›„, ì²­í¬ì˜ ê°œìˆ˜: 421\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema import Document\n",
    "\n",
    "# 1. ë¡œë“œëœ ë¬¸ì„œ ì „ì²˜ë¦¬(ì²­í‚¹)\n",
    "docs = ''.join(txt_list)\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=20)\n",
    "str_splits = text_splitter.split_text(docs)\n",
    "\n",
    "# 2. ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸ë¥¼ Document ê°ì²´ë¡œ ë³€í™˜\n",
    "doc_splits = [Document(page_content=str) for str in str_splits]\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=doc_splits, embedding=OpenAIEmbeddings())\n",
    "print(f\"ì²­í¬ë¡œ ë‚˜ëˆ ì§„ í›„, ì²­í¬ì˜ ê°œìˆ˜: {len(doc_splits)}\")\n",
    "\n",
    "# # ìƒìœ„ 10ê°œì˜ ì²­í¬ ì¶œë ¥\n",
    "# print(\"Top 10 chunks:\")\n",
    "# for i, chunk in enumerate(doc_splits[:10], 1):\n",
    "#     pprint(f\"\\nChunk {i}:\\n{chunk.page_content}\")\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "prompt = ChatPromptTemplate.from_messages([(\"system\", \"\"\"\n",
    "    ë‹¹ì‹ ì€ AI ê°•ì‚¬ì…ë‹ˆë‹¤. ì•„ë˜ contextë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•˜ë‚˜ì˜ í€´ì¦ˆë¥¼ ë§Œë“¤ì–´ ì‚¬ìš©ìì˜ ëŒ€ë‹µì„ ê¸°ë‹¤ë¦¬ì„¸ìš”.\n",
    "    í€´ì¦ˆëŠ” ë³´ê¸°ê°€ ìˆëŠ” ê°ê´€ì‹ ë˜ëŠ” O,X í˜•íƒœë¡œ ì¶œì œí•´ì£¼ì„¸ìš”. (ì£¼ë¡œ ì½”ë“œ ë‚´ìš©ê³¼ ê´€ë ¨ëœ ë¬¸ì œë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤.)\n",
    "    ì´í›„, ì‚¬ìš©ìì˜ ëŒ€ë‹µì„ í™•ì¸í•˜ê³  ì•„ë˜ í˜•ì‹ì„ ë°”íƒ•ìœ¼ë¡œ í”¼ë“œë°±ì„ ì œê³µí•˜ì„¸ìš”:\n",
    "    - ì •ë‹µ ì—¬ë¶€: \"Në²ˆ\" ë˜ëŠ” \"ì˜ˆ/ì•„ë‹ˆì˜¤\"\n",
    "    - ì¶”ê°€ ì„¤ëª…: (ì •ë‹µê³¼ ê´€ë ¨ëœ ì¶”ê°€ ì •ë³´ë¥¼ ì œê³µí•˜ì„¸ìš”)\n",
    "    \n",
    "    Context: {context}\n",
    "    \"\"\")])\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "rag_chain = (\n",
    "        {\"context\": retriever | format_docs}\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í€´ì¦ˆ: ë‚˜ì´ë¸Œë² ì´ì¦ˆ ë¶„ë¥˜ëª¨ë¸ì— ëŒ€í•œ ì„¤ëª… ì¤‘ ì˜³ì€ ê²ƒì„ ê³ ë¥´ì„¸ìš”.\n",
      "\n",
      "1. ë‚˜ì´ë¸Œë² ì´ì¦ˆ ëª¨ë¸ì€ ëª¨ë“  ì…ë ¥ ë³€ìˆ˜ê°€ ì„œë¡œ ë…ë¦½ì ì´ë¼ê³  ê°€ì •í•œë‹¤.\n",
      "2. ë‚˜ì´ë¸Œë² ì´ì¦ˆ ëª¨ë¸ì€ ì—°ì†í˜• ë°ì´í„°ë§Œ ì²˜ë¦¬í•  ìˆ˜ ìˆë‹¤.\n",
      "3. ë‚˜ì´ë¸Œë² ì´ì¦ˆ ëª¨ë¸ì€ ë¹„ì§€ë„í•™ìŠµì— ì†í•œë‹¤.\n",
      "4. ë‚˜ì´ë¸Œë² ì´ì¦ˆ ëª¨ë¸ì€ ì£¼ë¡œ íšŒê·€ ë¬¸ì œì— ì‚¬ìš©ëœë‹¤.\n",
      "\n",
      "ì •ë‹µì„ 1, 2, 3, 4 ì¤‘ í•˜ë‚˜ë¡œ ì„ íƒí•´ ì£¼ì„¸ìš”!\n",
      "1\n",
      "Formatted Feedback Data:\n",
      "System: \n",
      "    AI ê°•ì‚¬ë¡œì„œ ë‹¤ìŒ í€´ì¦ˆì˜ ì •ë‹µ ì—¬ë¶€ë¥¼ í™•ì¸í•˜ê³  í”¼ë“œë°±ì„ ì œê³µí•˜ì„¸ìš”.\n",
      "    í”¼ë“œë°±ì€ ì•„ë˜ì™€ ê°™ì€ í˜•ì‹ì´ì–´ì•¼ í•©ë‹ˆë‹¤:\n",
      "    - ì •ë‹µ ì—¬ë¶€: \"Në²ˆ\" ë˜ëŠ” \"ì˜ˆ/ì•„ë‹ˆì˜¤\"\n",
      "    - ì¶”ê°€ ì„¤ëª…: (ì •ë‹µê³¼ ê´€ë ¨ëœ ì¶”ê°€ ì •ë³´ë¥¼ ì œê³µí•˜ì„¸ìš”)\n",
      "    í€´ì¦ˆ: í€´ì¦ˆ: ë‚˜ì´ë¸Œë² ì´ì¦ˆ ë¶„ë¥˜ëª¨ë¸ì— ëŒ€í•œ ì„¤ëª… ì¤‘ ì˜³ì€ ê²ƒì„ ê³ ë¥´ì„¸ìš”.\n",
      "\n",
      "1. ë‚˜ì´ë¸Œë² ì´ì¦ˆ ëª¨ë¸ì€ ëª¨ë“  ì…ë ¥ ë³€ìˆ˜ê°€ ì„œë¡œ ë…ë¦½ì ì´ë¼ê³  ê°€ì •í•œë‹¤.\n",
      "2. ë‚˜ì´ë¸Œë² ì´ì¦ˆ ëª¨ë¸ì€ ì—°ì†í˜• ë°ì´í„°ë§Œ ì²˜ë¦¬í•  ìˆ˜ ìˆë‹¤.\n",
      "3. ë‚˜ì´ë¸Œë² ì´ì¦ˆ ëª¨ë¸ì€ ë¹„ì§€ë„í•™ìŠµì— ì†í•œë‹¤.\n",
      "4. ë‚˜ì´ë¸Œë² ì´ì¦ˆ ëª¨ë¸ì€ ì£¼ë¡œ íšŒê·€ ë¬¸ì œì— ì‚¬ìš©ëœë‹¤.\n",
      "\n",
      "ì •ë‹µì„ 1, 2, 3, 4 ì¤‘ í•˜ë‚˜ë¡œ ì„ íƒí•´ ì£¼ì„¸ìš”!\n",
      "    ë‹µë³€: 1\n",
      "    ëŒ€í™” ê¸°ë¡: ['í€´ì¦ˆ: ë‚˜ì´ë¸Œë² ì´ì¦ˆ ë¶„ë¥˜ëª¨ë¸ì— ëŒ€í•œ ì„¤ëª… ì¤‘ ì˜³ì€ ê²ƒì„ ê³ ë¥´ì„¸ìš”.']\n",
      "    ê±°ì ˆ ì‚¬ìœ : None\n",
      "    \n",
      "Feedback:\n",
      "AIMessage(content='- ì •ë‹µ ì—¬ë¶€: \"1\"\\n- ì¶”ê°€ ì„¤ëª…: ë‚˜ì´ë¸Œë² ì´ì¦ˆ ëª¨ë¸ì€ ë² ì´ì¦ˆ ì •ë¦¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•˜ë©°, ëª¨ë“  ì…ë ¥ ë³€ìˆ˜ê°€ ì„œë¡œ ë…ë¦½ì ì´ë¼ëŠ” ê°€ì •ì„ í•©ë‹ˆë‹¤. ì´ ê°€ì •ì€ \"ë‚˜ì´ë¸Œ(naive)\"ë¼ëŠ” ì´ë¦„ì˜ ìœ ë˜ì´ê¸°ë„ í•©ë‹ˆë‹¤. ë‚˜ì´ë¸Œë² ì´ì¦ˆëŠ” ì£¼ë¡œ ë¶„ë¥˜ ë¬¸ì œì— ì‚¬ìš©ë˜ë©°, ì´ë¡ ì ìœ¼ë¡œëŠ” ì—°ì†í˜• ë°ì´í„°ì™€ ë²”ì£¼í˜• ë°ì´í„° ëª¨ë‘ ì²˜ë¦¬í•  ìˆ˜ ìˆì§€ë§Œ, ì¼ë°˜ì ìœ¼ë¡œëŠ” ë²”ì£¼í˜• ë°ì´í„°ì— ë” ì í•©í•©ë‹ˆë‹¤. ë¹„ì§€ë„í•™ìŠµì´ ì•„ë‹Œ ì§€ë„í•™ìŠµì— ì†í•˜ë©°, íšŒê·€ ë¬¸ì œì—ëŠ” ë³´í†µ ì‚¬ìš©ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 136, 'prompt_tokens': 266, 'total_tokens': 402, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0705bf87c0', 'finish_reason': 'stop', 'logprobs': None}, id='run-884fabee-d1af-48ac-a9c9-0c7ac373cfcf-0', usage_metadata={'input_tokens': 266, 'output_tokens': 136, 'total_tokens': 402, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})\n",
      "í€´ì¦ˆ: ë‚˜ì´ë¸Œë² ì´ì¦ˆ ë¶„ë¥˜ëª¨ë¸ì— ëŒ€í•œ ì„¤ëª…ì…ë‹ˆë‹¤. ë‚˜ì´ë¸Œë² ì´ì¦ˆëŠ” ì–´ë–¤ ê°€ì •ì„ ê¸°ë°˜ìœ¼ë¡œ í•˜ëŠ” ë¶„ë¥˜ ì•Œê³ ë¦¬ì¦˜ì¸ê°€ìš”?\n",
      "\n",
      "A) ëª¨ë“  í”¼ì²˜ê°€ ì„œë¡œ ë…ë¦½ì ì´ë‹¤.  \n",
      "B) í”¼ì²˜ ê°„ì˜ ìƒê´€ê´€ê³„ê°€ ì¡´ì¬í•œë‹¤.  \n",
      "C) ëª¨ë“  í”¼ì²˜ê°€ ë™ì¼í•œ ì¤‘ìš”ë„ë¥¼ ê°€ì§„ë‹¤.  \n",
      "D) í”¼ì²˜ì˜ ë¶„í¬ê°€ ì •ê·œë¶„í¬ë¥¼ ë”°ë¥¸ë‹¤.  \n",
      "\n",
      "ì •ë‹µì„ ì„ íƒí•´ ì£¼ì„¸ìš”. (A, B, C, D ì¤‘ í•˜ë‚˜)\n",
      "1\n",
      "Formatted Feedback Data:\n",
      "System: \n",
      "    AI ê°•ì‚¬ë¡œì„œ ë‹¤ìŒ í€´ì¦ˆì˜ ì •ë‹µ ì—¬ë¶€ë¥¼ í™•ì¸í•˜ê³  í”¼ë“œë°±ì„ ì œê³µí•˜ì„¸ìš”.\n",
      "    í”¼ë“œë°±ì€ ì•„ë˜ì™€ ê°™ì€ í˜•ì‹ì´ì–´ì•¼ í•©ë‹ˆë‹¤:\n",
      "    - ì •ë‹µ ì—¬ë¶€: \"Në²ˆ\" ë˜ëŠ” \"ì˜ˆ/ì•„ë‹ˆì˜¤\"\n",
      "    - ì¶”ê°€ ì„¤ëª…: (ì •ë‹µê³¼ ê´€ë ¨ëœ ì¶”ê°€ ì •ë³´ë¥¼ ì œê³µí•˜ì„¸ìš”)\n",
      "    í€´ì¦ˆ: í€´ì¦ˆ: ë‚˜ì´ë¸Œë² ì´ì¦ˆ ë¶„ë¥˜ëª¨ë¸ì— ëŒ€í•œ ì„¤ëª…ì…ë‹ˆë‹¤. ë‚˜ì´ë¸Œë² ì´ì¦ˆëŠ” ì–´ë–¤ ê°€ì •ì„ ê¸°ë°˜ìœ¼ë¡œ í•˜ëŠ” ë¶„ë¥˜ ì•Œê³ ë¦¬ì¦˜ì¸ê°€ìš”?\n",
      "\n",
      "A) ëª¨ë“  í”¼ì²˜ê°€ ì„œë¡œ ë…ë¦½ì ì´ë‹¤.  \n",
      "B) í”¼ì²˜ ê°„ì˜ ìƒê´€ê´€ê³„ê°€ ì¡´ì¬í•œë‹¤.  \n",
      "C) ëª¨ë“  í”¼ì²˜ê°€ ë™ì¼í•œ ì¤‘ìš”ë„ë¥¼ ê°€ì§„ë‹¤.  \n",
      "D) í”¼ì²˜ì˜ ë¶„í¬ê°€ ì •ê·œë¶„í¬ë¥¼ ë”°ë¥¸ë‹¤.  \n",
      "\n",
      "ì •ë‹µì„ ì„ íƒí•´ ì£¼ì„¸ìš”. (A, B, C, D ì¤‘ í•˜ë‚˜)\n",
      "    ë‹µë³€: 1\n",
      "    ëŒ€í™” ê¸°ë¡: ['í€´ì¦ˆ: ë‚˜ì´ë¸Œë² ì´ì¦ˆ ë¶„ë¥˜ëª¨ë¸ì— ëŒ€í•œ ì„¤ëª… ì¤‘ ì˜³ì€ ê²ƒì„ ê³ ë¥´ì„¸ìš”.', 'í€´ì¦ˆ: ë‚˜ì´ë¸Œë² ì´ì¦ˆ ë¶„ë¥˜ëª¨ë¸ì— ëŒ€í•œ ì„¤ëª…ì…ë‹ˆë‹¤. ë‚˜ì´ë¸Œë² ì´ì¦ˆëŠ” ì–´ë–¤ ê°€ì •ì„ ê¸°ë°˜ìœ¼ë¡œ í•˜ëŠ” ë¶„ë¥˜ ì•Œê³ ë¦¬ì¦˜ì¸ê°€ìš”?']\n",
      "    ê±°ì ˆ ì‚¬ìœ : None\n",
      "    \n",
      "Feedback:\n",
      "AIMessage(content='- ì •ë‹µ ì—¬ë¶€: \"A\"\\n- ì¶”ê°€ ì„¤ëª…: ë‚˜ì´ë¸Œë² ì´ì¦ˆ ë¶„ë¥˜ëª¨ë¸ì€ \"ëª¨ë“  í”¼ì²˜ê°€ ì„œë¡œ ë…ë¦½ì ì´ë‹¤\"ë¼ëŠ” ê°€ì •ì„ ê¸°ë°˜ìœ¼ë¡œ í•©ë‹ˆë‹¤. ì´ ê°€ì •ì€ ì‹¤ì œ ë°ì´í„°ì—ì„œëŠ” í•­ìƒ ì„±ë¦½í•˜ì§€ ì•Šì„ ìˆ˜ ìˆì§€ë§Œ, ë‚˜ì´ë¸Œë² ì´ì¦ˆëŠ” ì´ ê°€ì •ì„ í†µí•´ ê³„ì‚°ì„ ë‹¨ìˆœí™”í•˜ê³  íš¨ìœ¨ì ì¸ ë¶„ë¥˜ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤. í”¼ì²˜ ê°„ì˜ ë…ë¦½ì„±ì„ ê°€ì •í•¨ìœ¼ë¡œì¨, ë‚˜ì´ë¸Œë² ì´ì¦ˆëŠ” ê° í”¼ì²˜ì˜ ì¡°ê±´ë¶€ í™•ë¥ ì„ ê³±í•˜ì—¬ ì „ì²´ í™•ë¥ ì„ ê³„ì‚°í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 128, 'prompt_tokens': 297, 'total_tokens': 425, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0705bf87c0', 'finish_reason': 'stop', 'logprobs': None}, id='run-ac9cc90e-e045-4faf-98f5-572a790c8a6b-0', usage_metadata={'input_tokens': 297, 'output_tokens': 128, 'total_tokens': 425, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})\n",
      "í€´ì¦ˆ: ë‚˜ì´ë¸Œë² ì´ì¦ˆ ë¶„ë¥˜ ëª¨ë¸ì—ì„œ 'ë‚˜ì´ë¸Œ'ë¼ëŠ” ìš©ì–´ëŠ” ì–´ë–¤ ì˜ë¯¸ë¥¼ ê°€ì§€ê³  ìˆë‚˜ìš”? ë‹¤ìŒ ë³´ê¸° ì¤‘ì—ì„œ ì˜¬ë°”ë¥¸ ì„¤ëª…ì„ ì„ íƒí•˜ì„¸ìš”.\n",
      "\n",
      "1. ëª¨ë“  íŠ¹ì„±ì´ ì„œë¡œ ë…ë¦½ì ì´ë‹¤.\n",
      "2. ëª¨ë“  íŠ¹ì„±ì´ ì„œë¡œ ì˜ì¡´ì ì´ë‹¤.\n",
      "3. íŠ¹ì„±ì´ ì—°ì†ì ì´ë‹¤.\n",
      "4. íŠ¹ì„±ì´ ë²”ì£¼í˜•ì´ë‹¤.\n",
      "\n",
      "ì‚¬ìš©ìì˜ ëŒ€ë‹µì„ ê¸°ë‹¤ë¦¬ê² ìŠµë‹ˆë‹¤!\n",
      "ëŒ€í™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# í´ë” ì´ë¦„\n",
    "folder_name = \"previous_conversation\"\n",
    "\n",
    "# í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "# íŒŒì¼ ì´ë¦„ì— íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ê°€\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")  # \"20241126_153045\" í˜•ì‹\n",
    "file_name = f\"conversation_log_{timestamp}.txt\"\n",
    "file_path = os.path.join(folder_name, file_name)\n",
    "\n",
    "quiz_list = []\n",
    "\n",
    "# ëŒ€í™” ì§„í–‰\n",
    "while True:\n",
    "    # 1. í€´ì¦ˆ ìƒì„±\n",
    "    quiz = rag_chain.invoke(\"í€´ì¦ˆë¥¼ ì‹œì‘í•˜ì„¸ìš”.\")\n",
    "    quiz_list.append(quiz)\n",
    "    print(quiz)\n",
    "    \n",
    "    # 2. ì‚¬ìš©ì ë‹µë³€ ìˆ˜ì§‘\n",
    "    user_answer = input(\"ë‹µë³€ì„ ì…ë ¥í•˜ì„¸ìš”: \")\n",
    "    if user_answer.strip().lower() == \"exit\":\n",
    "        print(\"ëŒ€í™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.\")\n",
    "        break\n",
    "    print(user_answer)\n",
    "\n",
    "    # ì´ì „ ëŒ€í™” ë‚´ìš© ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            previous_conversation = f.read()\n",
    "    else:\n",
    "        previous_conversation = \"\"  # íŒŒì¼ì´ ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´ë¡œ ì‹œì‘\n",
    "\n",
    "    # 'í€´ì¦ˆ:'ë¡œ ì‹œì‘í•˜ëŠ” ë‚´ìš©ë§Œ ì¶”ì¶œ\n",
    "    quiz_pattern = r\"í€´ì¦ˆ: .*\"\n",
    "    all_quizzes = \"\\n\".join(quiz_list)  # ë¦¬ìŠ¤íŠ¸ë¥¼ ë¬¸ìì—´ë¡œ ê²°í•©\n",
    "    quiz_onlys = re.findall(quiz_pattern, all_quizzes)  # ë¬¸ìì—´ì—ì„œ ê²€ìƒ‰\n",
    "\n",
    "    # # í•„ìš”í•œ ë¶€ë¶„ ì¶œë ¥\n",
    "    # print(\"ì¶”ì¶œëœ í€´ì¦ˆ:\")\n",
    "    # for quiz_only in quiz_onlys:\n",
    "    #     print(quiz_only)\n",
    "    \n",
    "    # 3. ì‚¬ìš©ì ë‹µë³€ì— ëŒ€í•œ í”¼ë“œë°± ìƒì„±\n",
    "    feedback_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", f\"\"\"\n",
    "    AI ê°•ì‚¬ë¡œì„œ ë‹¤ìŒ í€´ì¦ˆì˜ ì •ë‹µ ì—¬ë¶€ë¥¼ í™•ì¸í•˜ê³  í”¼ë“œë°±ì„ ì œê³µí•˜ì„¸ìš”.\n",
    "    í”¼ë“œë°±ì€ ì•„ë˜ì™€ ê°™ì€ í˜•ì‹ì´ì–´ì•¼ í•©ë‹ˆë‹¤:\n",
    "    - ì •ë‹µ ì—¬ë¶€: \"Në²ˆ\" ë˜ëŠ” \"ì˜ˆ/ì•„ë‹ˆì˜¤\"\n",
    "    - ì¶”ê°€ ì„¤ëª…: (ì •ë‹µê³¼ ê´€ë ¨ëœ ì¶”ê°€ ì •ë³´ë¥¼ ì œê³µí•˜ì„¸ìš”)\n",
    "    í€´ì¦ˆ: {{quiz}}\n",
    "    ë‹µë³€: {{answer}}\n",
    "    ëŒ€í™” ê¸°ë¡: {{quiz_onlys}}\n",
    "    ê±°ì ˆ ì‚¬ìœ : {{refusal}}\n",
    "    \"\"\")\n",
    "    ])\n",
    "\n",
    "    # í”¼ë“œë°± ìƒì„± - í‚¤ì›Œë“œ ì¸ìˆ˜ë¡œ ì „ë‹¬\n",
    "    feedback_data = feedback_prompt.format(\n",
    "        quiz=quiz,\n",
    "        answer=user_answer,\n",
    "        quiz_onlys=quiz_onlys,\n",
    "        refusal=\"None\"\n",
    "    )\n",
    "\n",
    "    # format ê²°ê³¼ë¥¼ í™•ì¸\n",
    "    print(\"Formatted Feedback Data:\")\n",
    "    print(feedback_data)\n",
    "\n",
    "    # í”¼ë“œë°± ì²´ì¸ í˜¸ì¶œ\n",
    "    feedback = llm.invoke(feedback_data)   # LLMì„ ì§ì ‘ í˜¸ì¶œí•˜ì—¬ í”¼ë“œë°± ìƒì„±\n",
    "    \n",
    "    print(\"Feedback:\")\n",
    "    pprint(feedback)\n",
    "    \n",
    "    # ëŒ€í™” ë‚´ìš© ì €ì¥(íŒŒì¼ì— ê¸°ë¡)\n",
    "    with open(file_path, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"Quiz: {quiz}\\n\")\n",
    "        f.write(f\"User Answer: {user_answer}\\n\")\n",
    "        f.write(f\"Feedback: {feedback}\\n\")\n",
    "        f.write(\"-\" * 50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI_boot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
