{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 코드 수정\n",
    "- 리뷰에 제공해주신 코드를 바탕으로 코드를 다시 수정했습니다.   \n",
    "```python\n",
    "quiz_list = []\n",
    "\n",
    "# 대화 진행\n",
    "while True:\n",
    "    # 1. 퀴즈 생성\n",
    "    quiz = rag_chain.invoke(\"퀴즈를 시작하세요.\")\n",
    "# '퀴즈:'로 시작하는 내용만 추출\n",
    "    quiz_pattern = r\"퀴즈: .*\"\n",
    "    all_quizzes = \"\\n\".join(quiz_list)  # 리스트를 문자열로 결합\n",
    "    quiz_onlys = re.findall(quiz_pattern, all_quizzes)  # 문자열에서 검색\n",
    "```\n",
    "\n",
    "- 내용을 추출해오는 곳을 previous_conversation에서 quiz_list로 바꿨습니다.\n",
    "```python\n",
    "# '퀴즈:'로 시작하는 내용만 추출\n",
    "quiz_pattern = r\"퀴즈: .*\"\n",
    "all_quizzes = \"\\n\".join(quiz_list)  # 리스트를 문자열로 결합\n",
    "quiz_onlys = re.findall(quiz_pattern, all_quizzes)  # 문자열에서 검색\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from pprint import pprint\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import re\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# .env 파일에서 환경변수 로드\n",
    "load_dotenv(\"C:/.env\")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# Selenium 옵션 설정 (헤드리스 모드로 실행)\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")  # 브라우저 창을 띄우지 않음\n",
    "chrome_options.add_argument(\"--disable-gpu\")  # GPU 비활성화 (일부 환경에서 필요)\n",
    "\n",
    "# WebDriver 경로 설정 (자동 설치)\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "\n",
    "url_list=[]\n",
    "txt_list=[]\n",
    "\n",
    "# 환경변수에 저장된 URL 로드\n",
    "for i in range(1, 17):  # URL_1 ~ URL_16\n",
    "    url = os.getenv(f\"URL_{i}\")\n",
    "    if url:  # 환경변수가 존재하면 추가\n",
    "        url_list.append(url)\n",
    "\n",
    "# 웹페이지 요청\n",
    "for url in url_list:\n",
    "    driver.get(url)  # 페이지 로드\n",
    "\n",
    "    # 특정 요소가 로드될 때까지 기다림 (예: Notion 페이지에서 주요 콘텐츠가 담길 요소)\n",
    "    try:\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, \".notion-page-content\"))\n",
    "        )\n",
    "    except TimeoutException:\n",
    "        print(f\"페이지 로딩 실패: {url}\")\n",
    "        continue\n",
    "    \n",
    "    # 토글이 닫혀 있으면 토글을 열기\n",
    "    try:\n",
    "        # 모든 토글 버튼을 찾음 (Ctrl+Alt+T에 해당하는 토글을 찾아서 열기)\n",
    "        toggle_buttons = driver.find_elements(By.XPATH, \"//div[@role='button' and contains(@aria-label, '열기')]\")\n",
    "        \n",
    "        # 각 토글을 클릭하여 열기\n",
    "        for button in toggle_buttons:\n",
    "            button.click()\n",
    "            time.sleep(1)  # 토글이 열리기 전에 잠깐 대기\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"토글을 여는 데 실패했습니다: {e}\")\n",
    "\n",
    "    # 페이지의 HTML 가져오기\n",
    "    html_code = driver.page_source\n",
    "\n",
    "    # BeautifulSoup으로 HTML 파싱\n",
    "    soup = BeautifulSoup(html_code, 'html.parser')\n",
    "\n",
    "    txt = soup.get_text()\n",
    "\n",
    "    # 1. \\xa0를 공백으로 변환\n",
    "    txt = txt.replace('\\xa0', ' ')\n",
    "\n",
    "    # 2. 정규식을 사용해 \\\\로 시작하는 LaTeX 명령어 제거\n",
    "    txt = re.sub(r'\\\\[a-zA-Z]+\\{.*?\\}', '', txt)  # \\command{...} 형식 제거\n",
    "    txt = re.sub(r'\\\\[a-zA-Z]+', '', txt)        # \\command 형식 제거\n",
    "\n",
    "    # 3. 불필요한 공백 제거 (코드 개행 유지를 위해 주석처리)\n",
    "    # txt = re.sub(r'\\s+', ' ', txt).strip()\n",
    "\n",
    "    # 텍스트만 가져오기\n",
    "    txt_list.append(txt)\n",
    "\n",
    "\n",
    "driver.quit()  # 브라우저 종료"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('[스파르타코딩클럽] 10강. 지도학습 : 분류모델 - SVM[SCC] 바닥부터 시작하는 머신러닝/[스파르타코딩클럽] 바닥부터 시작하는 '\n",
      " '머신러닝 - 3주차/[스파르타코딩클럽] 10강. 지도학습 : 분류모델 - SVM제작:[스파르타코딩클럽] 10강. 지도학습 : 분류모델 - '\n",
      " 'SVM[수업 목표]SVM(Support Vector Machine)에 대한 개념을 배우고, 데이터를 이용해 실습해 봅니다[목차]01. '\n",
      " 'SVM 개념02. SVM 실습💡모든 토글을 열고 닫는 단축키\\n'\n",
      " 'Windows : Ctrl + alt + t \\n'\n",
      " 'Mac : ⌘ + ⌥ + t 01. SVM 개념✔️SVM이 무엇인지 알아봅시다1) SVM SVM이란?서포트 벡터 머신(SVM)은 분류와 '\n",
      " '회귀 분석에 사용되는 강력한 지도학습 모델데이터를 분류하기 위해 결정 경계(결정 초평면, hyperplane)를 찾아 분류합니다.초평면은 '\n",
      " '두 클래스 사이의 최대 마진을 보장하는 방식으로 선택합니다.ALT마진 : 두 클래스 간의 가장 가까운 데이터 포인트 사이의 거리마진 : '\n",
      " '두 클래스 간의 가장 가까운 데이터 포인트 사이의 거리\\ufeff\\n'\n",
      " '서포트 벡터 : 결정 초평면에 가장 가까이 위치한 데이터 포인트 - 결정 초평면을 정의합니다서포트 벡터 : 결정 초평면에 가장 가까이 '\n",
      " '위치한 데이터 포인트 - 결정 초평면을 정의합니다\\ufeff\\n'\n",
      " '커널 함수 : 데이터를 더 높은 차원으로 매핑하여 선형적으로 분리 할 수 없는 데이터를 분리하게 합니다. 커널 함수 : 데이터를 더 높은 '\n",
      " '차원으로 매핑하여 선형적으로 분리 할 수 없는 데이터를 분리하게 합니다. \\ufeff\\u200b SVM의 목적SVM의 목표는 마진을 '\n",
      " '최대화하면서 결정 초평면을 찾아 데이터 포인트를 정확하게 분류하는 것입니다. 이는 일반화 성능을 높이는 데 도움을 '\n",
      " '줍니다.w⋅x−b=0   - b = 0 w⋅x−b=0여기서 w는 가중치 벡터, x는 입력 벡터, b는 절편입니다.\\\\)는 가중치 벡터, '\n",
      " '\\\\(\\\\)는 입력 벡터, \\\\(b\\\\)는 절편입니다.}여기서 w는 가중치 벡터, x는 입력 벡터, b는 '\n",
      " '절편입니다.\\ufeff\\u200b02. SVM 실습✔️Scikit-learn의 유방암데이터와 Seaborn의 타이타닉 데이터로 SVM '\n",
      " '실습을 진행합니다1) 유방암 데이터 데이터 로드 및 전처리유방암 데이터 로드 및 전처리 {5px}유방암 데이터 로드 및 전처리 '\n",
      " '\\ufeff\\u200bPython복사import numpy as np\\n'\n",
      " 'import pandas as pd\\n'\n",
      " 'from sklearn.datasets import load_breast_cancer\\n'\n",
      " 'from sklearn.model_selection import train_test_split\\n'\n",
      " 'from sklearn.preprocessing import StandardScaler\\n'\n",
      " '\\n'\n",
      " '# 데이터 로드\\n'\n",
      " 'data = load_breast_cancer()\\n'\n",
      " 'X = data.data\\n'\n",
      " 'y = data.target\\n'\n",
      " '\\n'\n",
      " '# 데이터 분할\\n'\n",
      " 'X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, '\n",
      " 'random_state=42)\\n'\n",
      " '# 데이터 스케일링\\n'\n",
      " 'scaler = StandardScaler()\\n'\n",
      " 'X_train = scaler.fit_transform(X_train)\\n'\n",
      " 'X_test = scaler.transform(X_test)\\n'\n",
      " '\\u200bsklearn.datasets.load_breast_cancer: 유방암 데이터셋 로드return_X_y=False: 데이터와 '\n",
      " '타겟을 함께 반환할지 여부. 기본값은 False입니다._X_y=False: 데이터와 타겟을 함께 반환할지 여부. 기본값은 '\n",
      " 'False입니다.\\ufeff\\u200bsklearn.model_selection.train_test_split: 데이터를 훈련 세트/ '\n",
      " '테스트 세트로 분할test_size=0.2: 테스트 세트의 비율을 0.2로 설정합니다._size=0.2: 테스트 세트의 비율을 0.2로 '\n",
      " '설정합니다.\\ufeff\\u200brandom_state=42: 랜덤 시드 값으로, 데이터 분할의 재현성을 위해 '\n",
      " '사용됩니다._state=42: 랜덤 시드 값으로, 데이터 분할의 재현성을 위해 '\n",
      " '사용됩니다.\\ufeff\\u200bsklearn.preprocessing.StandardScaler: 데이터의 평균을 0, 분산을 1로 '\n",
      " '스케일링fit_transform(X_train): 훈련 세트를 스케일링하고 변환합니다._transform(X_train): 훈련 세트를 '\n",
      " '스케일링하고 변환합니다.\\ufeff\\u200btransform(X_test): 테스트 세트를 변환합니다.(X_test): 테스트 세트를 '\n",
      " '변환합니다.\\ufeff\\u200b 모델 학습모델 학습 {5px}모델 학습 \\ufeff\\u200bPython복사from '\n",
      " 'sklearn.svm import SVC\\n'\n",
      " 'from sklearn.metrics import accuracy_score, classification_report, '\n",
      " 'confusion_matrix\\n'\n",
      " '\\n'\n",
      " '# 모델 생성 및 학습\\n'\n",
      " \"model = SVC(kernel='linear')\\n\"\n",
      " 'model.fit(X_train, y_train)\\n'\n",
      " '# 예측\\n'\n",
      " 'y_pred = model.predict(X_test)\\n'\n",
      " '# 평가\\n'\n",
      " 'print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\\n'\n",
      " 'print(f\"Classification Report:\")\\n'\n",
      " 'print(f\"Confusion Matrix:\")\\n'\n",
      " '\\u200bsklearn.svm.SVC: 서포트 벡터 머신 분류 모델 생성kernel=’linear’: 선형 커널을 사용하여 SVM을 '\n",
      " '학습합니다.=’linear’: 선형 커널을 사용하여 SVM을 학습합니다.\\ufeff\\u200bfit(X_train, y_train): '\n",
      " '모델을 훈련 세트에 맞추어 학습시킵니다(X_train, y_train): 모델을 훈련 세트에 맞추어 '\n",
      " '학습시킵니다\\ufeff\\u200bpredict(X_test): 테스트 세트에 대해 예측을 수행합니다.(X_test): 테스트 세트에 대해 '\n",
      " '예측을 수행합니다.\\ufeff\\u200bsklearn.metrics.accuracy_score: 정확도 '\n",
      " '계산accuracy_score(y_test, y_pred): 실제 값과 예측 값을 비교하여 정확도를 반환합니다._score(y_test, '\n",
      " 'y_pred): 실제 값과 예측 값을 비교하여 정확도를 '\n",
      " '반환합니다.\\ufeff\\u200bsklearn.metrics.classification_report: 분류 보고서 '\n",
      " '생성classification_report(y_test, y_pred): 정확도, 정밀도, 재현율 등의 메트릭을 포함한 보고서를 '\n",
      " '출력합니다._report(y_test, y_pred): 정확도, 정밀도, 재현율 등의 메트릭을 포함한 보고서를 '\n",
      " '출력합니다.\\ufeff\\u200bsklearn.metrics.confusion_matrix: 혼동 행렬 '\n",
      " '생성confusion_matrix(y_test, y_pred): 실제 값과 예측 값의 혼동 행렬을 반환합니다._matrix(y_test, '\n",
      " 'y_pred): 실제 값과 예측 값의 혼동 행렬을 반환합니다.\\ufeff\\u200b2) 타이타닉 데이터 데이터 로드 및 전처리타이타닉 '\n",
      " '데이터 로드 및 전처리 {5px}타이타닉 데이터 로드 및 전처리 \\ufeff\\u200bPython복사import seaborn as '\n",
      " 'sns\\n'\n",
      " '\\n'\n",
      " '# 데이터 로드\\n'\n",
      " \"titanic = sns.load_dataset('titanic')\\n\"\n",
      " '# 필요한 열 선택 및 결측값 처리\\n'\n",
      " \"titanic = titanic[['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', \"\n",
      " \"'fare', 'embarked']].dropna()\\n\"\n",
      " '# 성별과 탑승한 곳 인코딩\\n'\n",
      " \"titanic['sex'] = titanic['sex'].map({'male': 0, 'female': 1})\\n\"\n",
      " \"titanic['embarked'] = titanic['embarked'].map({'C': 0, 'Q': 1, 'S': 2})\\n\"\n",
      " '# 특성과 타겟 분리\\n'\n",
      " \"X = titanic.drop('survived', axis=1)\\n\"\n",
      " \"y = titanic['survived']\\n\"\n",
      " '# 데이터 분할\\n'\n",
      " 'X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, '\n",
      " 'random_state=42)\\n'\n",
      " '# 데이터 스케일링\\n'\n",
      " 'scaler = StandardScaler()\\n'\n",
      " 'X_train = scaler.fit_transform(X_train)\\n'\n",
      " 'X_test = scaler.transform(X_test)\\n'\n",
      " '\\u200bseaborn.load_dataset: seaborn의 내장 데이터셋 로드’titanic’: 타이타닉 데이터셋을 '\n",
      " '로드합니다.’titanic’: 타이타닉 데이터셋을 로드합니다.\\ufeff\\u200b pandas.DataFrame.dropna: 결측값이 '\n",
      " '있는 행 제거pandas.DataFrame.map: 데이터 값을 다른 값으로 매핑’male’: 0, ’female’: 1: 성별을 숫자로 '\n",
      " '매핑합니다.: 성별을 숫자로 매핑합니다.}’male’: 0, ’female’: 1: 성별을 숫자로 '\n",
      " '매핑합니다.\\ufeff\\u200b’C’: 0, ’Q’: 1, ’S’: 2: 탑승한 곳을 숫자로 매핑합니다.: 탑승한 곳을 숫자로 '\n",
      " '매핑합니다.}’C’: 0, ’Q’: 1, ’S’: 2: 탑승한 곳을 숫자로 매핑합니다.\\ufeff\\u200b 모델 학습모델 학습 '\n",
      " '{5px}모델 학습 \\ufeff\\u200bPython복사# 모델 생성 및 학습\\n'\n",
      " \"model = SVC(kernel='linear')\\n\"\n",
      " 'model.fit(X_train, y_train)\\n'\n",
      " '# 예측\\n'\n",
      " 'y_pred = model.predict(X_test)\\n'\n",
      " '# 평가\\n'\n",
      " 'print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\\n'\n",
      " 'print(f\"Classification Report:\")\\n'\n",
      " 'print(f\"Confusion Matrix:\")\\n'\n",
      " '\\u200bCopyright ⓒ TeamSparta All rights reserved.')\n"
     ]
    }
   ],
   "source": [
    "# 결과 출력\n",
    "pprint(txt_list[9])  # 두 번째 URL의 텍스트 내용 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "청크로 나눠진 후, 청크의 개수: 421\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema import Document\n",
    "\n",
    "# 1. 로드된 문서 전처리(청킹)\n",
    "docs = ''.join(txt_list)\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=20)\n",
    "str_splits = text_splitter.split_text(docs)\n",
    "\n",
    "# 2. 문자열 리스트를 Document 객체로 변환\n",
    "doc_splits = [Document(page_content=str) for str in str_splits]\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=doc_splits, embedding=OpenAIEmbeddings())\n",
    "print(f\"청크로 나눠진 후, 청크의 개수: {len(doc_splits)}\")\n",
    "\n",
    "# # 상위 10개의 청크 출력\n",
    "# print(\"Top 10 chunks:\")\n",
    "# for i, chunk in enumerate(doc_splits[:10], 1):\n",
    "#     pprint(f\"\\nChunk {i}:\\n{chunk.page_content}\")\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "prompt = ChatPromptTemplate.from_messages([(\"system\", \"\"\"\n",
    "    당신은 AI 강사입니다. 아래 context를 기반으로 하나의 퀴즈를 만들어 사용자의 대답을 기다리세요.\n",
    "    퀴즈는 보기가 있는 객관식 또는 O,X 형태로 출제해주세요. (주로 코드 내용과 관련된 문제를 추천합니다.)\n",
    "    이후, 사용자의 대답을 확인하고 아래 형식을 바탕으로 피드백을 제공하세요:\n",
    "    - 정답 여부: \"N번\" 또는 \"예/아니오\"\n",
    "    - 추가 설명: (정답과 관련된 추가 정보를 제공하세요)\n",
    "    \n",
    "    Context: {context}\n",
    "    \"\"\")])\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "rag_chain = (\n",
    "        {\"context\": retriever | format_docs}\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "퀴즈: 나이브베이즈 분류모델에 대한 설명 중 옳은 것을 고르세요.\n",
      "\n",
      "1. 나이브베이즈 모델은 모든 입력 변수가 서로 독립적이라고 가정한다.\n",
      "2. 나이브베이즈 모델은 연속형 데이터만 처리할 수 있다.\n",
      "3. 나이브베이즈 모델은 비지도학습에 속한다.\n",
      "4. 나이브베이즈 모델은 주로 회귀 문제에 사용된다.\n",
      "\n",
      "정답을 1, 2, 3, 4 중 하나로 선택해 주세요!\n",
      "1\n",
      "Formatted Feedback Data:\n",
      "System: \n",
      "    AI 강사로서 다음 퀴즈의 정답 여부를 확인하고 피드백을 제공하세요.\n",
      "    피드백은 아래와 같은 형식이어야 합니다:\n",
      "    - 정답 여부: \"N번\" 또는 \"예/아니오\"\n",
      "    - 추가 설명: (정답과 관련된 추가 정보를 제공하세요)\n",
      "    퀴즈: 퀴즈: 나이브베이즈 분류모델에 대한 설명 중 옳은 것을 고르세요.\n",
      "\n",
      "1. 나이브베이즈 모델은 모든 입력 변수가 서로 독립적이라고 가정한다.\n",
      "2. 나이브베이즈 모델은 연속형 데이터만 처리할 수 있다.\n",
      "3. 나이브베이즈 모델은 비지도학습에 속한다.\n",
      "4. 나이브베이즈 모델은 주로 회귀 문제에 사용된다.\n",
      "\n",
      "정답을 1, 2, 3, 4 중 하나로 선택해 주세요!\n",
      "    답변: 1\n",
      "    대화 기록: ['퀴즈: 나이브베이즈 분류모델에 대한 설명 중 옳은 것을 고르세요.']\n",
      "    거절 사유: None\n",
      "    \n",
      "Feedback:\n",
      "AIMessage(content='- 정답 여부: \"1\"\\n- 추가 설명: 나이브베이즈 모델은 베이즈 정리를 기반으로 하며, 모든 입력 변수가 서로 독립적이라는 가정을 합니다. 이 가정은 \"나이브(naive)\"라는 이름의 유래이기도 합니다. 나이브베이즈는 주로 분류 문제에 사용되며, 이론적으로는 연속형 데이터와 범주형 데이터 모두 처리할 수 있지만, 일반적으로는 범주형 데이터에 더 적합합니다. 비지도학습이 아닌 지도학습에 속하며, 회귀 문제에는 보통 사용되지 않습니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 136, 'prompt_tokens': 266, 'total_tokens': 402, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0705bf87c0', 'finish_reason': 'stop', 'logprobs': None}, id='run-884fabee-d1af-48ac-a9c9-0c7ac373cfcf-0', usage_metadata={'input_tokens': 266, 'output_tokens': 136, 'total_tokens': 402, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})\n",
      "퀴즈: 나이브베이즈 분류모델에 대한 설명입니다. 나이브베이즈는 어떤 가정을 기반으로 하는 분류 알고리즘인가요?\n",
      "\n",
      "A) 모든 피처가 서로 독립적이다.  \n",
      "B) 피처 간의 상관관계가 존재한다.  \n",
      "C) 모든 피처가 동일한 중요도를 가진다.  \n",
      "D) 피처의 분포가 정규분포를 따른다.  \n",
      "\n",
      "정답을 선택해 주세요. (A, B, C, D 중 하나)\n",
      "1\n",
      "Formatted Feedback Data:\n",
      "System: \n",
      "    AI 강사로서 다음 퀴즈의 정답 여부를 확인하고 피드백을 제공하세요.\n",
      "    피드백은 아래와 같은 형식이어야 합니다:\n",
      "    - 정답 여부: \"N번\" 또는 \"예/아니오\"\n",
      "    - 추가 설명: (정답과 관련된 추가 정보를 제공하세요)\n",
      "    퀴즈: 퀴즈: 나이브베이즈 분류모델에 대한 설명입니다. 나이브베이즈는 어떤 가정을 기반으로 하는 분류 알고리즘인가요?\n",
      "\n",
      "A) 모든 피처가 서로 독립적이다.  \n",
      "B) 피처 간의 상관관계가 존재한다.  \n",
      "C) 모든 피처가 동일한 중요도를 가진다.  \n",
      "D) 피처의 분포가 정규분포를 따른다.  \n",
      "\n",
      "정답을 선택해 주세요. (A, B, C, D 중 하나)\n",
      "    답변: 1\n",
      "    대화 기록: ['퀴즈: 나이브베이즈 분류모델에 대한 설명 중 옳은 것을 고르세요.', '퀴즈: 나이브베이즈 분류모델에 대한 설명입니다. 나이브베이즈는 어떤 가정을 기반으로 하는 분류 알고리즘인가요?']\n",
      "    거절 사유: None\n",
      "    \n",
      "Feedback:\n",
      "AIMessage(content='- 정답 여부: \"A\"\\n- 추가 설명: 나이브베이즈 분류모델은 \"모든 피처가 서로 독립적이다\"라는 가정을 기반으로 합니다. 이 가정은 실제 데이터에서는 항상 성립하지 않을 수 있지만, 나이브베이즈는 이 가정을 통해 계산을 단순화하고 효율적인 분류를 가능하게 합니다. 피처 간의 독립성을 가정함으로써, 나이브베이즈는 각 피처의 조건부 확률을 곱하여 전체 확률을 계산하는 방식으로 작동합니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 128, 'prompt_tokens': 297, 'total_tokens': 425, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0705bf87c0', 'finish_reason': 'stop', 'logprobs': None}, id='run-ac9cc90e-e045-4faf-98f5-572a790c8a6b-0', usage_metadata={'input_tokens': 297, 'output_tokens': 128, 'total_tokens': 425, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})\n",
      "퀴즈: 나이브베이즈 분류 모델에서 '나이브'라는 용어는 어떤 의미를 가지고 있나요? 다음 보기 중에서 올바른 설명을 선택하세요.\n",
      "\n",
      "1. 모든 특성이 서로 독립적이다.\n",
      "2. 모든 특성이 서로 의존적이다.\n",
      "3. 특성이 연속적이다.\n",
      "4. 특성이 범주형이다.\n",
      "\n",
      "사용자의 대답을 기다리겠습니다!\n",
      "대화를 종료합니다.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# 폴더 이름\n",
    "folder_name = \"previous_conversation\"\n",
    "\n",
    "# 폴더가 없으면 생성\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "# 파일 이름에 타임스탬프 추가\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")  # \"20241126_153045\" 형식\n",
    "file_name = f\"conversation_log_{timestamp}.txt\"\n",
    "file_path = os.path.join(folder_name, file_name)\n",
    "\n",
    "quiz_list = []\n",
    "\n",
    "# 대화 진행\n",
    "while True:\n",
    "    # 1. 퀴즈 생성\n",
    "    quiz = rag_chain.invoke(\"퀴즈를 시작하세요.\")\n",
    "    quiz_list.append(quiz)\n",
    "    print(quiz)\n",
    "    \n",
    "    # 2. 사용자 답변 수집\n",
    "    user_answer = input(\"답변을 입력하세요: \")\n",
    "    if user_answer.strip().lower() == \"exit\":\n",
    "        print(\"대화를 종료합니다.\")\n",
    "        break\n",
    "    print(user_answer)\n",
    "\n",
    "    # 이전 대화 내용 불러오기\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            previous_conversation = f.read()\n",
    "    else:\n",
    "        previous_conversation = \"\"  # 파일이 없으면 빈 문자열로 시작\n",
    "\n",
    "    # '퀴즈:'로 시작하는 내용만 추출\n",
    "    quiz_pattern = r\"퀴즈: .*\"\n",
    "    all_quizzes = \"\\n\".join(quiz_list)  # 리스트를 문자열로 결합\n",
    "    quiz_onlys = re.findall(quiz_pattern, all_quizzes)  # 문자열에서 검색\n",
    "\n",
    "    # # 필요한 부분 출력\n",
    "    # print(\"추출된 퀴즈:\")\n",
    "    # for quiz_only in quiz_onlys:\n",
    "    #     print(quiz_only)\n",
    "    \n",
    "    # 3. 사용자 답변에 대한 피드백 생성\n",
    "    feedback_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", f\"\"\"\n",
    "    AI 강사로서 다음 퀴즈의 정답 여부를 확인하고 피드백을 제공하세요.\n",
    "    피드백은 아래와 같은 형식이어야 합니다:\n",
    "    - 정답 여부: \"N번\" 또는 \"예/아니오\"\n",
    "    - 추가 설명: (정답과 관련된 추가 정보를 제공하세요)\n",
    "    퀴즈: {{quiz}}\n",
    "    답변: {{answer}}\n",
    "    대화 기록: {{quiz_onlys}}\n",
    "    거절 사유: {{refusal}}\n",
    "    \"\"\")\n",
    "    ])\n",
    "\n",
    "    # 피드백 생성 - 키워드 인수로 전달\n",
    "    feedback_data = feedback_prompt.format(\n",
    "        quiz=quiz,\n",
    "        answer=user_answer,\n",
    "        quiz_onlys=quiz_onlys,\n",
    "        refusal=\"None\"\n",
    "    )\n",
    "\n",
    "    # format 결과를 확인\n",
    "    print(\"Formatted Feedback Data:\")\n",
    "    print(feedback_data)\n",
    "\n",
    "    # 피드백 체인 호출\n",
    "    feedback = llm.invoke(feedback_data)   # LLM을 직접 호출하여 피드백 생성\n",
    "    \n",
    "    print(\"Feedback:\")\n",
    "    pprint(feedback)\n",
    "    \n",
    "    # 대화 내용 저장(파일에 기록)\n",
    "    with open(file_path, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"Quiz: {quiz}\\n\")\n",
    "        f.write(f\"User Answer: {user_answer}\\n\")\n",
    "        f.write(f\"Feedback: {feedback}\\n\")\n",
    "        f.write(\"-\" * 50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI_boot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
