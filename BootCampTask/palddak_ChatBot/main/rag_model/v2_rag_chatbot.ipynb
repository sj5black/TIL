{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirements\n",
    "\n",
    "- langchain>=0.0.200\n",
    "- openai>=0.27.8\n",
    "- chromadb>=0.4.7\n",
    "- beautifulsoup4>=4.12.2\n",
    "- selenium>=4.11.2\n",
    "- webdriver-manager>=3.8.6\n",
    "- python-dotenv>=1.0.0\n",
    "- pprintpp>=0.4.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 트러블 슈팅\n",
    "\n",
    "> 2024/11/22 (성진)\n",
    "---\n",
    "**데이터 전처리 과정**\n",
    "1. WebBaseLoader 로 레퍼런스가 정상적으로 인식되지 않는 문제  \n",
    " - 원인 : WebBaseLoader의 한계로 인한 실패 가능성. WebBaseLoader는 간단한 텍스트 추출에 적합하며, 복잡한 HTML 구조나 JavaScript 기반의 동적 콘텐츠를 처리하지 못할 수 있다. \n",
    "\n",
    "    1_1. WebBaseLoader 대신 request를 사용한 HTML 크롤링 시도 -> 실패  \n",
    "     - 원인 : Notion 페이지는 JavaScript를 활용한 동적 렌더링을 사용하는 구조여서 requests만 사용해서는 JavaScript로 렌더링된 내용을 가져올 수 없었다.\n",
    "\n",
    "    1_2. Selenium 사용 --> 부분 성공  \n",
    "     - 원인 : implicitly_wait 으로 대기 후 로드 시 데이터를 가져오는 경우가 있고, 못가져오는 경우가 있었음..\n",
    "\n",
    "    1_3. 대기 방식 변경 (WebDriverWait.until() 사용) --> 성공  \n",
    "     - 로드하려는 웹페이지의 html 중 특정 요소가 로드될 때까지 wait하는 방식 사용\n",
    "\n",
    "2. soup.get_text() 에서 노션 문서의 헤드라인만 추출되는 문제  \n",
    " - 원인 : 노션 페이지에 진입했을 때, 토글(Ctrl+Alt+T)이 닫힌 상태로 텍스트가 추출되고 있었음\n",
    "\n",
    "    2_1. 단축키 입력을 선언하는 방법 (헤드리스 상태에서 사용 불가)  \n",
    "\n",
    "    2_2. html 내에 토글 버튼을 찾아 여는 방법 (헤드리스 상태에서 사용 가능) --> 선택 (성공)  \n",
    "     - drive.find_elements 로 버튼 탐색 후 클릭 (지연시간 1초)\n",
    "\n",
    "3. 추출된 텍스트 파일에 일부 문법 구문이 남아있는 문제  \n",
    " - re (regular expression) 을 활용해 삭제/전처리 (성공)\n",
    "\n",
    "**유사한 질문을 계속해서 질문하는 경우**\n",
    "1. cosine 유사도 비교로 유사한 질문을 생성해내는 경우에는 다른 질문을 생성하도록 했음\n",
    "   - cosine 유사도는 단어의 유사도를 비교하는 것에 약점을 보였기 때문에 성능이 크게 좋아지지 않음 (실패)\n",
    "   - 프롬프팅으로 고도화 시도 (성공))\n",
    "\n",
    "\n",
    "---\n",
    "**AI 챗봇**\n",
    "\n",
    "1. AI 가 질문에 대한 사용자의 답변을 인식하지 못하는 문제  \n",
    " - 사용자의 답변을 질문과 함께 feedback_prompt 형식으로 묶어서 다시 AI에게 전달하는 방식으로 문제 해결\n",
    "\n",
    "2. AI 가 동일한 주제에 대해서 반복적으로 비슷한 질문만을 하는 문제 --> (해결중..)\n",
    "\n",
    "---\n",
    "\n",
    "> 2024/11/26 (수연)\n",
    "\n",
    "2. AI 가 동일한 주제에 대해서 반복적으로 비슷한 질문만을 하는 문제 -> 해결\n",
    "\n",
    "   - 해결 방법 : \n",
    "   - 수동적으로 참고할 docs와 갯수를 할당 (코드에서는 한 교재당 2개의 질문)\n",
    "   - 유사한 질문을 rag에 넘겨주어 겹치지 않도록 프롬프팅 (직전 5개의 문장 기준, 이미 한 docs당 2개의 문장 질문 제한 고려)\n",
    "   - 프롬프팅 고도화\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from pprint import pprint\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import re\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_file(txt:str, file_name:str):\n",
    "\n",
    "    with open(file_name, 'w', encoding='utf-8') as content_file:\n",
    "        content_file.write(txt)\n",
    "\n",
    "    print(f\"TEXT 파일 저장 완료: {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# .env 파일에서 환경변수 로드\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPEN_AI_KEY\")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 교재 저장하는 부분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "TEXT 파일 저장 완료: DL_dataset_1.txt\n",
      "6\n",
      "TEXT 파일 저장 완료: DL_dataset_2.txt\n",
      "5\n",
      "TEXT 파일 저장 완료: DL_dataset_3.txt\n",
      "3\n",
      "TEXT 파일 저장 완료: DL_dataset_4.txt\n",
      "5\n",
      "TEXT 파일 저장 완료: DL_dataset_5.txt\n",
      "4\n",
      "TEXT 파일 저장 완료: DL_dataset_6.txt\n",
      "3\n",
      "TEXT 파일 저장 완료: DL_dataset_7.txt\n",
      "4\n",
      "TEXT 파일 저장 완료: DL_dataset_8.txt\n",
      "3\n",
      "TEXT 파일 저장 완료: DL_dataset_9.txt\n",
      "3\n",
      "TEXT 파일 저장 완료: DL_dataset_10.txt\n",
      "3\n",
      "TEXT 파일 저장 완료: DL_dataset_11.txt\n",
      "4\n",
      "TEXT 파일 저장 완료: DL_dataset_12.txt\n",
      "2\n",
      "TEXT 파일 저장 완료: DL_dataset_13.txt\n",
      "4\n",
      "TEXT 파일 저장 완료: DL_dataset_14.txt\n",
      "2\n",
      "TEXT 파일 저장 완료: DL_dataset_15.txt\n",
      "3\n",
      "TEXT 파일 저장 완료: DL_dataset_16.txt\n"
     ]
    }
   ],
   "source": [
    "    save_file(''.join(txt), f\"DL_dataset_{j}.txt\")\n",
    "    \n",
    "\n",
    "\n",
    "driver.quit()  # 브라우저 종료\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 저장한 교재 (txt) 불러오는 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "text_list = []\n",
    "\n",
    "# 파일을 읽어와서 text_list에 저장하는 함수\n",
    "def load_files_to_list(file_path, text_list):\n",
    "    if os.path.exists(file_path):  # 파일이 존재하는지 확인\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:  # 파일 열기\n",
    "            content = file.read()  # 파일 내용 읽기\n",
    "            text_list.append(content)  # text_list에 추가\n",
    "    else:\n",
    "        print(f\"File {file_path} not found.\")\n",
    "        \n",
    "    \n",
    "\n",
    "# 예시: 파일 경로 목록을 지정\n",
    "file_paths = [f\"DL_dataset_{i}.txt\" for i in range(1, 17)]  # 파일 경로 목록 (DL_dataset_1.txt, DL_dataset_2.txt, ...)\n",
    "\n",
    "print(file_paths)\n",
    "\n",
    "for j in range(len(file_paths)):\n",
    "    load_files_to_list(file_paths[j], text_list)\n",
    "\n",
    "text_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 각 교재별 retriever 생성부분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "\n",
    "# text_list를 Document 객체로 변환\n",
    "documents = [Document(page_content=text) for text in text_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "from langchain.schema import Document\n",
    "\n",
    "def get_retriever(texts:str):\n",
    "\n",
    "    # text_list를 Document 객체로 변환\n",
    "    documents = [Document(page_content=texts)]\n",
    "\n",
    "    recursive_text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size= 200,\n",
    "    chunk_overlap= 20,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    "    )\n",
    "\n",
    "    splits_recur = recursive_text_splitter.split_documents(documents)\n",
    "    splits = splits_recur\n",
    "\n",
    "    print(\"Top 10 chunks:\")\n",
    "    for i, chunk in enumerate(splits[:10], 1):\n",
    "        pprint(f\"\\nChunk {i}:\\n{chunk.page_content}\")\n",
    "    # OpenAI 임베딩 모델 초기화\n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\", api_key=api_key)\n",
    "    vectorstore = FAISS.from_documents(documents=splits, embedding=embeddings)\n",
    "    bm25_retriever = BM25Retriever.from_documents(splits)\n",
    "    faiss_retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5})\n",
    "\n",
    "    retriever = EnsembleRetriever(\n",
    "                retrievers=[bm25_retriever, faiss_retriever],\n",
    "                weights=[0.5, 0.5]  # 가중치 설정 (가중치의 합은 1.0)\n",
    "            )\n",
    "\n",
    "    return retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 chunks:\n",
      "('\\n'\n",
      " 'Chunk 1:\\n'\n",
      " '[스파르타코딩클럽] 1. 딥러닝 개념을 잡아봅시다!📘[SCC] 기초가 탄탄한 딥러닝/📚[스파르타코딩클럽] 기초가 탄탄한 딥러닝 - '\n",
      " '1주차/📕[스파르타코딩클럽] 1. 딥러닝 개념을 잡아봅시다!Made with📕[스파르타코딩클럽] 1. 딥러닝 개념을 잡아봅시다![수업 '\n",
      " '목표]딥러닝이 무엇인지 개념에 대해 알아봅시다.딥러닝의 역사와 어디에 사용할 수 있을지')\n",
      "('\\n'\n",
      " 'Chunk 2:\\n'\n",
      " '역사와 어디에 사용할 수 있을지 알아봅시다[목차]01. 딥러닝이란 무엇일까요?02. 딥러닝의 역사와 활용 방안03. 딥러닝을 배워야 하는 '\n",
      " '이유💡모든 토글을 열고 닫는 단축키')\n",
      "'\\nChunk 3:\\nWindows : Ctrl + alt + t'\n",
      "('\\n'\n",
      " 'Chunk 4:\\n'\n",
      " 'Mac : ⌘ + ⌥ + t 01. 딥러닝이란 무엇일까요?✔️딥러닝이란 무엇인지 개념에 대해서 알아봅시다!1) 딥러닝이란?☑️ 딥러닝 '\n",
      " '개념딥러닝은 인공신경망(Artificial Neural Networks)을 기반으로 한 기계 학습의 한 분야입니다.다층 신경망을 사용하여 '\n",
      " '데이터로부터 특징을 자동으로 학습하고, 이를 통해 복잡한 문제를 해결합니다.입력')\n",
      "('\\n'\n",
      " 'Chunk 5:\\n'\n",
      " '통해 복잡한 문제를 해결합니다.입력 데이터에서 중요한 패턴을 추출하고, 이를 바탕으로 예측, 분류, 생성 등의 다양한 작업을 수행할 수 '\n",
      " '있습니다.ALT☑️ 딥러닝의 특징비선형 추론: 딥러닝은 비선형 추론을 통해 복잡한 데이터의 패턴을 학습할 수 있습니다.다층 구조: 여러 '\n",
      " '층의 신경망을 사용하여 데이터의 고차원 특징을 학습합니다.자동 특징 추출:')\n",
      "('\\n'\n",
      " 'Chunk 6:\\n'\n",
      " '특징을 학습합니다.자동 특징 추출: 데이터로부터 중요한 특징을 자동으로 추출하여 별도의 특징 공학(feature engineering) '\n",
      " '과정이 필요 없습니다.02. 딥러닝의 역사와 활용 방안✔️딥러닝의 역사와 어디에 딥러닝을 쓸 수 있을지 배워봅시다!1) 딥러닝의 역사와 '\n",
      " '발전☑️ 발전 과정ALT☑️ 인공지능, 머신러닝, 딥러닝의 관계인공지능(AI) :')\n",
      "('\\n'\n",
      " 'Chunk 7:\\n'\n",
      " '딥러닝의 관계인공지능(AI) : 인공지능은 인간의 지능을 모방하여 문제를 해결하는 기술을 의미합니다. AI는 규칙 기반 시스템부터 자율 '\n",
      " '학습 시스템까지 다양한 접근 방식을 포함합니다.머신러닝(ML) : 머신러닝은 데이터를 이용해 모델을 학습하고, 이를 통해 예측이나 결정을 '\n",
      " '내리는 기술입니다. 머신러닝은 AI의 하위 분야로, 지도 학습, 비지도 학습, 강화')\n",
      "('\\n'\n",
      " 'Chunk 8:\\n'\n",
      " '지도 학습, 비지도 학습, 강화 학습 등의 방법을 포함합니다.딥러닝(DL) : 딥러닝은 머신러닝의 하위 분야로, 다층 신경망을 사용하여 '\n",
      " '데이터를 학습합니다. 딥러닝은 특히 대규모 데이터와 복잡한 문제를 다루는 데 강력한 성능을 발휘합니다.ALT2) 최근의 활용 방안☑️ '\n",
      " '이미지 인식딥러닝은 이미지 분류, 객체 검출, 이미지 생성 등 다양한 이미지 처리')\n",
      "('\\n'\n",
      " 'Chunk 9:\\n'\n",
      " '이미지 생성 등 다양한 이미지 처리 작업에 활용됩니다. 예를 들어, 자율 주행 자동차는 딥러닝을 사용하여 도로 상황을 인식하고, 보행자와 '\n",
      " '차량을 감지합니다.☑️ 자연어 처리번역, 요약, 감정 분석 등 자연어 처리 작업에 사용됩니다. 예를 들어, 구글 번역은 딥러닝 모델을 '\n",
      " '사용하여 다양한 언어 간의 번역을 수행합니다.☑️ 음성 인식딥러닝은 음성 인식')\n",
      "('\\n'\n",
      " 'Chunk 10:\\n'\n",
      " '음성 인식딥러닝은 음성 인식 시스템의 성능을 크게 향상시켰습니다.예를 들어, 애플의 Siri, 아마존의 Alexa와 같은 가상 비서는 '\n",
      " '딥러닝을 사용하여 사용자의 음성을 인식하고 명령을 수행합니다.☑️ 의료 분야의료 영상 분석, 질병 예측, 신약 개발 등 다양한 의료 '\n",
      " '분야에서도 활용됩니다.예를 들어, 딥러닝 모델은 MRI나 CT 스캔 이미지를 분석하여 암을')\n",
      "Top 10 chunks:\n",
      "('\\n'\n",
      " 'Chunk 1:\\n'\n",
      " '[스파르타코딩클럽] 2. 신경망의 기본 원리📘[SCC] 기초가 탄탄한 딥러닝/📚[스파르타코딩클럽] 기초가 탄탄한 딥러닝 - '\n",
      " '1주차/📕[스파르타코딩클럽] 2. 신경망의 기본 원리Made with📕[스파르타코딩클럽] 2. 신경망의 기본 원리[수업 목표]퍼셉트론의 '\n",
      " '개념과 다층 퍼셉트론에 대해 배워봅시다.신경망을 강화하기 위한 활성화 함수/손실 함수/역전파/최적화')\n",
      "('\\n'\n",
      " 'Chunk 2:\\n'\n",
      " '함수/손실 함수/역전파/최적화 알고리즘에 대해 배워봅시다[목차]01. 퍼셉트론과 다층 퍼셉트론(XOR 문제 포함)02. 다층 '\n",
      " '퍼셉트론(MLP)03. 활성화 함수04. 손실 함수와 최적화 알고리즘05. 역전파에 대해 알아볼까요?💡모든 토글을 열고 닫는 단축키')\n",
      "'\\nChunk 3:\\nWindows : Ctrl + alt + t'\n",
      "('\\n'\n",
      " 'Chunk 4:\\n'\n",
      " 'Mac : ⌘ + ⌥ + t 01. 퍼셉트론과 다층 퍼셉트론(XOR 문제 포함)✔️인공신공망의 가장 기본 단위인 퍼셉트론에 대해 '\n",
      " '배워봅시다1) 단일 퍼셉트론의 원리☑️ 단일 퍼셉트론의 개념퍼셉트론(Perceptron)은 인공 신경망의 가장 기본적인 단위로, 하나의 '\n",
      " '뉴런을 모델링한 것입니다.퍼셉트론은 입력 값을 받아 가중치(weight)를 곱하고, 이를')\n",
      "('\\n'\n",
      " 'Chunk 5:\\n'\n",
      " '곱하고, 이를 모두 더한 후 활성화 함수(activation function)를 통해 출력 값을 결정합니다.ALT☑️ 퍼셉트론의 수학적 '\n",
      " '표현y=f(∑i=1nwixi+b)y = f(_{i=1}^{n} w_i x_i + b) '\n",
      " 'y=f(i=1∑n\\u200bwi\\u200bxi\\u200b+b)여기서 xi는 입력 값, wi는 가중치, b는 바이어스(bias), f는 '\n",
      " '활성화 함수입니다.여기서')\n",
      "('\\n'\n",
      " 'Chunk 6:\\n'\n",
      " 'f는 활성화 함수입니다.여기서 xi\\u200b는 입력 값, wi\\u200b는 가중치, b는 바이어스(bias), f는 활성화 '\n",
      " '함수입니다.\\ufeff\\u200b02. 다층 퍼셉트론(MLP)✔️다층 퍼셉트론에 대해 배워봅시다1) 다층 퍼셉트론(MLP)과 XOR 문제 '\n",
      " '해결☑️ 다층 퍼셉트론(MLP)의 개념다층 퍼셉트론(Multi-Layer Perceptron, MLP)은 여러 층의 퍼셉트론을')\n",
      "('\\n'\n",
      " 'Chunk 7:\\n'\n",
      " 'MLP)은 여러 층의 퍼셉트론을 쌓아 올린 신경망 구조입니다.MLP는 입력층(input layer), 은닉층(hidden layer), '\n",
      " '출력층(output layer)으로 구성되며, 각 층의 뉴런들이 서로 연결되어 있습니다.ALT☑️ 입력, 은닉, 출력 레이어의 개념입력 '\n",
      " '레이어(Input Layer) : 외부 데이터가 신경망에 입력되는 부분입니다. 입력')\n",
      "('\\n'\n",
      " 'Chunk 8:\\n'\n",
      " '신경망에 입력되는 부분입니다. 입력 레이어의 뉴런 수는 입력 데이터의 특징 수와 동일합니다.은닉 레이어(Hidden Layer) : 은닉 '\n",
      " '레이어는 입력 레이어와 출력 레이어 사이에 위치한 층으로, 입력 데이터를 처리하고 특징을 추출하는 역할을 합니다. 은닉 레이어의 뉴런 '\n",
      " '수와 층 수는 모델의 복잡성과 성능에 영향을 미칩니다.출력 레이어(Output')\n",
      "('\\n'\n",
      " 'Chunk 9:\\n'\n",
      " '미칩니다.출력 레이어(Output Layer) : 출력 레이어는 신경망의 마지막 층으로, 최종 예측 값을 출력합니다. 출력 레이어의 뉴런 '\n",
      " '수는 예측하려는 클래스 수 또는 회귀 문제의 출력 차원과 동일합니다.☑️ XOR 문제와 MLP단일 퍼셉트론은 선형 분류기이기 때문에 '\n",
      " 'XOR 문제와 같은 비선형 문제를 해결할 수 없습니다.XOR 문제는 두 입력 값이 다를')\n",
      "('\\n'\n",
      " 'Chunk 10:\\n'\n",
      " '문제는 두 입력 값이 다를 때만 1을 출력하는 문제로, 단일 퍼셉트론으로는 해결할 수 없습니다. 그러나 MLP는 은닉층을 통해 비선형성을 '\n",
      " '학습할 수 있어 XOR 문제를 해결할 수 있습니다.03. 활성화 함수✔️활성화 함수라는게 무엇인지, 신경망에서 어떤 역할을 하는지 '\n",
      " '알아보고, 어떤 종류의 활성화 함수가 있는지 배워봅시다1) 활성화 함수의 필요성과')\n",
      "Top 10 chunks:\n",
      "('\\n'\n",
      " 'Chunk 1:\\n'\n",
      " '[스파르타코딩클럽] 3. 딥러닝 실습 환경 구축📘[SCC] 기초가 탄탄한 딥러닝/📚[스파르타코딩클럽] 기초가 탄탄한 딥러닝 - '\n",
      " '1주차/📕[스파르타코딩클럽] 3. 딥러닝 실습 환경 구축Made with📕[스파르타코딩클럽] 3. 딥러닝 실습 환경 구축[수업 '\n",
      " '목표]딥러닝 실습을 위한 환경을 구축해 봅시다[목차]01. conda를 이용한 환경 설정02.')\n",
      "('\\n'\n",
      " 'Chunk 2:\\n'\n",
      " 'conda를 이용한 환경 설정02. jupyter notebook 03. 가상환경 설치 및 jupyter notebook 연결 04. '\n",
      " 'pytorch 설치\\u200b환경 활성화 {5px}환경 활성화 \\ufeff\\u200bPythonCopyconda activate '\n",
      " 'myenv')\n",
      "('\\n'\n",
      " 'Chunk 3:\\n'\n",
      " '\\u200b필요한 패키지 설치 {5px}필요한 패키지 설치 \\ufeff\\u200bPythonCopyconda install numpy '\n",
      " 'pandas matplotlib')\n",
      "('\\n'\n",
      " 'Chunk 4:\\n'\n",
      " '\\u200b02. jupyter notebook ✔️jupyter notebook이 무엇인지 알아보고 설치해 봅시다.1)  jupyter '\n",
      " 'notebook 사용법☑️ jupyter notebook이란?Jupyter Notebook은 데이터 과학자와 연구자들이 코드를 작성하고 '\n",
      " '실행하며, 결과를 시각화하고 문서화할 수 있는 대화형 환경입니다.☑️ jupyter')\n",
      "('\\n'\n",
      " 'Chunk 5:\\n'\n",
      " '환경입니다.☑️ jupyter notebook 설치Jupyter Notebook은 conda를 통해 쉽게 설치할 수 있습니다jupyter '\n",
      " 'notebook 설치 {5px}jupyter notebook 설치 \\ufeff\\u200bPythonCopyconda install '\n",
      " 'jupyter')\n",
      "('\\n'\n",
      " 'Chunk 6:\\n'\n",
      " '\\u200b☑️ jupyter notebook 시작하기Jupyter Notebook 실행jupyter notebook 실행 '\n",
      " '{5px}jupyter notebook 실행 \\ufeff\\u200bPythonCopyjupyter notebook')\n",
      "('\\n'\n",
      " 'Chunk 7:\\n'\n",
      " '\\u200b이 명령어를 실행하면 웹 브라우저가 열리고, Jupyter Notebook 인터페이스가 나타납니다.새로운 노트북 '\n",
      " '생성:Jupyter Notebook 인터페이스에서 \"New\" 버튼을 클릭하고, \"Python (myenv)\"를 선택하여 새로운 노트북을 '\n",
      " '생성합니다.코드 작성 및 실행:셀(Cell)에 코드를 작성하고, 셀을 선택한 후 \"Shift +')\n",
      "('\\n'\n",
      " 'Chunk 8:\\n'\n",
      " '셀을 선택한 후 \"Shift + Enter\"를 눌러 코드를 실행합니다.03. 가상환경 설치 및 jupyter notebook 연결 '\n",
      " '✔️가상환경이 무엇인지 알아보고 jupyter notebook과 가상환경을 연결해 봅시다1) 가상환경 설치 ☑️ 가상환경이란 '\n",
      " '무엇인가?가상환경(Virtual Environment)은 프로젝트마다 독립적인 파이썬 환경을')\n",
      "('\\n'\n",
      " 'Chunk 9:\\n'\n",
      " '프로젝트마다 독립적인 파이썬 환경을 제공합니다.가상환경을 이용해 서로 다른 프로젝트 간의 패키지 충돌을 방지할 수 있습니다. Conda를 '\n",
      " '이용하면 쉽게 가상환경을 생성하고 관리할 수 있습니다.☑️ 가상환경 생성 및 관리가상 환경 생성 {5px}가상 환경 생성 '\n",
      " '\\ufeff\\u200bPythonCopyconda create --name myenv python=3.8')\n",
      "('\\n'\n",
      " 'Chunk 10:\\n'\n",
      " '\\u200b여기서 myenv 는 가상환경의 이름이며 python=3.8은 설치할 파이썬 버전입니다여기서 myenv 는 가상환경의 이름이며 '\n",
      " 'python=3.8은 설치할 파이썬 버전입니다\\ufeff\\u200b가상 환경 비활성화 {5px}가상 환경 비활성화 '\n",
      " '\\ufeff\\u200bPythonCopyconda deactivate')\n",
      "Top 10 chunks:\n",
      "('\\n'\n",
      " 'Chunk 1:\\n'\n",
      " '[스파르타코딩클럽] 4. 인공 신경망(ANN)📘[SCC] 기초가 탄탄한 딥러닝/📚[스파르타코딩클럽] 기초가 탄탄한 딥러닝 - '\n",
      " '2주차/📕[스파르타코딩클럽] 4. 인공 신경망(ANN)Made with📕[스파르타코딩클럽] 4. 인공 신경망(ANN)[수업 '\n",
      " '목표]인공신경망의 개념에 대해서 배워보고 어떤 원리로 동작하는지 알아봅시다Pytorch로 간단한 인공신경망')\n",
      "('\\n'\n",
      " 'Chunk 2:\\n'\n",
      " '간단한 인공신경망 모델 구현 실습을 진행해 봅시다[목차]01. 기본 구조와 동작원리02. 실습: 간단한 인공 신경망 모델 구현 '\n",
      " '(PyTorch) - 입력데이터를 받아들이는 층, 입력층의 뉴런수는 입력데이터 피쳐수와 동일 - 입력데이터를 받아들이는 층, 입력층의 '\n",
      " '뉴런수는 입력데이터 피쳐수와 동일\\ufeff')\n",
      "('\\n'\n",
      " 'Chunk 3:\\n'\n",
      " '은닉층\\n'\n",
      " ' - 입력데이터를 처리하고 특징을 추출하는 층, 은닉층의 뉴런수와 층수는 모델의 복잡성과 성능에 영향 - 입력데이터를 처리하고 특징을 '\n",
      " '추출하는 층, 은닉층의 뉴런수와 층수는 모델의 복잡성과 성능에 영향\\ufeff\\n'\n",
      " '출력층')\n",
      "('\\n'\n",
      " 'Chunk 4:\\n'\n",
      " '- 최종 예측값을 출력하는 층, 출력층의 뉴런 수는 예측하려는 클래스 수 또는 회귀문제 출력차원과 동일 - 최종 예측값을 출력하는 층, '\n",
      " '출력층의 뉴런 수는 예측하려는 클래스 수 또는 회귀문제 출력차원과 동일\\ufeff\\u200b☑️ 동작 방식순전파 (Forward '\n",
      " 'Propagation)입력 데이터를 통해 각 층의 뉴런이 활성화되고, 최종 출력 값을 계산합니다.각 뉴런은')\n",
      "('\\n'\n",
      " 'Chunk 5:\\n'\n",
      " '출력 값을 계산합니다.각 뉴런은 입력 값에 가중치(weight)를 곱하고, 바이어스(bias)를 더한 후 활성화 함수(activation '\n",
      " 'function)를 통해 출력 값을 결정합니다.손실 계산 (Loss Calculation)예측 값과 실제 값의 차이를 손실 함수(Loss '\n",
      " 'Function)로 계산합니다.역전파 (Backpropagation)손실 함수의')\n",
      "('\\n'\n",
      " 'Chunk 6:\\n'\n",
      " '함수의 기울기를 출력층에서 입력층 방향으로 계산하고, 이를 바탕으로 가중치를 업데이트합니다.ALT2) 출력 레이어의 구성☑️ 출력레이어의 '\n",
      " '유형과 활용출력 레이어는 신경망의 최종 예측 값을 출력하는 층으로, 문제의 유형에 따라 다양한 형태로 구성될 수 있습니다.회귀 문제 '\n",
      " '(Regression):출력 레이어의 뉴런 수는 예측하려는 연속적인 값의 차원과')\n",
      "('\\n'\n",
      " 'Chunk 7:\\n'\n",
      " '예측하려는 연속적인 값의 차원과 동일합니다.활성화 함수로는 주로 선형 함수(linear function)를 사용합니다.이진 분류 문제 '\n",
      " '(Binary Classification):출력 레이어의 뉴런 수는 1입니다.활성화 함수로는 시그모이드 함수(Sigmoid '\n",
      " 'Function)를 사용하여 출력 값을 0과 1 사이의 확률로 변환합니다.다중 클래스 분류 문제')\n",
      "('\\n'\n",
      " 'Chunk 8:\\n'\n",
      " '변환합니다.다중 클래스 분류 문제 (Multi-Class Classification):출력 레이어의 뉴런 수는 예측하려는 클래스 수와 '\n",
      " '동일합니다.활성화 함수로는 소프트맥스 함수(Softmax Function)를 사용하여 각 클래스에 대한 확률을 출력합니다.02. 실습: '\n",
      " '간단한 인공 신경망 모델 구현 (PyTorch)✔️ PyTorch를 사용하여 간단한')\n",
      "('\\n'\n",
      " 'Chunk 9:\\n'\n",
      " 'PyTorch를 사용하여 간단한 인공 신경망 모델을 구축하고 학습해보겠습니다. 예제로는 MNIST 데이터셋을 사용하여 숫자 이미지를 '\n",
      " '분류하는 모델을 구현하겠습니다.1)  간단한 ANN 모델 구축 및 학습☑️ PyTorch 및 필요한 라이브러리 임포트PyTorch 및 '\n",
      " '필요한 라이브러리 임포트 {5px}PyTorch 및 필요한 라이브러리 임포트')\n",
      "'\\nChunk 10:\\n및 필요한 라이브러리 임포트 \\ufeff\\u200bPythonCopyimport torch'\n",
      "Top 10 chunks:\n",
      "('\\n'\n",
      " 'Chunk 1:\\n'\n",
      " '[스파르타코딩클럽] 5. 합성곱 신경망(CNN)📘[SCC] 기초가 탄탄한 딥러닝/📚[스파르타코딩클럽] 기초가 탄탄한 딥러닝 - '\n",
      " '2주차/📕[스파르타코딩클럽] 5. 합성곱 신경망(CNN)Made with📕[스파르타코딩클럽] 5. 합성곱 신경망(CNN)[수업 '\n",
      " '목표]합성곱 신경망의 개념에 대해서 배워보고 어떤 원리로 동작하는지 알아봅시다Pytorch로 간단한')\n",
      "('\\n'\n",
      " 'Chunk 2:\\n'\n",
      " '알아봅시다Pytorch로 간단한 CNN 모델 구현 실습을 진행해 봅시다[목차]01. CNN의 기본 구조와 동작 원리02. 실습: CNN을 '\n",
      " '이용한 이미지 분류 (PyTorch) - 입력 이미지에 필터(커널)를 적용하여 특징 맵(feature map)을 생성합니다. - 입력 '\n",
      " '이미지에 필터(커널)를 적용하여 특징 맵(feature map)을 생성합니다.\\ufeff')\n",
      "('\\n'\n",
      " 'Chunk 3:\\n'\n",
      " '- 필터는 이미지의 국소적인 패턴을 학습합니다. - 필터는 이미지의 국소적인 패턴을 학습합니다.\\ufeff\\n'\n",
      " '풀링 층 (Pooling Layer)\\n'\n",
      " ' - 특징 맵의 크기를 줄이고, 중요한 특징을 추출합니다. - 특징 맵의 크기를 줄이고, 중요한 특징을 추출합니다.\\ufeff')\n",
      "('\\n'\n",
      " 'Chunk 4:\\n'\n",
      " '- 주로 Max Pooling과 Average Pooling이 사용됩니다. - 주로 Max Pooling과 Average Pooling이 '\n",
      " '사용됩니다.\\ufeff\\n'\n",
      " '완전 연결 층 (Fully Connected Layer)\\n'\n",
      " ' - 추출된 특징을 바탕으로 최종 예측을 수행합니다. - 추출된 특징을 바탕으로 최종 예측을 수행합니다.\\ufeff')\n",
      "('\\n'\n",
      " 'Chunk 5:\\n'\n",
      " '- CNN이라는 분석레이어를 통해 추출한 특성을 바탕으로 결론을 내리는 부분 - CNN이라는 분석레이어를 통해 추출한 특성을 바탕으로 '\n",
      " '결론을 내리는 부분\\ufeff\\u200b2) 합성곱 연산과 필터☑️ 합성곱 연산의 원리와 필터의 역할합성곱 연산은 입력 이미지에 '\n",
      " '필터(커널)를 적용하여 특징 맵을 생성하는 과정입니다. 필터는 작은 크기의 행렬로, 이미지의 국소적인 패턴을')\n",
      "('\\n'\n",
      " 'Chunk 6:\\n'\n",
      " '행렬로, 이미지의 국소적인 패턴을 학습합니다.합성곱 연산:필터를 이미지의 각 위치에 슬라이딩하며, 필터와 이미지의 해당 부분 간의 '\n",
      " '점곱(dot product)을 계산합니다.계산된 값은 특징 맵의 해당 위치에 저장됩니다.필터의 역할:필터는 이미지의 에지(edge), '\n",
      " '코너(corner), 텍스처(texture) 등 다양한 국소적인 패턴을 학습합니다.여러 개의')\n",
      "('\\n'\n",
      " 'Chunk 7:\\n'\n",
      " '패턴을 학습합니다.여러 개의 필터를 사용하여 다양한 특징 맵을 생성할 수 있습니다.3) 풀링 레이어, 플래튼☑️ 풀링 레이어의 필요성과 '\n",
      " '종류풀링 층은 특징 맵의 크기를 줄이고, 중요한 특징을 추출하는 역할을 합니다. 풀링 층은 주로 Max Pooling과 Average '\n",
      " 'Pooling이 사용됩니다.Max Pooling:필터 크기 내에서 최대 값을')\n",
      "('\\n'\n",
      " 'Chunk 8:\\n'\n",
      " '크기 내에서 최대 값을 선택합니다.중요한 특징을 강조하고, 불필요한 정보를 제거합니다.Average Pooling:필터 크기 내에서 평균 '\n",
      " '값을 계산합니다.특징 맵의 크기를 줄이면서, 정보의 손실을 최소화합니다.☑️ 플래튼 레이어의 역할플래튼 층(Flatten Layer)은 '\n",
      " '2차원 특징 맵을 1차원 벡터로 변환하는 역할을 합니다. 이는 완전 연결 층에')\n",
      "('\\n'\n",
      " 'Chunk 9:\\n'\n",
      " '합니다. 이는 완전 연결 층에 입력으로 사용하기 위해 필요합니다.4) CNN 구조와 응용☑️ 다양한 CNN 아키텍처LeNet:최초의 '\n",
      " 'CNN 아키텍처 중 하나로, 손글씨 숫자 인식에 사용되었습니다.합성곱 층과 풀링 층을 반복한 후, 완전 연결 층을 '\n",
      " '사용합니다.AlexNet:2012년 이미지넷 대회에서 우승한 아키텍처로, 딥러닝의 가능성을')\n",
      "('\\n'\n",
      " 'Chunk 10:\\n'\n",
      " '아키텍처로, 딥러닝의 가능성을 입증했습니다.ReLU 활성화 함수와 드롭아웃(dropout)을 도입하여 성능을 향상시켰습니다.VGG:깊고 '\n",
      " '규칙적인 구조를 가진 아키텍처로, 작은 3x3 필터를 사용하여 깊이를 증가시켰습니다.VGG16과 VGG19가 대표적인 모델입니다.02. '\n",
      " '실습: CNN을 이용한 이미지 분류 (PyTorch)✔️ 이제 PyTorch를')\n",
      "Top 10 chunks:\n",
      "('\\n'\n",
      " 'Chunk 1:\\n'\n",
      " '[스파르타코딩클럽] 6. 순환 신경망(RNN)📘[SCC] 기초가 탄탄한 딥러닝/📚[스파르타코딩클럽] 기초가 탄탄한 딥러닝 - '\n",
      " '2주차/📕[스파르타코딩클럽] 6. 순환 신경망(RNN)Made with📕[스파르타코딩클럽] 6. 순환 신경망(RNN)[수업 목표]순환 '\n",
      " '신경망(RNN) 개념에 대해서 배워보고 어떤 원리로 동작하는지 알아봅시다Pytorch로 간단한')\n",
      "('\\n'\n",
      " 'Chunk 2:\\n'\n",
      " '알아봅시다Pytorch로 간단한 RNN 모델 구현 실습을 진행해 봅시다[목차]01. RNN의 기본 구조와 동작 원리02. RNN과 '\n",
      " 'LSTM을 이용한 시계열 데이터 예측 (PyTorch)import torch.nn as nn')\n",
      "('\\n'\n",
      " 'Chunk 3:\\n'\n",
      " 'import torch.optim as optim\\n'\n",
      " 'import numpy as np\\n'\n",
      " 'import matplotlib.pyplot as plt\\n'\n",
      " '\\u200b☑️데이터셋 생성 및 전처리데이터셋 생성 및 전처리 {5px}데이터셋 생성 및 전처리 '\n",
      " '\\ufeff\\u200bPythonCopy# Sine 파형 데이터 생성')\n",
      "('\\n'\n",
      " 'Chunk 4:\\n'\n",
      " 'def create_sine_wave_data(seq_length, num_samples):\\n'\n",
      " '    X = []\\n'\n",
      " '    y = []\\n'\n",
      " 'for _ in range(num_samples):\\n'\n",
      " '        start = np.random.rand()\\n'\n",
      " '        x = np.linspace(start, start + 2 * np.pi, seq_length)')\n",
      "('\\n'\n",
      " 'Chunk 5:\\n'\n",
      " 'X.append(np.sin(x))\\n'\n",
      " '        y.append(np.sin(x + 0.1))\\n'\n",
      " 'return np.array(X), np.array(y)')\n",
      "('\\n'\n",
      " 'Chunk 6:\\n'\n",
      " 'seq_length = 50\\n'\n",
      " 'num_samples = 1000\\n'\n",
      " 'X, y = create_sine_wave_data(seq_length, num_samples)\\n'\n",
      " '# 데이터셋을 PyTorch 텐서로 변환\\n'\n",
      " 'X = torch.tensor(X, dtype=torch.float32).unsqueeze(-1)')\n",
      "('\\n'\n",
      " 'Chunk 7:\\n'\n",
      " 'y = torch.tensor(y, dtype=torch.float32).unsqueeze(-1)\\n'\n",
      " '\\u200b☑️ 간단한 RNN 모델 정의간단한 RNN 모델 정의 {5px}간단한 RNN 모델 정의 '\n",
      " '\\ufeff\\u200bPythonCopyclass SimpleRNN(nn.Module):')\n",
      "('\\n'\n",
      " 'Chunk 8:\\n'\n",
      " 'def __init__(self, input_size, hidden_size, output_size):\\n'\n",
      " 'super(SimpleRNN, self).__init__()\\n'\n",
      " '        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)')\n",
      "('\\n'\n",
      " 'Chunk 9:\\n'\n",
      " 'self.fc = nn.Linear(hidden_size, output_size)\\n'\n",
      " 'def forward(self, x):\\n'\n",
      " '        h0 = torch.zeros(1, x.size(0), hidden_size) # 초기 은닉 상태\\n'\n",
      " '        out, _ = self.rnn(x, h0)')\n",
      "'\\nChunk 10:\\nout = self.fc(out[:, -1, :]) # 마지막 시간 단계의 출력\\nreturn out'\n",
      "Top 10 chunks:\n",
      "('\\n'\n",
      " 'Chunk 1:\\n'\n",
      " '[스파르타코딩클럽] 7. 어텐션 (Attention) 메커니즘📘[SCC] 기초가 탄탄한 딥러닝/📚[스파르타코딩클럽] 기초가 탄탄한 딥러닝 '\n",
      " '- 3주차/📕[스파르타코딩클럽] 7. 어텐션 (Attention) 메커니즘Made with📕[스파르타코딩클럽] 7. 어텐션 '\n",
      " '(Attention) 메커니즘[수업 목표]최근 가장 성능 좋은 매커니즘! 어텐션 메커니즘에 대해')\n",
      "('\\n'\n",
      " 'Chunk 2:\\n'\n",
      " '매커니즘! 어텐션 메커니즘에 대해 알아봅시다Pytorch의 구현 예시를 살펴봅시다[목차]01. 개념02. 실습:  Attention '\n",
      " '메커니즘의 구현한번 훑는 정도로 넘어갑시다!1)  Attention☑️ Scaled Dot-Product AttentionScaled '\n",
      " 'Dot-Product attention 메커니즘 구현{5px}Scaled')\n",
      "('\\n'\n",
      " 'Chunk 3:\\n'\n",
      " '메커니즘 구현{5px}Scaled Dot-Product attention 메커니즘 구현\\ufeff\\u200bPythonCopyimport '\n",
      " 'torch')\n",
      "'\\nChunk 4:\\nimport torch.nn.functional as F'\n",
      "('\\n'\n",
      " 'Chunk 5:\\n'\n",
      " 'def scaled_dot_product_attention(Q, K, V):\\n'\n",
      " '    d_k = Q.size(-1) # Key의 차원 수\\n'\n",
      " '    scores = torch.matmul(Q, K.transpose(-2, -1)) / '\n",
      " 'torch.sqrt(torch.tensor(d_k, dtype=torch.float32)) # 유사도 계산 및 스케일링')\n",
      "('\\n'\n",
      " 'Chunk 6:\\n'\n",
      " 'attn_weights = F.softmax(scores, dim=-1) # Softmax를 통한 가중치 계산\\n'\n",
      " '    output = torch.matmul(attn_weights, V) # 가중합을 통한 최종 출력 계산\\n'\n",
      " 'return output, attn_weights')\n",
      "('\\n'\n",
      " 'Chunk 7:\\n'\n",
      " '\\u200b☑️ Multi-Head Attention Multi-Head Attention 메커니즘 구현{5px} Multi-Head '\n",
      " 'Attention 메커니즘 구현\\ufeff\\u200bPythonCopyclass MultiHeadAttention(nn.Module):\\n'\n",
      " 'def __init__(self, embed_size, heads):')\n",
      "('\\n'\n",
      " 'Chunk 8:\\n'\n",
      " 'super(MultiHeadAttention, self).__init__()\\n'\n",
      " '        self.embed_size = embed_size\\n'\n",
      " '        self.heads = heads\\n'\n",
      " '        self.head_dim = embed_size // heads')\n",
      "('\\n'\n",
      " 'Chunk 9:\\n'\n",
      " 'assert (\\n'\n",
      " '            self.head_dim * heads == embed_size\\n'\n",
      " '        ), \"Embedding size needs to be divisible by heads\"')\n",
      "('\\n'\n",
      " 'Chunk 10:\\n'\n",
      " 'self.values = nn.Linear(self.head_dim, self.head_dim, bias=False)\\n'\n",
      " '        self.keys = nn.Linear(self.head_dim, self.head_dim, bias=False)')\n",
      "Top 10 chunks:\n",
      "('\\n'\n",
      " 'Chunk 1:\\n'\n",
      " '[스파르타코딩클럽] 8. 자연어 처리(NLP) 모델📘[SCC] 기초가 탄탄한 딥러닝/📚[스파르타코딩클럽] 기초가 탄탄한 딥러닝 - '\n",
      " '3주차/📕[스파르타코딩클럽] 8. 자연어 처리(NLP) 모델Made with📕[스파르타코딩클럽] 8. 자연어 처리(NLP) 모델[수업 '\n",
      " '목표]자연어 처리 모델에 대해서 알아보고 동작 원리에 대해서 학습해 봅시다Pytorch로')\n",
      "('\\n'\n",
      " 'Chunk 2:\\n'\n",
      " '대해서 학습해 봅시다Pytorch로 간단한 텍스트 분류 및 생성 모델 구현 실습을 진행해 봅시다[목차]01. 워드 임베딩과 시퀀스 '\n",
      " '모델링02. Transformer와 BERT💡모든 토글을 열고 닫는 단축키')\n",
      "'\\nChunk 3:\\nWindows : Ctrl + alt + t'\n",
      "('\\n'\n",
      " 'Chunk 4:\\n'\n",
      " 'Mac : ⌘ + ⌥ + t 01. 워드 임베딩과 시퀀스 모델링✔️워드임베딩 기법이 무엇인지 알아보고 시퀀스 모델링이 무엇인지 학습해 '\n",
      " '봅시다1) 워드 임베딩 기법☑️ 워드 임베딩 기법워드 임베딩(Word Embedding)은 단어를 고정된 크기의 벡터로 변환하는 '\n",
      " '기법으로, 단어 간의 의미적 유사성을 반영합니다.대표적인 워드 임베딩 기법으로는')\n",
      "('\\n'\n",
      " 'Chunk 5:\\n'\n",
      " '워드 임베딩 기법으로는 Word2Vec과 GloVe가 있습니다.ALT☑️ Word2VecWord2Vec은 단어를 벡터로 변환하는 두 가지 '\n",
      " '모델(CBOW와 Skip-gram)을 제공합니다.CBOW (Continuous Bag of Words): 주변 단어(context)로 '\n",
      " '중심 단어(target)를 예측합니다.Skip-gram: 중심 단어(target)로')\n",
      "('\\n'\n",
      " 'Chunk 6:\\n'\n",
      " '중심 단어(target)로 주변 단어(context)를 예측합니다.☑️ GloVe (Global Vectors for Word '\n",
      " 'Representation)GloVe는 단어-단어 공기행렬(word-word co-occurrence matrix)을 사용, 단어 벡터를 '\n",
      " '학습합니다.전역적인 통계 정보를 활용하여 단어 간의 의미적 유사성을 반영합니다.2) 시퀀스')\n",
      "('\\n'\n",
      " 'Chunk 7:\\n'\n",
      " '유사성을 반영합니다.2) 시퀀스 모델링☑️ 시퀀스 모델링의 기본 개념시퀀스 모델링(Sequence Modeling)은 순차적인 데이터를 '\n",
      " '처리하고 예측하는 모델링 기법입니다. 시퀀스 모델링은 주로 RNN, LSTM, GRU와 같은 순환 신경망을 사용합니다.ALT☑️ 입력 '\n",
      " '시퀀스시퀀스 모델링에서는 입력 데이터가 순차적인 형태로 제공됩니다.예를 들어, 텍스트')\n",
      "('\\n'\n",
      " 'Chunk 8:\\n'\n",
      " '제공됩니다.예를 들어, 텍스트 데이터는 단어의 시퀀스로 표현됩니다.☑️ 은닉 상태순환 신경망은 이전 시간 단계의 은닉 상태를 현재 시간 '\n",
      " '단계로 전달하여, 시퀀스의 패턴을 학습합니다.☑️ 출력 시퀀스시퀀스 모델링의 출력은 입력 시퀀스와 동일한 길이의 시퀀스일 수도 있고, '\n",
      " '단일 값일 수도 있습니다.02. Transformer와')\n",
      "('\\n'\n",
      " 'Chunk 9:\\n'\n",
      " 'Transformer와 BERT✔️Transformer의 구조에 대해 알아보고 이를 이용한 BERT 모델에 대해서 배워봅시다1) '\n",
      " 'Transformer의 구조와 원리☑️ Transformer의 구조와 원리Transformer는 순차적인 데이터를 병렬로 처리할 수 있는 '\n",
      " '모델로, 자연어 처리에서 뛰어난 성능을 보입니다.Transformer는')\n",
      "('\\n'\n",
      " 'Chunk 10:\\n'\n",
      " '보입니다.Transformer는 인코더-디코더(Encoder-Decoder) 구조로 구성됩니다.ALT☑️ 인코더 (Encoder)입력 '\n",
      " '시퀀스를 처리하여 인코딩된 표현을 생성합니다.각 인코더 층은 셀프 어텐션(Self-Attention)과 피드포워드 '\n",
      " '신경망(Feed-Forward Neural Network)으로 구성됩니다.☑️ 디코더')\n",
      "Top 10 chunks:\n",
      "('\\n'\n",
      " 'Chunk 1:\\n'\n",
      " '[스파르타코딩클럽] 9. ResNet📘[SCC] 기초가 탄탄한 딥러닝/📚[스파르타코딩클럽] 기초가 탄탄한 딥러닝 - '\n",
      " '4주차/📕[스파르타코딩클럽] 9. ResNetMade with📕[스파르타코딩클럽] 9. ResNet[수업 목표]비전 모델의 길을 열어준 '\n",
      " 'ResNet!왜 좋은 지 한번 알아봅시다[목차]01. 개념import torch.nn as nn')\n",
      "'\\nChunk 2:\\nimport torch.nn.functional as F'\n",
      "('\\n'\n",
      " 'Chunk 3:\\n'\n",
      " 'class Block(nn.Module):\\n'\n",
      " 'def __init__(self, in_ch, out_ch, stride=1):\\n'\n",
      " 'super(Block, self).__init__()\\n'\n",
      " '# 첫 번째 컨볼루션 레이어')\n",
      "('\\n'\n",
      " 'Chunk 4:\\n'\n",
      " '# 첫 번째 컨볼루션 레이어\\n'\n",
      " '        self.conv1 = nn.Conv2d(in_ch, out_ch, kernel_size=3, stride=stride, '\n",
      " 'padding=1, bias=False)\\n'\n",
      " '        self.bn1 = nn.BatchNorm2d(out_ch) # 배치 정규화\\n'\n",
      " '# 두 번째 컨볼루션 레이어')\n",
      "('\\n'\n",
      " 'Chunk 5:\\n'\n",
      " '# 두 번째 컨볼루션 레이어\\n'\n",
      " '        self.conv2 = nn.Conv2d(out_ch, out_ch, kernel_size=3, stride=1, '\n",
      " 'padding=1, bias=False)\\n'\n",
      " '        self.bn2 = nn.BatchNorm2d(out_ch) # 배치 정규화\\n'\n",
      " '# 입력과 출력의 차원이 다를 경우 shortcut 경로 정의')\n",
      "('\\n'\n",
      " 'Chunk 6:\\n'\n",
      " 'self.skip_connection = nn.Sequential()\\n'\n",
      " 'if stride != 1 or in_ch != out_ch:\\n'\n",
      " '            self.skip_connection = nn.Sequential(')\n",
      "('\\n'\n",
      " 'Chunk 7:\\n'\n",
      " 'nn.Conv2d(in_ch, out_ch, kernel_size=1, stride=stride, bias=False), # 차원 맞추기 '\n",
      " '위한 1x1 컨볼루션\\n'\n",
      " '                nn.BatchNorm2d(out_ch) # 배치 정규화\\n'\n",
      " ')\\n'\n",
      " 'def forward(self, x):')\n",
      "('\\n'\n",
      " 'Chunk 8:\\n'\n",
      " '# 첫 번째 컨볼루션 + ReLU 활성화 함수\\n'\n",
      " '        output = F.relu(self.bn1(self.conv1(x)))\\n'\n",
      " '# 두 번째 컨볼루션 후 배치 정규화\\n'\n",
      " '        output = self.bn2(self.conv2(output))\\n'\n",
      " '# shortcut 경로 출력과 현재 블록의 출력 더하기')\n",
      "('\\n'\n",
      " 'Chunk 9:\\n'\n",
      " 'output += self.skip_connection(x)\\n'\n",
      " '# 최종 ReLU 활성화 함수 적용\\n'\n",
      " '        output = F.relu(output)\\n'\n",
      " 'return output')\n",
      "('\\n'\n",
      " 'Chunk 10:\\n'\n",
      " '# ResNet 모델 정의\\n'\n",
      " 'class CustomResNet(nn.Module):\\n'\n",
      " 'def __init__(self, block, layers, num_classes=10):\\n'\n",
      " 'super(CustomResNet, self).__init__()\\n'\n",
      " '        self.initial_channels = 64 # 첫 번째 레이어의 입력 채널 수 정의')\n",
      "Top 10 chunks:\n",
      "('\\n'\n",
      " 'Chunk 1:\\n'\n",
      " '[스파르타코딩클럽] 10. 이미지 처리 모델📘[SCC] 기초가 탄탄한 딥러닝/📚[스파르타코딩클럽] 기초가 탄탄한 딥러닝 - '\n",
      " '4주차/📕[스파르타코딩클럽] 10. 이미지 처리 모델Made with📕[스파르타코딩클럽] 10. 이미지 처리 모델[수업 목표]이미지 처리 '\n",
      " '모델에 대해 배워봅시다Pytorch로 간단한 YOLO 모델 구현 실습을 진행해 봅시다[목차]01.')\n",
      "('\\n'\n",
      " 'Chunk 2:\\n'\n",
      " '실습을 진행해 봅시다[목차]01. CNN기반 이미지 분류이미지의 각 픽셀을 클래스 레이블로 분류합니다이미지의 각 픽셀을 클래스 레이블로 '\n",
      " '분류합니다\\ufeff')\n",
      "'\\nChunk 3:\\n인스턴스 세그멘테이션 (Instance Segmentation)'\n",
      "('\\n'\n",
      " 'Chunk 4:\\n'\n",
      " '시맨틱 세그멘테이션과 달리, 같은 클래스 내에서도 개별 객체를 구분합니다.시맨틱 세그멘테이션과 달리, 같은 클래스 내에서도 개별 객체를 '\n",
      " '구분합니다.\\ufeff\\u200b☑️ 주요 세그멘테이션 모델FCN (Fully Convolutional Network): 모든 레이어를 '\n",
      " '합성곱 레이어로 구성하여, 픽셀 단위의 예측을 수행합니다.U-Net: U자형 구조를 가지며,')\n",
      "('\\n'\n",
      " 'Chunk 5:\\n'\n",
      " 'U자형 구조를 가지며, 인코더-디코더 아키텍처를 사용하여 세그멘테이션을 수행합니다.Mask R-CNN: 객체 탐지와 인스턴스 '\n",
      " '세그멘테이션을 동시에 수행하는 모델입니다.Copyright ⓒ TeamSparta All rights reserved.')\n",
      "Top 10 chunks:\n",
      "('\\n'\n",
      " 'Chunk 1:\\n'\n",
      " '[스파르타코딩클럽] 11. 오토인코더📘[SCC] 기초가 탄탄한 딥러닝/📚[스파르타코딩클럽] 기초가 탄탄한 딥러닝 - '\n",
      " '5주차/📕[스파르타코딩클럽] 11. 오토인코더Made with📕[스파르타코딩클럽] 11. 오토인코더[수업 목표]오토인코더의 개념에 대해 '\n",
      " '알아봅시다[목차]01. 오토인코더02. 오토인코더의 구조💡모든 토글을 열고 닫는 단축키')\n",
      "'\\nChunk 2:\\nWindows : Ctrl + alt + t'\n",
      "('\\n'\n",
      " 'Chunk 3:\\n'\n",
      " 'Mac : ⌘ + ⌥ + t 01. 오토인코더1) 오토인코더의 기본 개념☑️ 오토인코더란?오토인코더(Autoencoder)는 입력 '\n",
      " '데이터를 압축하고, 이를 다시 복원하는 과정을 통해 데이터를 효율적으로 표현하는 비지도 학습 모델입니다. 주로 차원 축소, 잡음 제거, '\n",
      " '생성 모델 등 다양한 분야에서 활용됩니다.2) 동작 원리☑️ 인코더(Encoder)인코더는')\n",
      "('\\n'\n",
      " 'Chunk 4:\\n'\n",
      " '인코더(Encoder)인코더는 입력 데이터를 저차원(latent space) 표현으로 변환하는 역할을 합니다. 인코더의 목적은 중요한 '\n",
      " '특징을 추출하고, 입력 데이터를 압축하는 것입니다.☑️ 디코더(Decoder)디코더는 인코더에 의해 생성된 저차원 표현을 다시 원래의 '\n",
      " '고차원 데이터로 복원하는 역할을 합니다. 디코더의 목적은 입력 데이터를 최대한 원본과')\n",
      "('\\n'\n",
      " 'Chunk 5:\\n'\n",
      " '목적은 입력 데이터를 최대한 원본과 가깝게 복원하는 것입니다.☑️ 잠재 공간(Latent Space)잠재 공간은 인코더에 의해 생성된 '\n",
      " '저차원 표현 공간입니다. 이 공간에서는 입력 데이터의 중요한 특징만을 포함하고 있으며, 디코더는 이를 이용해 원래 데이터를 '\n",
      " '복원합니다.02. 오토인코더의 구조✔️오토인코더의 다양한 구조 및 종류에 대해 알아봅시다1)')\n",
      "('\\n'\n",
      " 'Chunk 6:\\n'\n",
      " '구조 및 종류에 대해 알아봅시다1) 오토인코더의 종류☑️ 기본 오토인코더ALT☑️ 변형된 오토인코더오토인코더는 다양한 변형 모델들이 '\n",
      " '존재합니다. 대표적인 예로는 다음과 같습니다:딥 오토인코더(Deep Autoencoder): 더 깊은 인코더와 디코더 구조를 가지며, '\n",
      " '복잡한 데이터 표현을 학습합니다.변분 오토인코더(Variational')\n",
      "('\\n'\n",
      " 'Chunk 7:\\n'\n",
      " '오토인코더(Variational Autoencoder, VAE): 확률적 잠재 공간을 사용하여 데이터의 분포를 학습합니다.희소 '\n",
      " '오토인코더(Sparse Autoencoder): 잠재 공간의 표현을 희소하게 유지하여 중요한 특징만을 학습합니다.잡음 제거 '\n",
      " '오토인코더(Denoising Autoencoder): 입력 데이터에 잡음을 추가하고, 이를 제거하는 학습을')\n",
      "('\\n'\n",
      " 'Chunk 8:\\n'\n",
      " '추가하고, 이를 제거하는 학습을 통해 데이터 복원 능력을 향상시킵니다.Copyright ⓒ TeamSparta All rights '\n",
      " 'reserved.')\n",
      "Top 10 chunks:\n",
      "('\\n'\n",
      " 'Chunk 1:\\n'\n",
      " '[스파르타코딩클럽] 12. 생성형 모델 📘[SCC] 기초가 탄탄한 딥러닝/📚[스파르타코딩클럽] 기초가 탄탄한 딥러닝 - '\n",
      " '5주차/📕[스파르타코딩클럽] 12. 생성형 모델 Made with📕[스파르타코딩클럽] 12. 생성형 모델 [수업 목표]생성형 모델인 '\n",
      " 'GAN 과 VAE 모델에 대해 배워봅시다[목차]01. GAN(Generative Adversarial')\n",
      "('\\n'\n",
      " 'Chunk 2:\\n'\n",
      " 'Adversarial Network)02. VAE (Variational Autoencoder)💡모든 토글을 열고 닫는 단축키')\n",
      "'\\nChunk 3:\\nWindows : Ctrl + alt + t'\n",
      "('\\n'\n",
      " 'Chunk 4:\\n'\n",
      " 'Mac : ⌘ + ⌥ + t 01. GAN(Generative Adversarial Network)1) GAN의 개념☑️ '\n",
      " 'GAN이란GAN은 2014년 Ian Goodfellow와 그의 동료들에 의해 제안된 생성형 모델입니다GAN은 두 개의 신경망, 즉 '\n",
      " '생성자(Generator)와 판별자(Discriminator)로 구성되어 있습니다.생성자는 가짜 데이터를')\n",
      "('\\n'\n",
      " 'Chunk 5:\\n'\n",
      " '있습니다.생성자는 가짜 데이터를 생성하고, 판별자는 이 데이터가 진짜인지 가짜인지 판별하며, 서로 경쟁하여 동시에 학습합니다ALT2) '\n",
      " '동작 원리☑️ 생성자(Generator)랜덤 노이즈 벡터를 입력으로 받아서 이를 통해 가짜 데이터를 생성합니다생성된 데이터는 판별자에게 '\n",
      " '전달되어 진짜 데이터처럼 보이도록 학습됩니다.☑️ 판별자(Discriminator)진짜')\n",
      "('\\n'\n",
      " 'Chunk 6:\\n'\n",
      " '데이터와 생성된 가짜 데이터를 입력으로 받아서 이를 구분하는 역할을 합니다판별자는 진짜 데이터를 1로, 가짜 데이터를 0으로 분류하도록 '\n",
      " '학습됩니다.☑️ 경쟁 과정생성자는 판별자를 속이기 위해 점점 더 진짜 같은 데이터를 생성하려고 노력하게 됩니다.판별자는 생성자가 만든 '\n",
      " '가짜 데이터를 더 잘 구분하려고 노력하게 됩니다이 과정에서 두 네트워크는 서로 경쟁하며')\n",
      "('\\n'\n",
      " 'Chunk 7:\\n'\n",
      " '두 네트워크는 서로 경쟁하며 동시에 발전하게 됩니다02. VAE (Variational Autoencoder)✔️생성형 모델중 하나인 '\n",
      " 'VAE모델이 무엇인지, 어디에 사용할 수 있을지 알아 봅시다.1) VAE의 개념☑️ VAE이란?VAE는 2013년 Kingma와 '\n",
      " 'Welling에 의해 제안된 생성형 모델입니다.VAE는 인코더(Encoder)와')\n",
      "('\\n'\n",
      " 'Chunk 8:\\n'\n",
      " '인코더(Encoder)와 디코더(Decoder)로 구성된 오토인코더의 변형입니다.인코더는 입력 데이터를 잠재 공간(latent '\n",
      " 'space)으로 매핑하고, 디코더는 이 잠재 공간에서 데이터를 다시 원래 공간으로 복원합니다.VAE는 잠재 공간을 확률 분포로 '\n",
      " '모델링하여, 새로운 데이터를 생성할 수 있는 능력을 갖추게 됩니다.ALT2) 응용☑️ 이미지')\n",
      "('\\n'\n",
      " 'Chunk 9:\\n'\n",
      " '됩니다.ALT2) 응용☑️ 이미지 생성VAE는 새로운 이미지를 생성하는 데 사용될 수 있다.예를 들어, 얼굴 이미지 데이터셋을 학습한 '\n",
      " 'VAE는 새로운 얼굴 이미지를 생성할 수 있다.☑️ 데이터 압축VAE는 데이터를 잠재 공간으로 압축하고, 이를 통해 데이터 압축 및 '\n",
      " '복원에 사용할 수 있다.☑️ 노이즈 제거VAE는 노이즈가 있는 데이터를 입력으로 받아서')\n",
      "('\\n'\n",
      " 'Chunk 10:\\n'\n",
      " '있는 데이터를 입력으로 받아서 노이즈를 제거한 깨끗한 데이터를 출력할 수 있다.Copyright ⓒ TeamSparta All '\n",
      " 'rights reserved.')\n",
      "Top 10 chunks:\n",
      "('\\n'\n",
      " 'Chunk 1:\\n'\n",
      " '[스파르타코딩클럽] 13. 전이학습📘[SCC] 기초가 탄탄한 딥러닝/📚[스파르타코딩클럽] 기초가 탄탄한 딥러닝 - '\n",
      " '5주차/📕[스파르타코딩클럽] 13. 전이학습Made with📕[스파르타코딩클럽] 13. 전이학습[수업 목표]전이학습에 대해서 배워보고, '\n",
      " '언제 전이학습을 사용하는지 알아 봅시다Pytorch로 사전 학습된 모델을 이용해 전이학습 구현 실습을 진행해')\n",
      "'\\nChunk 2:\\n이용해 전이학습 구현 실습을 진행해 봅시다[목차]01. 전이학습💡모든 토글을 열고 닫는 단축키'\n",
      "'\\nChunk 3:\\nWindows : Ctrl + alt + t'\n",
      "('\\n'\n",
      " 'Chunk 4:\\n'\n",
      " 'Mac : ⌘ + ⌥ + t 01. 전이학습✔️전이학습이란 무엇인지, 어떨때 적용하는지 배워봅시다1) 전이학습의 필요성과 원리☑️ 전이 '\n",
      " '학습이란?전이학습(Transfer Learning)은 이미 학습된 모델의 지식을 새로운 문제에 적용하는 방법입니다. 전이학습은 특히 '\n",
      " '데이터가 부족한 상황에서 유용하며, 모델 학습 시간을 단축하고 성능을 향상시킬 수')\n",
      "('\\n'\n",
      " 'Chunk 5:\\n'\n",
      " '시간을 단축하고 성능을 향상시킬 수 있습니다.ALT☑️ 전이학습의 필요성데이터 부족: 새로운 문제에 대한 데이터가 충분하지 않을 때, '\n",
      " '전이학습을 통해 기존 모델의 지식을 활용할 수 있습니다.학습 시간 단축: 사전 학습된 모델 사용시, 처음부터 모델을 학습하는것 보다 '\n",
      " '빠르게 학습할 수 있습니다.성능 향상: 사전 학습된 모델은 대규모 데이터셋에서 학습되었기')\n",
      "('\\n'\n",
      " 'Chunk 6:\\n'\n",
      " '대규모 데이터셋에서 학습되었기 때문에, 통상 더 나은 성능을 보입니다.☑️ 전이학습의 원리특징 추출기 (Feature '\n",
      " 'Extractor): 사전 학습된 모델의 초기 층을 고정하고, 새로운 데이터에 맞게 마지막 층만 재학습합니다.미세 조정 '\n",
      " '(Fine-Tuning): 사전 학습된 모델 전체를 새로운 데이터에 맞게 재학습합니다.2) 전이학습을 통해 모델 만들어')\n",
      "('\\n'\n",
      " 'Chunk 7:\\n'\n",
      " '전이학습을 통해 모델 만들어 보기☑️ 전이학습을 적용한 모델 구축 과정 사전 학습된 모델 로드:PyTorch에서 제공하는 사전 학습된 '\n",
      " '모델을 로드합니다.예를 들어, ResNet, VGG, Inception 등의 모델을 사용할 수 있습니다.모델 수정:사전 학습된 모델의 '\n",
      " '마지막 층을 새로운 문제에 맞게 수정합니다.예를 들어, 이미지 분류 문제에서 클래스 수를')\n",
      "('\\n'\n",
      " 'Chunk 8:\\n'\n",
      " '이미지 분류 문제에서 클래스 수를 변경합니다.모델 학습:수정된 모델을 새로운 데이터에 맞게 학습시킵니다.특징 추출기 방식이나 미세 조정 '\n",
      " '방식을 사용할 수 있습니다.Copyright ⓒ TeamSparta All rights reserved.')\n",
      "Top 10 chunks:\n",
      "('\\n'\n",
      " 'Chunk 1:\\n'\n",
      " '[스파르타코딩클럽] 14. 과적합 방지 기법📘[SCC] 기초가 탄탄한 딥러닝/📚[스파르타코딩클럽] 기초가 탄탄한 딥러닝 - '\n",
      " '6주차/📕[스파르타코딩클럽] 14. 과적합 방지 기법Made with📕[스파르타코딩클럽] 14. 과적합 방지 기법[수업 목표]여러 과적합 '\n",
      " '방지 기법에 대해서 알아봅시다.Pytorch로  과적합 방지 기법에 대한 실습 예시![목차]01.')\n",
      "('\\n'\n",
      " 'Chunk 2:\\n'\n",
      " '대한 실습 예시![목차]01. 과적화 방지 기법02. 과적합 방지기법 실습(Pytorch)import torch.nn as nn')\n",
      "('\\n'\n",
      " 'Chunk 3:\\n'\n",
      " 'import torch.optim as optim\\n'\n",
      " 'import torchvision\\n'\n",
      " 'import torchvision.transforms as transforms\\n'\n",
      " '\\u200b☑️데이터셋 로드 및 전처리데이터셋 로드 및 전처리 {5px}데이터셋 로드 및 전처리 '\n",
      " '\\ufeff\\u200bPythonCopy# 데이터셋 전처리\\n'\n",
      " 'transform = transforms.Compose([')\n",
      "('\\n'\n",
      " 'Chunk 4:\\n'\n",
      " 'transforms.Resize((224, 224)),\\n'\n",
      " '    transforms.ToTensor(),\\n'\n",
      " '    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\\n'\n",
      " '])\\n'\n",
      " '# CIFAR-10 데이터셋 로드')\n",
      "('\\n'\n",
      " 'Chunk 5:\\n'\n",
      " '# CIFAR-10 데이터셋 로드\\n'\n",
      " \"trainset = torchvision.datasets.CIFAR10(root='./data', train=True, \"\n",
      " 'download=True, transform=transform)')\n",
      "('\\n'\n",
      " 'Chunk 6:\\n'\n",
      " 'trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, '\n",
      " 'shuffle=True)')\n",
      "('\\n'\n",
      " 'Chunk 7:\\n'\n",
      " \"testset = torchvision.datasets.CIFAR10(root='./data', train=False, \"\n",
      " 'download=True, transform=transform)\\n'\n",
      " 'testloader = torch.utils.data.DataLoader(testset, batch_size=64, '\n",
      " 'shuffle=False)')\n",
      "('\\n'\n",
      " 'Chunk 8:\\n'\n",
      " '\\u200b☑️  드롭아웃과 배치 정규화를 적용한 모델 정의 드롭아웃과 배치 정규화를 적용한 모델 정의 {5px} 드롭아웃과 배치 '\n",
      " '정규화를 적용한 모델 정의 \\ufeff\\u200bPythonCopyclass '\n",
      " 'CNNWithDropoutAndBatchNorm(nn.Module):\\n'\n",
      " 'def __init__(self):')\n",
      "('\\n'\n",
      " 'Chunk 9:\\n'\n",
      " 'def __init__(self):\\n'\n",
      " 'super(CNNWithDropoutAndBatchNorm, self).__init__()\\n'\n",
      " '        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\\n'\n",
      " '        self.bn1 = nn.BatchNorm2d(64)')\n",
      "('\\n'\n",
      " 'Chunk 10:\\n'\n",
      " 'self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\\n'\n",
      " '        self.bn2 = nn.BatchNorm2d(128)\\n'\n",
      " '        self.fc1 = nn.Linear(128 * 56 * 56, 256)\\n'\n",
      " '        self.dropout = nn.Dropout(0.5)')\n",
      "Top 10 chunks:\n",
      "('\\n'\n",
      " 'Chunk 1:\\n'\n",
      " '[스파르타코딩클럽] 15. 하이퍼파라미터 튜닝📘[SCC] 기초가 탄탄한 딥러닝/📚[스파르타코딩클럽] 기초가 탄탄한 딥러닝 - '\n",
      " '6주차/📕[스파르타코딩클럽] 15. 하이퍼파라미터 튜닝Made with📕[스파르타코딩클럽] 15. 하이퍼파라미터 튜닝[수업 목표]주요 '\n",
      " '하이퍼파라미터 종류와 자동화 튜닝방법에 대해 배워봅시다[목차]01. 하이퍼파라미터 튜닝 방법💡모든')\n",
      "'\\nChunk 2:\\n하이퍼파라미터 튜닝 방법💡모든 토글을 열고 닫는 단축키'\n",
      "'\\nChunk 3:\\nWindows : Ctrl + alt + t'\n",
      "('\\n'\n",
      " 'Chunk 4:\\n'\n",
      " 'Mac : ⌘ + ⌥ + t 01. 하이퍼파라미터 튜닝 방법✔️하이퍼파라미터란 무엇인지, 주요 하이퍼파라미터엔 어떤것들이 있는지 '\n",
      " '알아보고, 자동 튜닝기법에 대해 배워봅시다.1) 주요 하이퍼파라미터와 튜닝 방법☑️ 하이퍼파라미터란?하이퍼파라미터는 모델 학습 과정에서 '\n",
      " '사용자가 설정해야 하는 값으로, 모델의 성능에 큰 영향을 미칩니다.ALT☑️ 학습률')\n",
      "('\\n'\n",
      " 'Chunk 5:\\n'\n",
      " '영향을 미칩니다.ALT☑️ 학습률 (Learning Rate)학습률은 모델의 가중치를 업데이트하는 속도를 결정합니다.너무 크면 학습이 '\n",
      " '불안정해지고, 너무 작으면 학습이 느려집니다.일반적으로 0.1, 0.01, 0.001 등의 값을 시도해볼 수 있습니다.☑️ 배치 크기 '\n",
      " '(Batch Size)배치 크기는 한 번의 업데이트에 사용되는 데이터 샘플의 수를')\n",
      "('\\n'\n",
      " 'Chunk 6:\\n'\n",
      " '사용되는 데이터 샘플의 수를 결정합니다.큰 배치 크기는 학습 속도를 높이지만, 메모리 사용량이 증가합니다.일반적으로 32, 64, 128 '\n",
      " '등의 값을 시도해볼 수 있습니다.☑️ 에포크 수 (Number of Epochs)에포크 수는 전체 데이터셋을 몇 번 반복하여 학습할지를 '\n",
      " '결정합니다.너무 적으면 과소적합이 발생하고, 너무 많으면 과적합이 발생할 수')\n",
      "('\\n'\n",
      " 'Chunk 7:\\n'\n",
      " '너무 많으면 과적합이 발생할 수 있습니다.조기 종료(Early Stopping) 기법을 사용하여 적절한 에포크 수를 결정할 수 '\n",
      " '있습니다.☑️ 모멘텀 (Momentum)모멘텀은 이전 기울기를 현재 기울기에 반영하여, 학습 속도를 높이고 진동을 줄입니다.일반적으로 '\n",
      " '0.9, 0.99 등의 값을 시도해볼 수 있습니다.☑️ 가중치 초기화 (Weight')\n",
      "('\\n'\n",
      " 'Chunk 8:\\n'\n",
      " '가중치 초기화 (Weight Initialization)가중치 초기화는 모델의 가중치를 초기화하는 방법을 결정합니다.일반적으로 '\n",
      " 'Xavier 초기화, He 초기화 등을 사용합니다.2) 하이퍼파라미터 자동 튜닝 기법☑️ Grid Search하이퍼파라미터의 모든 조합을 '\n",
      " '시도하여 최적의 값을 찾습니다.계산 비용이 많이 들지만, 모든 조합을 탐색할 수')\n",
      "('\\n'\n",
      " 'Chunk 9:\\n'\n",
      " '들지만, 모든 조합을 탐색할 수 있습니다.☑️ Random Search하이퍼파라미터 공간에서 무작위로 값을 선택하여 최적의 값을 '\n",
      " '찾습니다.Grid Search보다 계산 비용이 적고, 더 넓은 하이퍼파라미터 공간을 탐색할 수 있습니다.☑️ Bayesian '\n",
      " 'Optimization베이지안 최적화는 이전 평가 결과를 바탕으로, 다음 평가할 하이퍼파라미터를')\n",
      "('\\n'\n",
      " 'Chunk 10:\\n'\n",
      " '다음 평가할 하이퍼파라미터를 선택합니다.계산 비용이 적고, 효율적으로 최적의 값을 찾을 수 있습니다.Copyright ⓒ '\n",
      " 'TeamSparta All rights reserved.')\n"
     ]
    }
   ],
   "source": [
    "retriever_list = []\n",
    "\n",
    "docs_1_retriever = get_retriever(text_list[0])\n",
    "retriever_list.append(docs_1_retriever)\n",
    "docs_2_retriever = get_retriever(text_list[1])\n",
    "retriever_list.append(docs_2_retriever)\n",
    "docs_3_retriever = get_retriever(text_list[2])\n",
    "retriever_list.append(docs_3_retriever)\n",
    "docs_4_retriever = get_retriever(text_list[3])\n",
    "retriever_list.append(docs_4_retriever)\n",
    "docs_5_retriever = get_retriever(text_list[4])\n",
    "retriever_list.append(docs_5_retriever)\n",
    "docs_6_retriever = get_retriever(text_list[5])\n",
    "retriever_list.append(docs_6_retriever)\n",
    "docs_7_retriever = get_retriever(text_list[6])\n",
    "retriever_list.append(docs_7_retriever)\n",
    "docs_8_retriever = get_retriever(text_list[7])\n",
    "retriever_list.append(docs_8_retriever)\n",
    "docs_9_retriever = get_retriever(text_list[8])\n",
    "retriever_list.append(docs_9_retriever)\n",
    "docs_10_retriever = get_retriever(text_list[9])\n",
    "retriever_list.append(docs_10_retriever)\n",
    "docs_11_retriever = get_retriever(text_list[10])\n",
    "retriever_list.append(docs_11_retriever)\n",
    "docs_12_retriever = get_retriever(text_list[11])\n",
    "retriever_list.append(docs_12_retriever)\n",
    "docs_13_retriever = get_retriever(text_list[12])\n",
    "retriever_list.append(docs_13_retriever)\n",
    "docs_14_retriever = get_retriever(text_list[13])\n",
    "retriever_list.append(docs_14_retriever)\n",
    "docs_15_retriever = get_retriever(text_list[14])\n",
    "retriever_list.append(docs_15_retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DebugPassThrough(RunnablePassthrough):\n",
    "    def invoke(self, *args, **kwargs):\n",
    "        output = super().invoke(*args, **kwargs)\n",
    "        print(\"Debug Output:\", output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt 및 Chain 구성\n",
    "class ContextToText(RunnablePassthrough):\n",
    "    def invoke(self, inputs, config=None, **kwargs):  # config 인수 추가\n",
    "        # context의 각 문서를 문자열로 결합\n",
    "        context_text = \" \".join([doc.page_content for doc in inputs[\"context\"]])\n",
    "        print(f\"Context output: {context_text}\")\n",
    "        return {\"context\": context_text, \"quiz_list\": inputs[\"quiz_list\"]}\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"\n",
    "    당신은 딥러닝을 가르치는 AI 강사입니다.\n",
    "    아래의 {context} 바탕으로만 하나의 질문과 답변 한 쌍을 생성해주세요.\n",
    "    (최대한 코드에 관한 시나리오적 질문이면 더 좋습니다.)\n",
    "    {quiz_list}에 존재하는 질문들과는 최대한 덜 유사한 질문을 생성해주세요.\n",
    "    아래의 제약 조건과 출제 방식에 맞춘 질문을 생성해주세요.\n",
    "     \n",
    "    제약 조건:\n",
    "    1. \"Context\"에서 제공된 내용만 기반으로 질문을 생성하세요.\n",
    "    2. AI 관련 내용이 아닌 질문은 생성하지 마세요\n",
    "    3. \"QuizList\"에 이미 있는 질문과 유사하지 않은 새로운 질문을 생성하세요.\n",
    "\n",
    "    출제 방식:\n",
    "    - 질문은 반드시 보기가 있는 객관식(MCQ) 또는 O,X 형태로 출제하세요.\n",
    "    - \"Context\"에 명시적으로 언급된 개념, 정의, 또는 내용을 활용하세요.\n",
    "    \n",
    "    Context:\n",
    "    {context}\n",
    "    \n",
    "    QuizList:\n",
    "    {quiz_list}\n",
    "\n",
    "    \"\"\")\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG Chain 생성 함수\n",
    "def create_rag_chain(retriever):\n",
    "    return (\n",
    "        {\n",
    "            \"context\": retriever,\n",
    "            \"quiz_list\": DebugPassThrough()\n",
    "        }\n",
    "        | DebugPassThrough()  # DebugPassThrough()가 실제로 어떤 역할을 하는지 확인\n",
    "        | ContextToText()     # Text 변환을 위한 ContextToText\n",
    "        | prompt              # prompt 사용\n",
    "        | llm                 # LLM 호출\n",
    "        | StrOutputParser()   # 출력 파서\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 트러블 슈팅 (cosine 유사도 기반 유사한 문장 제외 코드)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "# from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# # 임베딩을 가져오는 함수\n",
    "# def get_embeddings(text, api_key):\n",
    "#     \"\"\"텍스트를 임베딩 벡터로 변환\"\"\"\n",
    "#     embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\", api_key=api_key)\n",
    "#     return embeddings.embed_documents([text])[0]  # 텍스트를 임베딩 벡터로 변환\n",
    "\n",
    "# # 코사인 유사도 계산 함수\n",
    "# def calculate_cosine_similarity(embedding1, embedding2):\n",
    "#     \"\"\"두 벡터 간의 코사인 유사도를 계산\"\"\"\n",
    "#     return cosine_similarity([embedding1], [embedding2])[0][0]\n",
    "\n",
    "# # 유사한 퀴즈가 있는지 확인하는 함수\n",
    "# def is_similar_to_existing_quizzes(quiz, quiz_list, api_key, threshold=0.8):\n",
    "#     \"\"\"\n",
    "#     주어진 퀴즈가 quiz_list에 있는 퀴즈들과 유사한지 비교하여\n",
    "#     유사도가 threshold 이상이면 True를 반환하고, 그렇지 않으면 False를 반환.\n",
    "#     \"\"\"\n",
    "#     quiz_embedding = get_embeddings(quiz, api_key)  # 새로 생성한 퀴즈의 임베딩 벡터\n",
    "    \n",
    "#     for existing_quiz in quiz_list:\n",
    "#         existing_quiz_embedding = get_embeddings(existing_quiz, api_key)\n",
    "#         similarity = calculate_cosine_similarity(quiz_embedding, existing_quiz_embedding)\n",
    "        \n",
    "#         if similarity > threshold:  # 유사도가 threshold 이상이면 유사한 퀴즈로 간주\n",
    "#             return True\n",
    "#     return False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 동작부분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "퀴즈를 생성합니다 ===============\n",
      "Debug Output: 퀴즈 하나를 생성해줘\n",
      "Debug Output: {'context': [Document(metadata={}, page_content='CT 스캔 이미지를 분석하여 암을 조기에 발견할 수 있습니다.03. 딥러닝을 배워야 하는 이유✔️그러면 왜? 딥러닝을 배워야 하는지 이유를 알아 봅시다1) 딥러닝을 배워야 하는 이유'), Document(metadata={}, page_content='음성 인식딥러닝은 음성 인식 시스템의 성능을 크게 향상시켰습니다.예를 들어, 애플의 Siri, 아마존의 Alexa와 같은 가상 비서는 딥러닝을 사용하여 사용자의 음성을 인식하고 명령을 수행합니다.☑️ 의료 분야의료 영상 분석, 질병 예측, 신약 개발 등 다양한 의료 분야에서도 활용됩니다.예를 들어, 딥러닝 모델은 MRI나 CT 스캔 이미지를 분석하여 암을'), Document(metadata={}, page_content='[스파르타코딩클럽] 1. 딥러닝 개념을 잡아봅시다!📘[SCC] 기초가 탄탄한 딥러닝/📚[스파르타코딩클럽] 기초가 탄탄한 딥러닝 - 1주차/📕[스파르타코딩클럽] 1. 딥러닝 개념을 잡아봅시다!Made with📕[스파르타코딩클럽] 1. 딥러닝 개념을 잡아봅시다![수업 목표]딥러닝이 무엇인지 개념에 대해 알아봅시다.딥러닝의 역사와 어디에 사용할 수 있을지'), Document(metadata={}, page_content='역사와 어디에 사용할 수 있을지 알아봅시다[목차]01. 딥러닝이란 무엇일까요?02. 딥러닝의 역사와 활용 방안03. 딥러닝을 배워야 하는 이유💡모든 토글을 열고 닫는 단축키'), Document(metadata={}, page_content='이미지 생성 등 다양한 이미지 처리 작업에 활용됩니다. 예를 들어, 자율 주행 자동차는 딥러닝을 사용하여 도로 상황을 인식하고, 보행자와 차량을 감지합니다.☑️ 자연어 처리번역, 요약, 감정 분석 등 자연어 처리 작업에 사용됩니다. 예를 들어, 구글 번역은 딥러닝 모델을 사용하여 다양한 언어 간의 번역을 수행합니다.☑️ 음성 인식딥러닝은 음성 인식'), Document(metadata={}, page_content='통해 복잡한 문제를 해결합니다.입력 데이터에서 중요한 패턴을 추출하고, 이를 바탕으로 예측, 분류, 생성 등의 다양한 작업을 수행할 수 있습니다.ALT☑️ 딥러닝의 특징비선형 추론: 딥러닝은 비선형 추론을 통해 복잡한 데이터의 패턴을 학습할 수 있습니다.다층 구조: 여러 층의 신경망을 사용하여 데이터의 고차원 특징을 학습합니다.자동 특징 추출:'), Document(metadata={}, page_content='지도 학습, 비지도 학습, 강화 학습 등의 방법을 포함합니다.딥러닝(DL) : 딥러닝은 머신러닝의 하위 분야로, 다층 신경망을 사용하여 데이터를 학습합니다. 딥러닝은 특히 대규모 데이터와 복잡한 문제를 다루는 데 강력한 성능을 발휘합니다.ALT2) 최근의 활용 방안☑️ 이미지 인식딥러닝은 이미지 분류, 객체 검출, 이미지 생성 등 다양한 이미지 처리')], 'quiz_list': '퀴즈 하나를 생성해줘'}\n",
      "Context output: CT 스캔 이미지를 분석하여 암을 조기에 발견할 수 있습니다.03. 딥러닝을 배워야 하는 이유✔️그러면 왜? 딥러닝을 배워야 하는지 이유를 알아 봅시다1) 딥러닝을 배워야 하는 이유 음성 인식딥러닝은 음성 인식 시스템의 성능을 크게 향상시켰습니다.예를 들어, 애플의 Siri, 아마존의 Alexa와 같은 가상 비서는 딥러닝을 사용하여 사용자의 음성을 인식하고 명령을 수행합니다.☑️ 의료 분야의료 영상 분석, 질병 예측, 신약 개발 등 다양한 의료 분야에서도 활용됩니다.예를 들어, 딥러닝 모델은 MRI나 CT 스캔 이미지를 분석하여 암을 [스파르타코딩클럽] 1. 딥러닝 개념을 잡아봅시다!📘[SCC] 기초가 탄탄한 딥러닝/📚[스파르타코딩클럽] 기초가 탄탄한 딥러닝 - 1주차/📕[스파르타코딩클럽] 1. 딥러닝 개념을 잡아봅시다!Made with📕[스파르타코딩클럽] 1. 딥러닝 개념을 잡아봅시다![수업 목표]딥러닝이 무엇인지 개념에 대해 알아봅시다.딥러닝의 역사와 어디에 사용할 수 있을지 역사와 어디에 사용할 수 있을지 알아봅시다[목차]01. 딥러닝이란 무엇일까요?02. 딥러닝의 역사와 활용 방안03. 딥러닝을 배워야 하는 이유💡모든 토글을 열고 닫는 단축키 이미지 생성 등 다양한 이미지 처리 작업에 활용됩니다. 예를 들어, 자율 주행 자동차는 딥러닝을 사용하여 도로 상황을 인식하고, 보행자와 차량을 감지합니다.☑️ 자연어 처리번역, 요약, 감정 분석 등 자연어 처리 작업에 사용됩니다. 예를 들어, 구글 번역은 딥러닝 모델을 사용하여 다양한 언어 간의 번역을 수행합니다.☑️ 음성 인식딥러닝은 음성 인식 통해 복잡한 문제를 해결합니다.입력 데이터에서 중요한 패턴을 추출하고, 이를 바탕으로 예측, 분류, 생성 등의 다양한 작업을 수행할 수 있습니다.ALT☑️ 딥러닝의 특징비선형 추론: 딥러닝은 비선형 추론을 통해 복잡한 데이터의 패턴을 학습할 수 있습니다.다층 구조: 여러 층의 신경망을 사용하여 데이터의 고차원 특징을 학습합니다.자동 특징 추출: 지도 학습, 비지도 학습, 강화 학습 등의 방법을 포함합니다.딥러닝(DL) : 딥러닝은 머신러닝의 하위 분야로, 다층 신경망을 사용하여 데이터를 학습합니다. 딥러닝은 특히 대규모 데이터와 복잡한 문제를 다루는 데 강력한 성능을 발휘합니다.ALT2) 최근의 활용 방안☑️ 이미지 인식딥러닝은 이미지 분류, 객체 검출, 이미지 생성 등 다양한 이미지 처리\n",
      "Quiz : **Question:**\n",
      "\n",
      "딥러닝은 MRI나 CT 스캔 이미지를 분석하여 암을 조기에 발견하는 데 활용될 수 있습니다. 이러한 딥러닝의 활용 분야는 무엇인가요?\n",
      "\n",
      "A) 자연어 처리  \n",
      "B) 음성 인식  \n",
      "C) 의료 영상 분석  \n",
      "D) 자율 주행\n",
      "\n",
      "**Answer:**\n",
      "\n",
      "C) 의료 영상 분석\n",
      "TEXT 파일 저장 완료: quiz_list_1.txt\n",
      "Updated quiz_list: ['**Question:**\\n\\n딥러닝은 MRI나 CT 스캔 이미지를 분석하여 암을 조기에 발견하는 데 활용될 수 있습니다. 이러한 딥러닝의 활용 분야는 무엇인가요?\\n\\nA) 자연어 처리  \\nB) 음성 인식  \\nC) 의료 영상 분석  \\nD) 자율 주행\\n\\n**Answer:**\\n\\nC) 의료 영상 분석']\n",
      "Feedback:\n",
      "AIMessage(content='- 정답 여부: 예\\n- 추가 설명: 딥러닝은 의료 영상 분석 분야에서 중요한 역할을 합니다. 딥러닝 모델은 MRI, CT 스캔과 같은 의료 이미지를 분석하여 질병을 조기에 발견하고 진단하는 데 도움을 줄 수 있습니다. 이는 의료 영상의 복잡한 패턴을 인식하고 분석하는 능력을 가지고 있기 때문입니다. 반면에, 자연어 처리, 음성 인식, 자율 주행은 각각 텍스트 데이터, 음성 데이터, 자율 주행 차량과 관련된 다른 딥러닝 응용 분야입니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 130, 'prompt_tokens': 182, 'total_tokens': 312, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_7f6be3efb0', 'finish_reason': 'stop', 'logprobs': None}, id='run-3b30d36a-647b-491c-97e6-2c391e795a92-0', usage_metadata={'input_tokens': 182, 'output_tokens': 130, 'total_tokens': 312, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})\n",
      "퀴즈를 생성합니다 ===============\n",
      "Debug Output: 퀴즈 하나를 생성해줘\n",
      "Debug Output: {'context': [Document(metadata={}, page_content='CT 스캔 이미지를 분석하여 암을 조기에 발견할 수 있습니다.03. 딥러닝을 배워야 하는 이유✔️그러면 왜? 딥러닝을 배워야 하는지 이유를 알아 봅시다1) 딥러닝을 배워야 하는 이유'), Document(metadata={}, page_content='음성 인식딥러닝은 음성 인식 시스템의 성능을 크게 향상시켰습니다.예를 들어, 애플의 Siri, 아마존의 Alexa와 같은 가상 비서는 딥러닝을 사용하여 사용자의 음성을 인식하고 명령을 수행합니다.☑️ 의료 분야의료 영상 분석, 질병 예측, 신약 개발 등 다양한 의료 분야에서도 활용됩니다.예를 들어, 딥러닝 모델은 MRI나 CT 스캔 이미지를 분석하여 암을'), Document(metadata={}, page_content='[스파르타코딩클럽] 1. 딥러닝 개념을 잡아봅시다!📘[SCC] 기초가 탄탄한 딥러닝/📚[스파르타코딩클럽] 기초가 탄탄한 딥러닝 - 1주차/📕[스파르타코딩클럽] 1. 딥러닝 개념을 잡아봅시다!Made with📕[스파르타코딩클럽] 1. 딥러닝 개념을 잡아봅시다![수업 목표]딥러닝이 무엇인지 개념에 대해 알아봅시다.딥러닝의 역사와 어디에 사용할 수 있을지'), Document(metadata={}, page_content='역사와 어디에 사용할 수 있을지 알아봅시다[목차]01. 딥러닝이란 무엇일까요?02. 딥러닝의 역사와 활용 방안03. 딥러닝을 배워야 하는 이유💡모든 토글을 열고 닫는 단축키'), Document(metadata={}, page_content='이미지 생성 등 다양한 이미지 처리 작업에 활용됩니다. 예를 들어, 자율 주행 자동차는 딥러닝을 사용하여 도로 상황을 인식하고, 보행자와 차량을 감지합니다.☑️ 자연어 처리번역, 요약, 감정 분석 등 자연어 처리 작업에 사용됩니다. 예를 들어, 구글 번역은 딥러닝 모델을 사용하여 다양한 언어 간의 번역을 수행합니다.☑️ 음성 인식딥러닝은 음성 인식'), Document(metadata={}, page_content='통해 복잡한 문제를 해결합니다.입력 데이터에서 중요한 패턴을 추출하고, 이를 바탕으로 예측, 분류, 생성 등의 다양한 작업을 수행할 수 있습니다.ALT☑️ 딥러닝의 특징비선형 추론: 딥러닝은 비선형 추론을 통해 복잡한 데이터의 패턴을 학습할 수 있습니다.다층 구조: 여러 층의 신경망을 사용하여 데이터의 고차원 특징을 학습합니다.자동 특징 추출:'), Document(metadata={}, page_content='지도 학습, 비지도 학습, 강화 학습 등의 방법을 포함합니다.딥러닝(DL) : 딥러닝은 머신러닝의 하위 분야로, 다층 신경망을 사용하여 데이터를 학습합니다. 딥러닝은 특히 대규모 데이터와 복잡한 문제를 다루는 데 강력한 성능을 발휘합니다.ALT2) 최근의 활용 방안☑️ 이미지 인식딥러닝은 이미지 분류, 객체 검출, 이미지 생성 등 다양한 이미지 처리')], 'quiz_list': '퀴즈 하나를 생성해줘'}\n",
      "Context output: CT 스캔 이미지를 분석하여 암을 조기에 발견할 수 있습니다.03. 딥러닝을 배워야 하는 이유✔️그러면 왜? 딥러닝을 배워야 하는지 이유를 알아 봅시다1) 딥러닝을 배워야 하는 이유 음성 인식딥러닝은 음성 인식 시스템의 성능을 크게 향상시켰습니다.예를 들어, 애플의 Siri, 아마존의 Alexa와 같은 가상 비서는 딥러닝을 사용하여 사용자의 음성을 인식하고 명령을 수행합니다.☑️ 의료 분야의료 영상 분석, 질병 예측, 신약 개발 등 다양한 의료 분야에서도 활용됩니다.예를 들어, 딥러닝 모델은 MRI나 CT 스캔 이미지를 분석하여 암을 [스파르타코딩클럽] 1. 딥러닝 개념을 잡아봅시다!📘[SCC] 기초가 탄탄한 딥러닝/📚[스파르타코딩클럽] 기초가 탄탄한 딥러닝 - 1주차/📕[스파르타코딩클럽] 1. 딥러닝 개념을 잡아봅시다!Made with📕[스파르타코딩클럽] 1. 딥러닝 개념을 잡아봅시다![수업 목표]딥러닝이 무엇인지 개념에 대해 알아봅시다.딥러닝의 역사와 어디에 사용할 수 있을지 역사와 어디에 사용할 수 있을지 알아봅시다[목차]01. 딥러닝이란 무엇일까요?02. 딥러닝의 역사와 활용 방안03. 딥러닝을 배워야 하는 이유💡모든 토글을 열고 닫는 단축키 이미지 생성 등 다양한 이미지 처리 작업에 활용됩니다. 예를 들어, 자율 주행 자동차는 딥러닝을 사용하여 도로 상황을 인식하고, 보행자와 차량을 감지합니다.☑️ 자연어 처리번역, 요약, 감정 분석 등 자연어 처리 작업에 사용됩니다. 예를 들어, 구글 번역은 딥러닝 모델을 사용하여 다양한 언어 간의 번역을 수행합니다.☑️ 음성 인식딥러닝은 음성 인식 통해 복잡한 문제를 해결합니다.입력 데이터에서 중요한 패턴을 추출하고, 이를 바탕으로 예측, 분류, 생성 등의 다양한 작업을 수행할 수 있습니다.ALT☑️ 딥러닝의 특징비선형 추론: 딥러닝은 비선형 추론을 통해 복잡한 데이터의 패턴을 학습할 수 있습니다.다층 구조: 여러 층의 신경망을 사용하여 데이터의 고차원 특징을 학습합니다.자동 특징 추출: 지도 학습, 비지도 학습, 강화 학습 등의 방법을 포함합니다.딥러닝(DL) : 딥러닝은 머신러닝의 하위 분야로, 다층 신경망을 사용하여 데이터를 학습합니다. 딥러닝은 특히 대규모 데이터와 복잡한 문제를 다루는 데 강력한 성능을 발휘합니다.ALT2) 최근의 활용 방안☑️ 이미지 인식딥러닝은 이미지 분류, 객체 검출, 이미지 생성 등 다양한 이미지 처리\n",
      "Quiz : **Quiz:**\n",
      "\n",
      "딥러닝은 음성 인식 시스템의 성능을 어떻게 향상시켰습니까?\n",
      "\n",
      "a) 딥러닝은 음성 인식 시스템에서 사용자의 목소리를 텍스트로 변환하는 데 사용됩니다.  \n",
      "b) 딥러닝은 음성 인식 시스템에서만 사용되며, 의료 분야에서는 활용되지 않습니다.  \n",
      "c) 딥러닝은 음성 인식 시스템에서 사용자의 목소리를 무시하는 기능을 제공합니다.  \n",
      "d) 딥러닝은 음성 인식 시스템에서 사용자의 목소리를 저장하지 않는 데 도움을 줍니다.  \n",
      "\n",
      "정답: a) 딥러닝은 음성 인식 시스템에서 사용자의 목소리를 텍스트로 변환하는 데 사용됩니다.\n",
      "TEXT 파일 저장 완료: quiz_list_2.txt\n",
      "Updated quiz_list: ['**Question:**\\n\\n딥러닝은 MRI나 CT 스캔 이미지를 분석하여 암을 조기에 발견하는 데 활용될 수 있습니다. 이러한 딥러닝의 활용 분야는 무엇인가요?\\n\\nA) 자연어 처리  \\nB) 음성 인식  \\nC) 의료 영상 분석  \\nD) 자율 주행\\n\\n**Answer:**\\n\\nC) 의료 영상 분석', '**Quiz:**\\n\\n딥러닝은 음성 인식 시스템의 성능을 어떻게 향상시켰습니까?\\n\\na) 딥러닝은 음성 인식 시스템에서 사용자의 목소리를 텍스트로 변환하는 데 사용됩니다.  \\nb) 딥러닝은 음성 인식 시스템에서만 사용되며, 의료 분야에서는 활용되지 않습니다.  \\nc) 딥러닝은 음성 인식 시스템에서 사용자의 목소리를 무시하는 기능을 제공합니다.  \\nd) 딥러닝은 음성 인식 시스템에서 사용자의 목소리를 저장하지 않는 데 도움을 줍니다.  \\n\\n정답: a) 딥러닝은 음성 인식 시스템에서 사용자의 목소리를 텍스트로 변환하는 데 사용됩니다.']\n",
      "Feedback:\n",
      "AIMessage(content='- 정답 여부: 예\\n- 추가 설명: 딥러닝은 음성 인식 시스템에서 사용자의 목소리를 텍스트로 변환하는 데 큰 역할을 합니다. 딥러닝 모델, 특히 신경망은 복잡한 패턴을 학습하고 처리하는 데 뛰어난 성능을 발휘하며, 이를 통해 음성 신호를 더 정확하게 텍스트로 변환할 수 있습니다. 이러한 기술은 구글의 음성 인식 서비스나 애플의 시리와 같은 다양한 상용 제품에 적용되어 음성 인식의 정확도와 효율성을 크게 향상시켰습니다. 나머지 선택지들은 딥러닝의 실제 역할과는 관련이 없습니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 156, 'prompt_tokens': 271, 'total_tokens': 427, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_7f6be3efb0', 'finish_reason': 'stop', 'logprobs': None}, id='run-cb6c6c45-bcab-4151-99fb-2a91f8f3e21c-0', usage_metadata={'input_tokens': 271, 'output_tokens': 156, 'total_tokens': 427, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})\n",
      "1 번째 docs 참고\n",
      "퀴즈를 생성합니다 ===============\n",
      "Debug Output: 퀴즈 하나를 생성해줘\n",
      "Debug Output: {'context': [Document(metadata={}, page_content='함수/손실 함수/역전파/최적화 알고리즘에 대해 배워봅시다[목차]01. 퍼셉트론과 다층 퍼셉트론(XOR 문제 포함)02. 다층 퍼셉트론(MLP)03. 활성화 함수04. 손실 함수와 최적화 알고리즘05. 역전파에 대해 알아볼까요?💡모든 토글을 열고 닫는 단축키'), Document(metadata={}, page_content='층의 기울기는 이전 층의 기울기와 현재 층의 기울기를 곱하여 계산합니다.이를 통해 신경망의 모든 가중치가 업데이트 됩니다ALTCopyright ⓒ TeamSparta All rights reserved.'), Document(metadata={}, page_content='곱하고, 이를 모두 더한 후 활성화 함수(activation function)를 통해 출력 값을 결정합니다.ALT☑️ 퍼셉트론의 수학적 표현y=f(∑i=1nwixi+b)y = f(_{i=1}^{n} w_i x_i + b) y=f(i=1∑n\\u200bwi\\u200bxi\\u200b+b)여기서 xi는 입력 값, wi는 가중치, b는 바이어스(bias), f는 활성화 함수입니다.여기서'), Document(metadata={}, page_content='수학적 원리☑️ 역전파 알고리즘의 개념역전파(Backpropagation)는 신경망의 가중치를 학습시키기 위해 사용되는 알고리즘입니다. 출력에서 입력 방향으로 손실 함수의 기울기를 계산하고, 이를 바탕으로 가중치를 업데이트합니다.☑️ 역전파의 수학적 원리연쇄 법칙(Chain Rule)을 사용해 손실함수의 기울기를 계산합니다.각 층의 기울기는 이전 층의'), Document(metadata={}, page_content='Mac : ⌘ + ⌥ + t 01. 퍼셉트론과 다층 퍼셉트론(XOR 문제 포함)✔️인공신공망의 가장 기본 단위인 퍼셉트론에 대해 배워봅시다1) 단일 퍼셉트론의 원리☑️ 단일 퍼셉트론의 개념퍼셉트론(Perceptron)은 인공 신경망의 가장 기본적인 단위로, 하나의 뉴런을 모델링한 것입니다.퍼셉트론은 입력 값을 받아 가중치(weight)를 곱하고, 이를'), Document(metadata={}, page_content='Windows : Ctrl + alt + t'), Document(metadata={}, page_content='f는 활성화 함수입니다.여기서 xi\\u200b는 입력 값, wi\\u200b는 가중치, b는 바이어스(bias), f는 활성화 함수입니다.\\ufeff\\u200b02. 다층 퍼셉트론(MLP)✔️다층 퍼셉트론에 대해 배워봅시다1) 다층 퍼셉트론(MLP)과 XOR 문제 해결☑️ 다층 퍼셉트론(MLP)의 개념다층 퍼셉트론(Multi-Layer Perceptron, MLP)은 여러 층의 퍼셉트론을'), Document(metadata={}, page_content=\"'죽은 ReLU' 문제가 발생할 수 있습니다.Sigmoidf(x)=11+e−xf(x) = {1 + e^{-x}} f(x)=1+e−x1\\u200b장점: 출력 값이 0과 1 사이로 제한되어 확률을 표현하기에 적합합니다.단점: 기울기 소실 문제와 출력 값이 0 또는 1에 가까워질 때 학습이 느려지는 문제가 있습니다.Tanh (Hyperbolic\")], 'quiz_list': '퀴즈 하나를 생성해줘'}\n",
      "Context output: 함수/손실 함수/역전파/최적화 알고리즘에 대해 배워봅시다[목차]01. 퍼셉트론과 다층 퍼셉트론(XOR 문제 포함)02. 다층 퍼셉트론(MLP)03. 활성화 함수04. 손실 함수와 최적화 알고리즘05. 역전파에 대해 알아볼까요?💡모든 토글을 열고 닫는 단축키 층의 기울기는 이전 층의 기울기와 현재 층의 기울기를 곱하여 계산합니다.이를 통해 신경망의 모든 가중치가 업데이트 됩니다ALTCopyright ⓒ TeamSparta All rights reserved. 곱하고, 이를 모두 더한 후 활성화 함수(activation function)를 통해 출력 값을 결정합니다.ALT☑️ 퍼셉트론의 수학적 표현y=f(∑i=1nwixi+b)y = f(_{i=1}^{n} w_i x_i + b) y=f(i=1∑n​wi​xi​+b)여기서 xi는 입력 값, wi는 가중치, b는 바이어스(bias), f는 활성화 함수입니다.여기서 수학적 원리☑️ 역전파 알고리즘의 개념역전파(Backpropagation)는 신경망의 가중치를 학습시키기 위해 사용되는 알고리즘입니다. 출력에서 입력 방향으로 손실 함수의 기울기를 계산하고, 이를 바탕으로 가중치를 업데이트합니다.☑️ 역전파의 수학적 원리연쇄 법칙(Chain Rule)을 사용해 손실함수의 기울기를 계산합니다.각 층의 기울기는 이전 층의 Mac : ⌘ + ⌥ + t 01. 퍼셉트론과 다층 퍼셉트론(XOR 문제 포함)✔️인공신공망의 가장 기본 단위인 퍼셉트론에 대해 배워봅시다1) 단일 퍼셉트론의 원리☑️ 단일 퍼셉트론의 개념퍼셉트론(Perceptron)은 인공 신경망의 가장 기본적인 단위로, 하나의 뉴런을 모델링한 것입니다.퍼셉트론은 입력 값을 받아 가중치(weight)를 곱하고, 이를 Windows : Ctrl + alt + t f는 활성화 함수입니다.여기서 xi​는 입력 값, wi​는 가중치, b는 바이어스(bias), f는 활성화 함수입니다.﻿​02. 다층 퍼셉트론(MLP)✔️다층 퍼셉트론에 대해 배워봅시다1) 다층 퍼셉트론(MLP)과 XOR 문제 해결☑️ 다층 퍼셉트론(MLP)의 개념다층 퍼셉트론(Multi-Layer Perceptron, MLP)은 여러 층의 퍼셉트론을 '죽은 ReLU' 문제가 발생할 수 있습니다.Sigmoidf(x)=11+e−xf(x) = {1 + e^{-x}} f(x)=1+e−x1​장점: 출력 값이 0과 1 사이로 제한되어 확률을 표현하기에 적합합니다.단점: 기울기 소실 문제와 출력 값이 0 또는 1에 가까워질 때 학습이 느려지는 문제가 있습니다.Tanh (Hyperbolic\n",
      "Quiz : Quiz:\n",
      "\n",
      "다음 중 퍼셉트론(Perceptron)의 수학적 표현에 포함되지 않는 요소는 무엇입니까?\n",
      "\n",
      "A) 입력 값 (xi)\n",
      "\n",
      "B) 가중치 (wi)\n",
      "\n",
      "C) 활성화 함수 (f)\n",
      "\n",
      "D) 손실 함수 (Loss function) \n",
      "\n",
      "정답: D) 손실 함수 (Loss function) \n",
      "\n",
      "퍼셉트론의 수학적 표현은 y=f(∑i=1nwixi+b)로, 여기에는 입력 값, 가중치, 바이어스, 활성화 함수가 포함되지만 손실 함수는 포함되지 않습니다.\n",
      "TEXT 파일 저장 완료: quiz_list_3.txt\n",
      "Updated quiz_list: ['**Question:**\\n\\n딥러닝은 MRI나 CT 스캔 이미지를 분석하여 암을 조기에 발견하는 데 활용될 수 있습니다. 이러한 딥러닝의 활용 분야는 무엇인가요?\\n\\nA) 자연어 처리  \\nB) 음성 인식  \\nC) 의료 영상 분석  \\nD) 자율 주행\\n\\n**Answer:**\\n\\nC) 의료 영상 분석', '**Quiz:**\\n\\n딥러닝은 음성 인식 시스템의 성능을 어떻게 향상시켰습니까?\\n\\na) 딥러닝은 음성 인식 시스템에서 사용자의 목소리를 텍스트로 변환하는 데 사용됩니다.  \\nb) 딥러닝은 음성 인식 시스템에서만 사용되며, 의료 분야에서는 활용되지 않습니다.  \\nc) 딥러닝은 음성 인식 시스템에서 사용자의 목소리를 무시하는 기능을 제공합니다.  \\nd) 딥러닝은 음성 인식 시스템에서 사용자의 목소리를 저장하지 않는 데 도움을 줍니다.  \\n\\n정답: a) 딥러닝은 음성 인식 시스템에서 사용자의 목소리를 텍스트로 변환하는 데 사용됩니다.', 'Quiz:\\n\\n다음 중 퍼셉트론(Perceptron)의 수학적 표현에 포함되지 않는 요소는 무엇입니까?\\n\\nA) 입력 값 (xi)\\n\\nB) 가중치 (wi)\\n\\nC) 활성화 함수 (f)\\n\\nD) 손실 함수 (Loss function) \\n\\n정답: D) 손실 함수 (Loss function) \\n\\n퍼셉트론의 수학적 표현은 y=f(∑i=1nwixi+b)로, 여기에는 입력 값, 가중치, 바이어스, 활성화 함수가 포함되지만 손실 함수는 포함되지 않습니다.']\n",
      "Feedback:\n",
      "AIMessage(content='- 정답 여부: 아니오\\n- 추가 설명: 퍼셉트론의 수학적 표현은 입력 값 (xi), 가중치 (wi), 바이어스 (b), 그리고 활성화 함수 (f)를 포함합니다. 손실 함수는 퍼셉트론의 학습 과정에서 가중치를 조정하기 위해 사용되지만, 퍼셉트론의 기본 수학적 계산에는 포함되지 않습니다. 따라서 손실 함수가 포함되지 않는 요소입니다. 활성화 함수 (f)는 퍼셉트론의 출력을 결정하는 데 사용되므로 수학적 표현에 포함됩니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 130, 'prompt_tokens': 231, 'total_tokens': 361, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'stop', 'logprobs': None}, id='run-526356a8-e064-4067-8511-c4dea66dcf79-0', usage_metadata={'input_tokens': 231, 'output_tokens': 130, 'total_tokens': 361, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})\n",
      "퀴즈를 생성합니다 ===============\n",
      "Debug Output: 퀴즈 하나를 생성해줘\n",
      "Debug Output: {'context': [Document(metadata={}, page_content='함수/손실 함수/역전파/최적화 알고리즘에 대해 배워봅시다[목차]01. 퍼셉트론과 다층 퍼셉트론(XOR 문제 포함)02. 다층 퍼셉트론(MLP)03. 활성화 함수04. 손실 함수와 최적화 알고리즘05. 역전파에 대해 알아볼까요?💡모든 토글을 열고 닫는 단축키'), Document(metadata={}, page_content='층의 기울기는 이전 층의 기울기와 현재 층의 기울기를 곱하여 계산합니다.이를 통해 신경망의 모든 가중치가 업데이트 됩니다ALTCopyright ⓒ TeamSparta All rights reserved.'), Document(metadata={}, page_content='곱하고, 이를 모두 더한 후 활성화 함수(activation function)를 통해 출력 값을 결정합니다.ALT☑️ 퍼셉트론의 수학적 표현y=f(∑i=1nwixi+b)y = f(_{i=1}^{n} w_i x_i + b) y=f(i=1∑n\\u200bwi\\u200bxi\\u200b+b)여기서 xi는 입력 값, wi는 가중치, b는 바이어스(bias), f는 활성화 함수입니다.여기서'), Document(metadata={}, page_content='수학적 원리☑️ 역전파 알고리즘의 개념역전파(Backpropagation)는 신경망의 가중치를 학습시키기 위해 사용되는 알고리즘입니다. 출력에서 입력 방향으로 손실 함수의 기울기를 계산하고, 이를 바탕으로 가중치를 업데이트합니다.☑️ 역전파의 수학적 원리연쇄 법칙(Chain Rule)을 사용해 손실함수의 기울기를 계산합니다.각 층의 기울기는 이전 층의'), Document(metadata={}, page_content='Mac : ⌘ + ⌥ + t 01. 퍼셉트론과 다층 퍼셉트론(XOR 문제 포함)✔️인공신공망의 가장 기본 단위인 퍼셉트론에 대해 배워봅시다1) 단일 퍼셉트론의 원리☑️ 단일 퍼셉트론의 개념퍼셉트론(Perceptron)은 인공 신경망의 가장 기본적인 단위로, 하나의 뉴런을 모델링한 것입니다.퍼셉트론은 입력 값을 받아 가중치(weight)를 곱하고, 이를'), Document(metadata={}, page_content='Windows : Ctrl + alt + t'), Document(metadata={}, page_content='f는 활성화 함수입니다.여기서 xi\\u200b는 입력 값, wi\\u200b는 가중치, b는 바이어스(bias), f는 활성화 함수입니다.\\ufeff\\u200b02. 다층 퍼셉트론(MLP)✔️다층 퍼셉트론에 대해 배워봅시다1) 다층 퍼셉트론(MLP)과 XOR 문제 해결☑️ 다층 퍼셉트론(MLP)의 개념다층 퍼셉트론(Multi-Layer Perceptron, MLP)은 여러 층의 퍼셉트론을'), Document(metadata={}, page_content=\"'죽은 ReLU' 문제가 발생할 수 있습니다.Sigmoidf(x)=11+e−xf(x) = {1 + e^{-x}} f(x)=1+e−x1\\u200b장점: 출력 값이 0과 1 사이로 제한되어 확률을 표현하기에 적합합니다.단점: 기울기 소실 문제와 출력 값이 0 또는 1에 가까워질 때 학습이 느려지는 문제가 있습니다.Tanh (Hyperbolic\")], 'quiz_list': '퀴즈 하나를 생성해줘'}\n",
      "Context output: 함수/손실 함수/역전파/최적화 알고리즘에 대해 배워봅시다[목차]01. 퍼셉트론과 다층 퍼셉트론(XOR 문제 포함)02. 다층 퍼셉트론(MLP)03. 활성화 함수04. 손실 함수와 최적화 알고리즘05. 역전파에 대해 알아볼까요?💡모든 토글을 열고 닫는 단축키 층의 기울기는 이전 층의 기울기와 현재 층의 기울기를 곱하여 계산합니다.이를 통해 신경망의 모든 가중치가 업데이트 됩니다ALTCopyright ⓒ TeamSparta All rights reserved. 곱하고, 이를 모두 더한 후 활성화 함수(activation function)를 통해 출력 값을 결정합니다.ALT☑️ 퍼셉트론의 수학적 표현y=f(∑i=1nwixi+b)y = f(_{i=1}^{n} w_i x_i + b) y=f(i=1∑n​wi​xi​+b)여기서 xi는 입력 값, wi는 가중치, b는 바이어스(bias), f는 활성화 함수입니다.여기서 수학적 원리☑️ 역전파 알고리즘의 개념역전파(Backpropagation)는 신경망의 가중치를 학습시키기 위해 사용되는 알고리즘입니다. 출력에서 입력 방향으로 손실 함수의 기울기를 계산하고, 이를 바탕으로 가중치를 업데이트합니다.☑️ 역전파의 수학적 원리연쇄 법칙(Chain Rule)을 사용해 손실함수의 기울기를 계산합니다.각 층의 기울기는 이전 층의 Mac : ⌘ + ⌥ + t 01. 퍼셉트론과 다층 퍼셉트론(XOR 문제 포함)✔️인공신공망의 가장 기본 단위인 퍼셉트론에 대해 배워봅시다1) 단일 퍼셉트론의 원리☑️ 단일 퍼셉트론의 개념퍼셉트론(Perceptron)은 인공 신경망의 가장 기본적인 단위로, 하나의 뉴런을 모델링한 것입니다.퍼셉트론은 입력 값을 받아 가중치(weight)를 곱하고, 이를 Windows : Ctrl + alt + t f는 활성화 함수입니다.여기서 xi​는 입력 값, wi​는 가중치, b는 바이어스(bias), f는 활성화 함수입니다.﻿​02. 다층 퍼셉트론(MLP)✔️다층 퍼셉트론에 대해 배워봅시다1) 다층 퍼셉트론(MLP)과 XOR 문제 해결☑️ 다층 퍼셉트론(MLP)의 개념다층 퍼셉트론(Multi-Layer Perceptron, MLP)은 여러 층의 퍼셉트론을 '죽은 ReLU' 문제가 발생할 수 있습니다.Sigmoidf(x)=11+e−xf(x) = {1 + e^{-x}} f(x)=1+e−x1​장점: 출력 값이 0과 1 사이로 제한되어 확률을 표현하기에 적합합니다.단점: 기울기 소실 문제와 출력 값이 0 또는 1에 가까워질 때 학습이 느려지는 문제가 있습니다.Tanh (Hyperbolic\n",
      "Quiz : Quiz: 역전파(Backpropagation) 알고리즘에 대한 설명으로 옳지 않은 것은 무엇인가요?\n",
      "\n",
      "A) 역전파는 출력에서 입력 방향으로 손실 함수의 기울기를 계산합니다.  \n",
      "B) 역전파는 연쇄 법칙(Chain Rule)을 사용해 손실 함수의 기울기를 계산합니다.  \n",
      "C) 역전파는 신경망의 가중치를 학습시키기 위해 사용되는 알고리즘입니다.  \n",
      "D) 역전파는 입력에서 출력 방향으로 손실 함수의 기울기를 계산합니다.  \n",
      "\n",
      "정답: D) 역전파는 입력에서 출력 방향으로 손실 함수의 기울기를 계산합니다.\n",
      "TEXT 파일 저장 완료: quiz_list_4.txt\n",
      "Updated quiz_list: ['**Question:**\\n\\n딥러닝은 MRI나 CT 스캔 이미지를 분석하여 암을 조기에 발견하는 데 활용될 수 있습니다. 이러한 딥러닝의 활용 분야는 무엇인가요?\\n\\nA) 자연어 처리  \\nB) 음성 인식  \\nC) 의료 영상 분석  \\nD) 자율 주행\\n\\n**Answer:**\\n\\nC) 의료 영상 분석', '**Quiz:**\\n\\n딥러닝은 음성 인식 시스템의 성능을 어떻게 향상시켰습니까?\\n\\na) 딥러닝은 음성 인식 시스템에서 사용자의 목소리를 텍스트로 변환하는 데 사용됩니다.  \\nb) 딥러닝은 음성 인식 시스템에서만 사용되며, 의료 분야에서는 활용되지 않습니다.  \\nc) 딥러닝은 음성 인식 시스템에서 사용자의 목소리를 무시하는 기능을 제공합니다.  \\nd) 딥러닝은 음성 인식 시스템에서 사용자의 목소리를 저장하지 않는 데 도움을 줍니다.  \\n\\n정답: a) 딥러닝은 음성 인식 시스템에서 사용자의 목소리를 텍스트로 변환하는 데 사용됩니다.', 'Quiz:\\n\\n다음 중 퍼셉트론(Perceptron)의 수학적 표현에 포함되지 않는 요소는 무엇입니까?\\n\\nA) 입력 값 (xi)\\n\\nB) 가중치 (wi)\\n\\nC) 활성화 함수 (f)\\n\\nD) 손실 함수 (Loss function) \\n\\n정답: D) 손실 함수 (Loss function) \\n\\n퍼셉트론의 수학적 표현은 y=f(∑i=1nwixi+b)로, 여기에는 입력 값, 가중치, 바이어스, 활성화 함수가 포함되지만 손실 함수는 포함되지 않습니다.', 'Quiz: 역전파(Backpropagation) 알고리즘에 대한 설명으로 옳지 않은 것은 무엇인가요?\\n\\nA) 역전파는 출력에서 입력 방향으로 손실 함수의 기울기를 계산합니다.  \\nB) 역전파는 연쇄 법칙(Chain Rule)을 사용해 손실 함수의 기울기를 계산합니다.  \\nC) 역전파는 신경망의 가중치를 학습시키기 위해 사용되는 알고리즘입니다.  \\nD) 역전파는 입력에서 출력 방향으로 손실 함수의 기울기를 계산합니다.  \\n\\n정답: D) 역전파는 입력에서 출력 방향으로 손실 함수의 기울기를 계산합니다.']\n",
      "Feedback:\n",
      "AIMessage(content='- 정답 여부: 예\\n- 추가 설명: 역전파(Backpropagation) 알고리즘은 신경망에서 가중치를 조정하기 위해 사용되며, 출력에서 입력 방향으로 손실 함수의 기울기를 계산합니다. 이는 출력층에서부터 시작하여 각 층으로 거슬러 올라가며 기울기를 계산하는 방식입니다. 따라서 D) \"역전파는 입력에서 출력 방향으로 손실 함수의 기울기를 계산합니다.\"는 잘못된 설명입니다. A, B, C는 모두 역전파의 올바른 설명입니다. 특히, 연쇄 법칙(Chain Rule)을 사용하여 각 층의 기울기를 계산하는 것이 역전파의 핵심입니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 155, 'prompt_tokens': 249, 'total_tokens': 404, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_7f6be3efb0', 'finish_reason': 'stop', 'logprobs': None}, id='run-54a0c6a5-69e0-4094-82a1-1474cf2a8d5b-0', usage_metadata={'input_tokens': 249, 'output_tokens': 155, 'total_tokens': 404, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})\n",
      "2 번째 docs 참고\n",
      "퀴즈를 생성합니다 ===============\n",
      "Debug Output: 퀴즈 하나를 생성해줘\n",
      "Debug Output: {'context': [Document(metadata={}, page_content='프로젝트마다 독립적인 파이썬 환경을 제공합니다.가상환경을 이용해 서로 다른 프로젝트 간의 패키지 충돌을 방지할 수 있습니다. Conda를 이용하면 쉽게 가상환경을 생성하고 관리할 수 있습니다.☑️ 가상환경 생성 및 관리가상 환경 생성 {5px}가상 환경 생성 \\ufeff\\u200bPythonCopyconda create --name myenv python=3.8'), Document(metadata={}, page_content='\\u200bCopyright ⓒ TeamSparta All rights reserved.'), Document(metadata={}, page_content='셀을 선택한 후 \"Shift + Enter\"를 눌러 코드를 실행합니다.03. 가상환경 설치 및 jupyter notebook 연결 ✔️가상환경이 무엇인지 알아보고 jupyter notebook과 가상환경을 연결해 봅시다1) 가상환경 설치 ☑️ 가상환경이란 무엇인가?가상환경(Virtual Environment)은 프로젝트마다 독립적인 파이썬 환경을'), Document(metadata={}, page_content='conda를 이용한 환경 설정02. jupyter notebook 03. 가상환경 설치 및 jupyter notebook 연결 04. pytorch 설치\\u200b환경 활성화 {5px}환경 활성화 \\ufeff\\u200bPythonCopyconda activate myenv'), Document(metadata={}, page_content='\\u200b이 명령어를 실행하면 웹 브라우저가 열리고, Jupyter Notebook 인터페이스가 나타납니다.새로운 노트북 생성:Jupyter Notebook 인터페이스에서 \"New\" 버튼을 클릭하고, \"Python (myenv)\"를 선택하여 새로운 노트북을 생성합니다.코드 작성 및 실행:셀(Cell)에 코드를 작성하고, 셀을 선택한 후 \"Shift +'), Document(metadata={}, page_content='\\u200b필요한 패키지 설치 {5px}필요한 패키지 설치 \\ufeff\\u200bPythonCopyconda install numpy pandas matplotlib'), Document(metadata={}, page_content='\\u200b가상환경을 Jupyter Notebook에 커널로 추가 {5px}가상환경을 Jupyter Notebook에 커널로 추가 \\ufeff\\u200bPythonCopypython -m ipykernel install --user --name myenv --display-name \"Python (myenv)\"'), Document(metadata={}, page_content='[스파르타코딩클럽] 3. 딥러닝 실습 환경 구축📘[SCC] 기초가 탄탄한 딥러닝/📚[스파르타코딩클럽] 기초가 탄탄한 딥러닝 - 1주차/📕[스파르타코딩클럽] 3. 딥러닝 실습 환경 구축Made with📕[스파르타코딩클럽] 3. 딥러닝 실습 환경 구축[수업 목표]딥러닝 실습을 위한 환경을 구축해 봅시다[목차]01. conda를 이용한 환경 설정02.')], 'quiz_list': '퀴즈 하나를 생성해줘'}\n",
      "Context output: 프로젝트마다 독립적인 파이썬 환경을 제공합니다.가상환경을 이용해 서로 다른 프로젝트 간의 패키지 충돌을 방지할 수 있습니다. Conda를 이용하면 쉽게 가상환경을 생성하고 관리할 수 있습니다.☑️ 가상환경 생성 및 관리가상 환경 생성 {5px}가상 환경 생성 ﻿​PythonCopyconda create --name myenv python=3.8 ​Copyright ⓒ TeamSparta All rights reserved. 셀을 선택한 후 \"Shift + Enter\"를 눌러 코드를 실행합니다.03. 가상환경 설치 및 jupyter notebook 연결 ✔️가상환경이 무엇인지 알아보고 jupyter notebook과 가상환경을 연결해 봅시다1) 가상환경 설치 ☑️ 가상환경이란 무엇인가?가상환경(Virtual Environment)은 프로젝트마다 독립적인 파이썬 환경을 conda를 이용한 환경 설정02. jupyter notebook 03. 가상환경 설치 및 jupyter notebook 연결 04. pytorch 설치​환경 활성화 {5px}환경 활성화 ﻿​PythonCopyconda activate myenv ​이 명령어를 실행하면 웹 브라우저가 열리고, Jupyter Notebook 인터페이스가 나타납니다.새로운 노트북 생성:Jupyter Notebook 인터페이스에서 \"New\" 버튼을 클릭하고, \"Python (myenv)\"를 선택하여 새로운 노트북을 생성합니다.코드 작성 및 실행:셀(Cell)에 코드를 작성하고, 셀을 선택한 후 \"Shift + ​필요한 패키지 설치 {5px}필요한 패키지 설치 ﻿​PythonCopyconda install numpy pandas matplotlib ​가상환경을 Jupyter Notebook에 커널로 추가 {5px}가상환경을 Jupyter Notebook에 커널로 추가 ﻿​PythonCopypython -m ipykernel install --user --name myenv --display-name \"Python (myenv)\" [스파르타코딩클럽] 3. 딥러닝 실습 환경 구축📘[SCC] 기초가 탄탄한 딥러닝/📚[스파르타코딩클럽] 기초가 탄탄한 딥러닝 - 1주차/📕[스파르타코딩클럽] 3. 딥러닝 실습 환경 구축Made with📕[스파르타코딩클럽] 3. 딥러닝 실습 환경 구축[수업 목표]딥러닝 실습을 위한 환경을 구축해 봅시다[목차]01. conda를 이용한 환경 설정02.\n",
      "Quiz : **Quiz:**\n",
      "\n",
      "가상환경을 생성하기 위한 Conda 명령어는 무엇인가요?\n",
      "\n",
      "a) conda start --name myenv python=3.8  \n",
      "b) conda build --name myenv python=3.8  \n",
      "c) conda create --name myenv python=3.8  \n",
      "d) conda init --name myenv python=3.8  \n",
      "\n",
      "**정답:** c) conda create --name myenv python=3.8\n",
      "TEXT 파일 저장 완료: quiz_list_5.txt\n",
      "Updated quiz_list: ['**Question:**\\n\\n딥러닝은 MRI나 CT 스캔 이미지를 분석하여 암을 조기에 발견하는 데 활용될 수 있습니다. 이러한 딥러닝의 활용 분야는 무엇인가요?\\n\\nA) 자연어 처리  \\nB) 음성 인식  \\nC) 의료 영상 분석  \\nD) 자율 주행\\n\\n**Answer:**\\n\\nC) 의료 영상 분석', '**Quiz:**\\n\\n딥러닝은 음성 인식 시스템의 성능을 어떻게 향상시켰습니까?\\n\\na) 딥러닝은 음성 인식 시스템에서 사용자의 목소리를 텍스트로 변환하는 데 사용됩니다.  \\nb) 딥러닝은 음성 인식 시스템에서만 사용되며, 의료 분야에서는 활용되지 않습니다.  \\nc) 딥러닝은 음성 인식 시스템에서 사용자의 목소리를 무시하는 기능을 제공합니다.  \\nd) 딥러닝은 음성 인식 시스템에서 사용자의 목소리를 저장하지 않는 데 도움을 줍니다.  \\n\\n정답: a) 딥러닝은 음성 인식 시스템에서 사용자의 목소리를 텍스트로 변환하는 데 사용됩니다.', 'Quiz:\\n\\n다음 중 퍼셉트론(Perceptron)의 수학적 표현에 포함되지 않는 요소는 무엇입니까?\\n\\nA) 입력 값 (xi)\\n\\nB) 가중치 (wi)\\n\\nC) 활성화 함수 (f)\\n\\nD) 손실 함수 (Loss function) \\n\\n정답: D) 손실 함수 (Loss function) \\n\\n퍼셉트론의 수학적 표현은 y=f(∑i=1nwixi+b)로, 여기에는 입력 값, 가중치, 바이어스, 활성화 함수가 포함되지만 손실 함수는 포함되지 않습니다.', 'Quiz: 역전파(Backpropagation) 알고리즘에 대한 설명으로 옳지 않은 것은 무엇인가요?\\n\\nA) 역전파는 출력에서 입력 방향으로 손실 함수의 기울기를 계산합니다.  \\nB) 역전파는 연쇄 법칙(Chain Rule)을 사용해 손실 함수의 기울기를 계산합니다.  \\nC) 역전파는 신경망의 가중치를 학습시키기 위해 사용되는 알고리즘입니다.  \\nD) 역전파는 입력에서 출력 방향으로 손실 함수의 기울기를 계산합니다.  \\n\\n정답: D) 역전파는 입력에서 출력 방향으로 손실 함수의 기울기를 계산합니다.', '**Quiz:**\\n\\n가상환경을 생성하기 위한 Conda 명령어는 무엇인가요?\\n\\na) conda start --name myenv python=3.8  \\nb) conda build --name myenv python=3.8  \\nc) conda create --name myenv python=3.8  \\nd) conda init --name myenv python=3.8  \\n\\n**정답:** c) conda create --name myenv python=3.8']\n",
      "Feedback:\n",
      "AIMessage(content='- 정답 여부: 예\\n- 추가 설명: Conda는 Python을 비롯한 다양한 패키지와 가상환경을 관리하기 위한 도구입니다. \"conda create --name myenv python=3.8\" 명령어는 \"myenv\"라는 이름의 새로운 가상환경을 생성하고, 해당 환경에 Python 3.8 버전을 설치합니다. 이 명령어는 새로운 프로젝트나 실험을 위한 격리된 환경을 설정할 때 유용합니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 105, 'prompt_tokens': 202, 'total_tokens': 307, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_7f6be3efb0', 'finish_reason': 'stop', 'logprobs': None}, id='run-29626165-19f9-4306-b04d-b368752264d5-0', usage_metadata={'input_tokens': 202, 'output_tokens': 105, 'total_tokens': 307, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})\n",
      "퀴즈를 생성합니다 ===============\n",
      "Debug Output: 퀴즈 하나를 생성해줘\n",
      "Debug Output: {'context': [Document(metadata={}, page_content='프로젝트마다 독립적인 파이썬 환경을 제공합니다.가상환경을 이용해 서로 다른 프로젝트 간의 패키지 충돌을 방지할 수 있습니다. Conda를 이용하면 쉽게 가상환경을 생성하고 관리할 수 있습니다.☑️ 가상환경 생성 및 관리가상 환경 생성 {5px}가상 환경 생성 \\ufeff\\u200bPythonCopyconda create --name myenv python=3.8'), Document(metadata={}, page_content='\\u200bCopyright ⓒ TeamSparta All rights reserved.'), Document(metadata={}, page_content='셀을 선택한 후 \"Shift + Enter\"를 눌러 코드를 실행합니다.03. 가상환경 설치 및 jupyter notebook 연결 ✔️가상환경이 무엇인지 알아보고 jupyter notebook과 가상환경을 연결해 봅시다1) 가상환경 설치 ☑️ 가상환경이란 무엇인가?가상환경(Virtual Environment)은 프로젝트마다 독립적인 파이썬 환경을'), Document(metadata={}, page_content='conda를 이용한 환경 설정02. jupyter notebook 03. 가상환경 설치 및 jupyter notebook 연결 04. pytorch 설치\\u200b환경 활성화 {5px}환경 활성화 \\ufeff\\u200bPythonCopyconda activate myenv'), Document(metadata={}, page_content='\\u200b이 명령어를 실행하면 웹 브라우저가 열리고, Jupyter Notebook 인터페이스가 나타납니다.새로운 노트북 생성:Jupyter Notebook 인터페이스에서 \"New\" 버튼을 클릭하고, \"Python (myenv)\"를 선택하여 새로운 노트북을 생성합니다.코드 작성 및 실행:셀(Cell)에 코드를 작성하고, 셀을 선택한 후 \"Shift +'), Document(metadata={}, page_content='\\u200b필요한 패키지 설치 {5px}필요한 패키지 설치 \\ufeff\\u200bPythonCopyconda install numpy pandas matplotlib'), Document(metadata={}, page_content='\\u200b가상환경을 Jupyter Notebook에 커널로 추가 {5px}가상환경을 Jupyter Notebook에 커널로 추가 \\ufeff\\u200bPythonCopypython -m ipykernel install --user --name myenv --display-name \"Python (myenv)\"'), Document(metadata={}, page_content='[스파르타코딩클럽] 3. 딥러닝 실습 환경 구축📘[SCC] 기초가 탄탄한 딥러닝/📚[스파르타코딩클럽] 기초가 탄탄한 딥러닝 - 1주차/📕[스파르타코딩클럽] 3. 딥러닝 실습 환경 구축Made with📕[스파르타코딩클럽] 3. 딥러닝 실습 환경 구축[수업 목표]딥러닝 실습을 위한 환경을 구축해 봅시다[목차]01. conda를 이용한 환경 설정02.')], 'quiz_list': '퀴즈 하나를 생성해줘'}\n",
      "Context output: 프로젝트마다 독립적인 파이썬 환경을 제공합니다.가상환경을 이용해 서로 다른 프로젝트 간의 패키지 충돌을 방지할 수 있습니다. Conda를 이용하면 쉽게 가상환경을 생성하고 관리할 수 있습니다.☑️ 가상환경 생성 및 관리가상 환경 생성 {5px}가상 환경 생성 ﻿​PythonCopyconda create --name myenv python=3.8 ​Copyright ⓒ TeamSparta All rights reserved. 셀을 선택한 후 \"Shift + Enter\"를 눌러 코드를 실행합니다.03. 가상환경 설치 및 jupyter notebook 연결 ✔️가상환경이 무엇인지 알아보고 jupyter notebook과 가상환경을 연결해 봅시다1) 가상환경 설치 ☑️ 가상환경이란 무엇인가?가상환경(Virtual Environment)은 프로젝트마다 독립적인 파이썬 환경을 conda를 이용한 환경 설정02. jupyter notebook 03. 가상환경 설치 및 jupyter notebook 연결 04. pytorch 설치​환경 활성화 {5px}환경 활성화 ﻿​PythonCopyconda activate myenv ​이 명령어를 실행하면 웹 브라우저가 열리고, Jupyter Notebook 인터페이스가 나타납니다.새로운 노트북 생성:Jupyter Notebook 인터페이스에서 \"New\" 버튼을 클릭하고, \"Python (myenv)\"를 선택하여 새로운 노트북을 생성합니다.코드 작성 및 실행:셀(Cell)에 코드를 작성하고, 셀을 선택한 후 \"Shift + ​필요한 패키지 설치 {5px}필요한 패키지 설치 ﻿​PythonCopyconda install numpy pandas matplotlib ​가상환경을 Jupyter Notebook에 커널로 추가 {5px}가상환경을 Jupyter Notebook에 커널로 추가 ﻿​PythonCopypython -m ipykernel install --user --name myenv --display-name \"Python (myenv)\" [스파르타코딩클럽] 3. 딥러닝 실습 환경 구축📘[SCC] 기초가 탄탄한 딥러닝/📚[스파르타코딩클럽] 기초가 탄탄한 딥러닝 - 1주차/📕[스파르타코딩클럽] 3. 딥러닝 실습 환경 구축Made with📕[스파르타코딩클럽] 3. 딥러닝 실습 환경 구축[수업 목표]딥러닝 실습을 위한 환경을 구축해 봅시다[목차]01. conda를 이용한 환경 설정02.\n",
      "Quiz : Q: 다음 중 가상환경을 Jupyter Notebook에 커널로 추가하는 명령어로 알맞은 것은 무엇인가요?\n",
      "\n",
      "A) conda create --name myenv python=3.8  \n",
      "B) conda activate myenv  \n",
      "C) conda install numpy pandas matplotlib  \n",
      "D) python -m ipykernel install --user --name myenv --display-name \"Python (myenv)\"  \n",
      "\n",
      "정답: D) python -m ipykernel install --user --name myenv --display-name \"Python (myenv)\"\n",
      "TEXT 파일 저장 완료: quiz_list_6.txt\n",
      "Updated quiz_list: ['**Question:**\\n\\n딥러닝은 MRI나 CT 스캔 이미지를 분석하여 암을 조기에 발견하는 데 활용될 수 있습니다. 이러한 딥러닝의 활용 분야는 무엇인가요?\\n\\nA) 자연어 처리  \\nB) 음성 인식  \\nC) 의료 영상 분석  \\nD) 자율 주행\\n\\n**Answer:**\\n\\nC) 의료 영상 분석', '**Quiz:**\\n\\n딥러닝은 음성 인식 시스템의 성능을 어떻게 향상시켰습니까?\\n\\na) 딥러닝은 음성 인식 시스템에서 사용자의 목소리를 텍스트로 변환하는 데 사용됩니다.  \\nb) 딥러닝은 음성 인식 시스템에서만 사용되며, 의료 분야에서는 활용되지 않습니다.  \\nc) 딥러닝은 음성 인식 시스템에서 사용자의 목소리를 무시하는 기능을 제공합니다.  \\nd) 딥러닝은 음성 인식 시스템에서 사용자의 목소리를 저장하지 않는 데 도움을 줍니다.  \\n\\n정답: a) 딥러닝은 음성 인식 시스템에서 사용자의 목소리를 텍스트로 변환하는 데 사용됩니다.', 'Quiz:\\n\\n다음 중 퍼셉트론(Perceptron)의 수학적 표현에 포함되지 않는 요소는 무엇입니까?\\n\\nA) 입력 값 (xi)\\n\\nB) 가중치 (wi)\\n\\nC) 활성화 함수 (f)\\n\\nD) 손실 함수 (Loss function) \\n\\n정답: D) 손실 함수 (Loss function) \\n\\n퍼셉트론의 수학적 표현은 y=f(∑i=1nwixi+b)로, 여기에는 입력 값, 가중치, 바이어스, 활성화 함수가 포함되지만 손실 함수는 포함되지 않습니다.', 'Quiz: 역전파(Backpropagation) 알고리즘에 대한 설명으로 옳지 않은 것은 무엇인가요?\\n\\nA) 역전파는 출력에서 입력 방향으로 손실 함수의 기울기를 계산합니다.  \\nB) 역전파는 연쇄 법칙(Chain Rule)을 사용해 손실 함수의 기울기를 계산합니다.  \\nC) 역전파는 신경망의 가중치를 학습시키기 위해 사용되는 알고리즘입니다.  \\nD) 역전파는 입력에서 출력 방향으로 손실 함수의 기울기를 계산합니다.  \\n\\n정답: D) 역전파는 입력에서 출력 방향으로 손실 함수의 기울기를 계산합니다.', '**Quiz:**\\n\\n가상환경을 생성하기 위한 Conda 명령어는 무엇인가요?\\n\\na) conda start --name myenv python=3.8  \\nb) conda build --name myenv python=3.8  \\nc) conda create --name myenv python=3.8  \\nd) conda init --name myenv python=3.8  \\n\\n**정답:** c) conda create --name myenv python=3.8', 'Q: 다음 중 가상환경을 Jupyter Notebook에 커널로 추가하는 명령어로 알맞은 것은 무엇인가요?\\n\\nA) conda create --name myenv python=3.8  \\nB) conda activate myenv  \\nC) conda install numpy pandas matplotlib  \\nD) python -m ipykernel install --user --name myenv --display-name \"Python (myenv)\"  \\n\\n정답: D) python -m ipykernel install --user --name myenv --display-name \"Python (myenv)\"']\n",
      "Feedback:\n",
      "AIMessage(content='- 정답 여부: 예\\n- 추가 설명: Jupyter Notebook에서 특정 가상환경을 커널로 추가하기 위해서는 해당 가상환경에 ipykernel을 설치하고, `python -m ipykernel install --user --name myenv --display-name \"Python (myenv)\"` 명령어를 사용하여 커널에 추가할 수 있습니다. 여기서 `myenv`는 가상환경의 이름으로, 사용자가 설정한 이름으로 대체할 수 있습니다. 이 명령어는 Jupyter Notebook에서 해당 가상환경을 선택하여 사용할 수 있도록 만들어줍니다. 다른 선택지들은 가상환경 생성, 활성화 또는 패키지 설치와 관련된 명령어입니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 151, 'prompt_tokens': 215, 'total_tokens': 366, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'stop', 'logprobs': None}, id='run-0bff4234-ac5d-4648-ba89-d7c124e58778-0', usage_metadata={'input_tokens': 215, 'output_tokens': 151, 'total_tokens': 366, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})\n",
      "3 번째 docs 참고\n",
      "퀴즈를 생성합니다 ===============\n",
      "Debug Output: 퀴즈 하나를 생성해줘\n",
      "Debug Output: {'context': [Document(metadata={}, page_content='간단한 인공신경망 모델 구현 실습을 진행해 봅시다[목차]01. 기본 구조와 동작원리02. 실습: 간단한 인공 신경망 모델 구현 (PyTorch) - 입력데이터를 받아들이는 층, 입력층의 뉴런수는 입력데이터 피쳐수와 동일 - 입력데이터를 받아들이는 층, 입력층의 뉴런수는 입력데이터 피쳐수와 동일\\ufeff'), Document(metadata={}, page_content='은닉층\\n - 입력데이터를 처리하고 특징을 추출하는 층, 은닉층의 뉴런수와 층수는 모델의 복잡성과 성능에 영향 - 입력데이터를 처리하고 특징을 추출하는 층, 은닉층의 뉴런수와 층수는 모델의 복잡성과 성능에 영향\\ufeff\\n출력층'), Document(metadata={}, page_content='각 샘플에 대해 가장 높은 확률을 가진 클래스를 반환합니다.\\ufeff\\u200blabels.size(0): 배치 크기를 반환합니다.(predicted == labels).sum().item(): 예측 값과 실제 값이 일치하는 샘플의 수를 계산합니다.Copyright ⓒ TeamSparta All rights reserved.'), Document(metadata={}, page_content='\\u200b☑️ 간단한 ANN 모델 정의간단한 ANN 모델 정의 {5px}간단한 ANN 모델 정의 \\ufeff\\u200bPythonCopyclass SimpleANN(nn.Module):\\ndef __init__(self):\\nsuper(SimpleANN, self).__init__()'), Document(metadata={}, page_content='PyTorch를 사용하여 간단한 인공 신경망 모델을 구축하고 학습해보겠습니다. 예제로는 MNIST 데이터셋을 사용하여 숫자 이미지를 분류하는 모델을 구현하겠습니다.1)  간단한 ANN 모델 구축 및 학습☑️ PyTorch 및 필요한 라이브러리 임포트PyTorch 및 필요한 라이브러리 임포트 {5px}PyTorch 및 필요한 라이브러리 임포트'), Document(metadata={}, page_content='모멘텀 값을 지정합니다.은 학습률, momentum은 모멘텀 값을 지정합니다.\\ufeff\\u200boptimizer.zero_grad(): 이전 단계에서 계산된 기울기를 초기화합니다.loss.backward(): 역전파를 통해 기울기를 계산합니다.optimizer.step(): 계산된 기울기를 바탕으로 가중치를 업데이트합니다.☑️ 모델  평가모델 평가 {5px}모델 평가'), Document(metadata={}, page_content='변환합니다.다중 클래스 분류 문제 (Multi-Class Classification):출력 레이어의 뉴런 수는 예측하려는 클래스 수와 동일합니다.활성화 함수로는 소프트맥스 함수(Softmax Function)를 사용하여 각 클래스에 대한 확률을 출력합니다.02. 실습: 간단한 인공 신경망 모델 구현 (PyTorch)✔️ PyTorch를 사용하여 간단한')], 'quiz_list': '퀴즈 하나를 생성해줘'}\n",
      "Context output: 간단한 인공신경망 모델 구현 실습을 진행해 봅시다[목차]01. 기본 구조와 동작원리02. 실습: 간단한 인공 신경망 모델 구현 (PyTorch) - 입력데이터를 받아들이는 층, 입력층의 뉴런수는 입력데이터 피쳐수와 동일 - 입력데이터를 받아들이는 층, 입력층의 뉴런수는 입력데이터 피쳐수와 동일﻿ 은닉층\n",
      " - 입력데이터를 처리하고 특징을 추출하는 층, 은닉층의 뉴런수와 층수는 모델의 복잡성과 성능에 영향 - 입력데이터를 처리하고 특징을 추출하는 층, 은닉층의 뉴런수와 층수는 모델의 복잡성과 성능에 영향﻿\n",
      "출력층 각 샘플에 대해 가장 높은 확률을 가진 클래스를 반환합니다.﻿​labels.size(0): 배치 크기를 반환합니다.(predicted == labels).sum().item(): 예측 값과 실제 값이 일치하는 샘플의 수를 계산합니다.Copyright ⓒ TeamSparta All rights reserved. ​☑️ 간단한 ANN 모델 정의간단한 ANN 모델 정의 {5px}간단한 ANN 모델 정의 ﻿​PythonCopyclass SimpleANN(nn.Module):\n",
      "def __init__(self):\n",
      "super(SimpleANN, self).__init__() PyTorch를 사용하여 간단한 인공 신경망 모델을 구축하고 학습해보겠습니다. 예제로는 MNIST 데이터셋을 사용하여 숫자 이미지를 분류하는 모델을 구현하겠습니다.1)  간단한 ANN 모델 구축 및 학습☑️ PyTorch 및 필요한 라이브러리 임포트PyTorch 및 필요한 라이브러리 임포트 {5px}PyTorch 및 필요한 라이브러리 임포트 모멘텀 값을 지정합니다.은 학습률, momentum은 모멘텀 값을 지정합니다.﻿​optimizer.zero_grad(): 이전 단계에서 계산된 기울기를 초기화합니다.loss.backward(): 역전파를 통해 기울기를 계산합니다.optimizer.step(): 계산된 기울기를 바탕으로 가중치를 업데이트합니다.☑️ 모델  평가모델 평가 {5px}모델 평가 변환합니다.다중 클래스 분류 문제 (Multi-Class Classification):출력 레이어의 뉴런 수는 예측하려는 클래스 수와 동일합니다.활성화 함수로는 소프트맥스 함수(Softmax Function)를 사용하여 각 클래스에 대한 확률을 출력합니다.02. 실습: 간단한 인공 신경망 모델 구현 (PyTorch)✔️ PyTorch를 사용하여 간단한\n",
      "Quiz : Quiz: PyTorch를 사용하여 인공 신경망 모델을 구축할 때, 'optimizer.zero_grad()'의 역할은 무엇인가요?\n",
      "\n",
      "a) 모델의 가중치를 초기화합니다.\n",
      "b) 이전 단계에서 계산된 기울기를 초기화합니다.\n",
      "c) 역전파를 통해 기울기를 계산합니다.\n",
      "d) 입력 데이터의 특성을 추출합니다.\n",
      "\n",
      "정답: b) 이전 단계에서 계산된 기울기를 초기화합니다.\n",
      "TEXT 파일 저장 완료: quiz_list_7.txt\n",
      "Updated quiz_list: ['**Quiz:**\\n\\n딥러닝은 음성 인식 시스템의 성능을 어떻게 향상시켰습니까?\\n\\na) 딥러닝은 음성 인식 시스템에서 사용자의 목소리를 텍스트로 변환하는 데 사용됩니다.  \\nb) 딥러닝은 음성 인식 시스템에서만 사용되며, 의료 분야에서는 활용되지 않습니다.  \\nc) 딥러닝은 음성 인식 시스템에서 사용자의 목소리를 무시하는 기능을 제공합니다.  \\nd) 딥러닝은 음성 인식 시스템에서 사용자의 목소리를 저장하지 않는 데 도움을 줍니다.  \\n\\n정답: a) 딥러닝은 음성 인식 시스템에서 사용자의 목소리를 텍스트로 변환하는 데 사용됩니다.', 'Quiz:\\n\\n다음 중 퍼셉트론(Perceptron)의 수학적 표현에 포함되지 않는 요소는 무엇입니까?\\n\\nA) 입력 값 (xi)\\n\\nB) 가중치 (wi)\\n\\nC) 활성화 함수 (f)\\n\\nD) 손실 함수 (Loss function) \\n\\n정답: D) 손실 함수 (Loss function) \\n\\n퍼셉트론의 수학적 표현은 y=f(∑i=1nwixi+b)로, 여기에는 입력 값, 가중치, 바이어스, 활성화 함수가 포함되지만 손실 함수는 포함되지 않습니다.', 'Quiz: 역전파(Backpropagation) 알고리즘에 대한 설명으로 옳지 않은 것은 무엇인가요?\\n\\nA) 역전파는 출력에서 입력 방향으로 손실 함수의 기울기를 계산합니다.  \\nB) 역전파는 연쇄 법칙(Chain Rule)을 사용해 손실 함수의 기울기를 계산합니다.  \\nC) 역전파는 신경망의 가중치를 학습시키기 위해 사용되는 알고리즘입니다.  \\nD) 역전파는 입력에서 출력 방향으로 손실 함수의 기울기를 계산합니다.  \\n\\n정답: D) 역전파는 입력에서 출력 방향으로 손실 함수의 기울기를 계산합니다.', '**Quiz:**\\n\\n가상환경을 생성하기 위한 Conda 명령어는 무엇인가요?\\n\\na) conda start --name myenv python=3.8  \\nb) conda build --name myenv python=3.8  \\nc) conda create --name myenv python=3.8  \\nd) conda init --name myenv python=3.8  \\n\\n**정답:** c) conda create --name myenv python=3.8', 'Q: 다음 중 가상환경을 Jupyter Notebook에 커널로 추가하는 명령어로 알맞은 것은 무엇인가요?\\n\\nA) conda create --name myenv python=3.8  \\nB) conda activate myenv  \\nC) conda install numpy pandas matplotlib  \\nD) python -m ipykernel install --user --name myenv --display-name \"Python (myenv)\"  \\n\\n정답: D) python -m ipykernel install --user --name myenv --display-name \"Python (myenv)\"', \"Quiz: PyTorch를 사용하여 인공 신경망 모델을 구축할 때, 'optimizer.zero_grad()'의 역할은 무엇인가요?\\n\\na) 모델의 가중치를 초기화합니다.\\nb) 이전 단계에서 계산된 기울기를 초기화합니다.\\nc) 역전파를 통해 기울기를 계산합니다.\\nd) 입력 데이터의 특성을 추출합니다.\\n\\n정답: b) 이전 단계에서 계산된 기울기를 초기화합니다.\"]\n",
      "Feedback:\n",
      "AIMessage(content=\"- 정답 여부: 예\\n- 추가 설명: PyTorch에서 'optimizer.zero_grad()'는 이전 단계에서 계산된 기울기를 초기화하는 역할을 합니다. 이는 역전파 과정에서 누적된 기울기가 다음 업데이트에 영향을 미치지 않도록 하기 위해 중요합니다. 따라서 매번 역전파를 실행하기 전에 기울기를 초기화하여 정확한 가중치 업데이트를 보장합니다.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 89, 'prompt_tokens': 199, 'total_tokens': 288, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_7f6be3efb0', 'finish_reason': 'stop', 'logprobs': None}, id='run-49f3a94f-8106-4f04-b226-1f3132169a2e-0', usage_metadata={'input_tokens': 199, 'output_tokens': 89, 'total_tokens': 288, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})\n",
      "퀴즈를 생성합니다 ===============\n",
      "Debug Output: 퀴즈 하나를 생성해줘\n",
      "Debug Output: {'context': [Document(metadata={}, page_content='간단한 인공신경망 모델 구현 실습을 진행해 봅시다[목차]01. 기본 구조와 동작원리02. 실습: 간단한 인공 신경망 모델 구현 (PyTorch) - 입력데이터를 받아들이는 층, 입력층의 뉴런수는 입력데이터 피쳐수와 동일 - 입력데이터를 받아들이는 층, 입력층의 뉴런수는 입력데이터 피쳐수와 동일\\ufeff'), Document(metadata={}, page_content='은닉층\\n - 입력데이터를 처리하고 특징을 추출하는 층, 은닉층의 뉴런수와 층수는 모델의 복잡성과 성능에 영향 - 입력데이터를 처리하고 특징을 추출하는 층, 은닉층의 뉴런수와 층수는 모델의 복잡성과 성능에 영향\\ufeff\\n출력층'), Document(metadata={}, page_content='각 샘플에 대해 가장 높은 확률을 가진 클래스를 반환합니다.\\ufeff\\u200blabels.size(0): 배치 크기를 반환합니다.(predicted == labels).sum().item(): 예측 값과 실제 값이 일치하는 샘플의 수를 계산합니다.Copyright ⓒ TeamSparta All rights reserved.'), Document(metadata={}, page_content='\\u200b☑️ 간단한 ANN 모델 정의간단한 ANN 모델 정의 {5px}간단한 ANN 모델 정의 \\ufeff\\u200bPythonCopyclass SimpleANN(nn.Module):\\ndef __init__(self):\\nsuper(SimpleANN, self).__init__()'), Document(metadata={}, page_content='PyTorch를 사용하여 간단한 인공 신경망 모델을 구축하고 학습해보겠습니다. 예제로는 MNIST 데이터셋을 사용하여 숫자 이미지를 분류하는 모델을 구현하겠습니다.1)  간단한 ANN 모델 구축 및 학습☑️ PyTorch 및 필요한 라이브러리 임포트PyTorch 및 필요한 라이브러리 임포트 {5px}PyTorch 및 필요한 라이브러리 임포트'), Document(metadata={}, page_content='모멘텀 값을 지정합니다.은 학습률, momentum은 모멘텀 값을 지정합니다.\\ufeff\\u200boptimizer.zero_grad(): 이전 단계에서 계산된 기울기를 초기화합니다.loss.backward(): 역전파를 통해 기울기를 계산합니다.optimizer.step(): 계산된 기울기를 바탕으로 가중치를 업데이트합니다.☑️ 모델  평가모델 평가 {5px}모델 평가'), Document(metadata={}, page_content='변환합니다.다중 클래스 분류 문제 (Multi-Class Classification):출력 레이어의 뉴런 수는 예측하려는 클래스 수와 동일합니다.활성화 함수로는 소프트맥스 함수(Softmax Function)를 사용하여 각 클래스에 대한 확률을 출력합니다.02. 실습: 간단한 인공 신경망 모델 구현 (PyTorch)✔️ PyTorch를 사용하여 간단한')], 'quiz_list': '퀴즈 하나를 생성해줘'}\n",
      "Context output: 간단한 인공신경망 모델 구현 실습을 진행해 봅시다[목차]01. 기본 구조와 동작원리02. 실습: 간단한 인공 신경망 모델 구현 (PyTorch) - 입력데이터를 받아들이는 층, 입력층의 뉴런수는 입력데이터 피쳐수와 동일 - 입력데이터를 받아들이는 층, 입력층의 뉴런수는 입력데이터 피쳐수와 동일﻿ 은닉층\n",
      " - 입력데이터를 처리하고 특징을 추출하는 층, 은닉층의 뉴런수와 층수는 모델의 복잡성과 성능에 영향 - 입력데이터를 처리하고 특징을 추출하는 층, 은닉층의 뉴런수와 층수는 모델의 복잡성과 성능에 영향﻿\n",
      "출력층 각 샘플에 대해 가장 높은 확률을 가진 클래스를 반환합니다.﻿​labels.size(0): 배치 크기를 반환합니다.(predicted == labels).sum().item(): 예측 값과 실제 값이 일치하는 샘플의 수를 계산합니다.Copyright ⓒ TeamSparta All rights reserved. ​☑️ 간단한 ANN 모델 정의간단한 ANN 모델 정의 {5px}간단한 ANN 모델 정의 ﻿​PythonCopyclass SimpleANN(nn.Module):\n",
      "def __init__(self):\n",
      "super(SimpleANN, self).__init__() PyTorch를 사용하여 간단한 인공 신경망 모델을 구축하고 학습해보겠습니다. 예제로는 MNIST 데이터셋을 사용하여 숫자 이미지를 분류하는 모델을 구현하겠습니다.1)  간단한 ANN 모델 구축 및 학습☑️ PyTorch 및 필요한 라이브러리 임포트PyTorch 및 필요한 라이브러리 임포트 {5px}PyTorch 및 필요한 라이브러리 임포트 모멘텀 값을 지정합니다.은 학습률, momentum은 모멘텀 값을 지정합니다.﻿​optimizer.zero_grad(): 이전 단계에서 계산된 기울기를 초기화합니다.loss.backward(): 역전파를 통해 기울기를 계산합니다.optimizer.step(): 계산된 기울기를 바탕으로 가중치를 업데이트합니다.☑️ 모델  평가모델 평가 {5px}모델 평가 변환합니다.다중 클래스 분류 문제 (Multi-Class Classification):출력 레이어의 뉴런 수는 예측하려는 클래스 수와 동일합니다.활성화 함수로는 소프트맥스 함수(Softmax Function)를 사용하여 각 클래스에 대한 확률을 출력합니다.02. 실습: 간단한 인공 신경망 모델 구현 (PyTorch)✔️ PyTorch를 사용하여 간단한\n",
      "Quiz : **퀴즈**: 'PyTorch를 사용하여 간단한 인공 신경망 모델을 구현할 때, 역전파를 통해 기울기를 계산하는 메서드는 무엇인가요?**\n",
      "\n",
      "A) optimizer.zero_grad()\n",
      "\n",
      "B) loss.backward()\n",
      "\n",
      "C) optimizer.step()\n",
      "\n",
      "D) nn.Module\n",
      "\n",
      "정답: B) loss.backward()\n",
      "TEXT 파일 저장 완료: quiz_list_8.txt\n",
      "Updated quiz_list: ['Quiz:\\n\\n다음 중 퍼셉트론(Perceptron)의 수학적 표현에 포함되지 않는 요소는 무엇입니까?\\n\\nA) 입력 값 (xi)\\n\\nB) 가중치 (wi)\\n\\nC) 활성화 함수 (f)\\n\\nD) 손실 함수 (Loss function) \\n\\n정답: D) 손실 함수 (Loss function) \\n\\n퍼셉트론의 수학적 표현은 y=f(∑i=1nwixi+b)로, 여기에는 입력 값, 가중치, 바이어스, 활성화 함수가 포함되지만 손실 함수는 포함되지 않습니다.', 'Quiz: 역전파(Backpropagation) 알고리즘에 대한 설명으로 옳지 않은 것은 무엇인가요?\\n\\nA) 역전파는 출력에서 입력 방향으로 손실 함수의 기울기를 계산합니다.  \\nB) 역전파는 연쇄 법칙(Chain Rule)을 사용해 손실 함수의 기울기를 계산합니다.  \\nC) 역전파는 신경망의 가중치를 학습시키기 위해 사용되는 알고리즘입니다.  \\nD) 역전파는 입력에서 출력 방향으로 손실 함수의 기울기를 계산합니다.  \\n\\n정답: D) 역전파는 입력에서 출력 방향으로 손실 함수의 기울기를 계산합니다.', '**Quiz:**\\n\\n가상환경을 생성하기 위한 Conda 명령어는 무엇인가요?\\n\\na) conda start --name myenv python=3.8  \\nb) conda build --name myenv python=3.8  \\nc) conda create --name myenv python=3.8  \\nd) conda init --name myenv python=3.8  \\n\\n**정답:** c) conda create --name myenv python=3.8', 'Q: 다음 중 가상환경을 Jupyter Notebook에 커널로 추가하는 명령어로 알맞은 것은 무엇인가요?\\n\\nA) conda create --name myenv python=3.8  \\nB) conda activate myenv  \\nC) conda install numpy pandas matplotlib  \\nD) python -m ipykernel install --user --name myenv --display-name \"Python (myenv)\"  \\n\\n정답: D) python -m ipykernel install --user --name myenv --display-name \"Python (myenv)\"', \"Quiz: PyTorch를 사용하여 인공 신경망 모델을 구축할 때, 'optimizer.zero_grad()'의 역할은 무엇인가요?\\n\\na) 모델의 가중치를 초기화합니다.\\nb) 이전 단계에서 계산된 기울기를 초기화합니다.\\nc) 역전파를 통해 기울기를 계산합니다.\\nd) 입력 데이터의 특성을 추출합니다.\\n\\n정답: b) 이전 단계에서 계산된 기울기를 초기화합니다.\", \"**퀴즈**: 'PyTorch를 사용하여 간단한 인공 신경망 모델을 구현할 때, 역전파를 통해 기울기를 계산하는 메서드는 무엇인가요?**\\n\\nA) optimizer.zero_grad()\\n\\nB) loss.backward()\\n\\nC) optimizer.step()\\n\\nD) nn.Module\\n\\n정답: B) loss.backward()\"]\n",
      "Feedback:\n",
      "AIMessage(content='- 정답 여부: 예\\n- 추가 설명: PyTorch에서 인공 신경망을 구현할 때, `loss.backward()` 메서드는 손실 함수의 역전파를 통해 모든 학습 가능한 매개변수에 대한 기울기를 계산합니다. 이 과정은 각 매개변수의 `grad` 속성에 기울기를 저장합니다. 그 후, `optimizer.step()`을 호출하여 계산된 기울기를 사용해 매개변수를 업데이트합니다. `optimizer.zero_grad()`는 이전 단계에서 계산된 기울기를 초기화하는 데 사용됩니다. `nn.Module`은 PyTorch에서 모델을 정의할 때 사용하는 기본 클래스입니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 140, 'prompt_tokens': 175, 'total_tokens': 315, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_7f6be3efb0', 'finish_reason': 'stop', 'logprobs': None}, id='run-88c65642-2c59-41b5-bd96-a1ab62248ef4-0', usage_metadata={'input_tokens': 175, 'output_tokens': 140, 'total_tokens': 315, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})\n",
      "4 번째 docs 참고\n",
      "퀴즈를 생성합니다 ===============\n",
      "Debug Output: 퀴즈 하나를 생성해줘\n",
      "Debug Output: {'context': [Document(metadata={}, page_content='각 샘플에 대해 가장 높은 확률을 가진 클래스를 반환합니다.\\ufeff\\u200blabels.size(0): 배치 크기를 반환합니다.(predicted == labels).sum().item(): 예측 값과 실제 값이 일치하는 샘플의 수를 계산합니다.Copyright ⓒ TeamSparta All rights reserved.'), Document(metadata={}, page_content='패턴을 학습합니다.여러 개의 필터를 사용하여 다양한 특징 맵을 생성할 수 있습니다.3) 풀링 레이어, 플래튼☑️ 풀링 레이어의 필요성과 종류풀링 층은 특징 맵의 크기를 줄이고, 중요한 특징을 추출하는 역할을 합니다. 풀링 층은 주로 Max Pooling과 Average Pooling이 사용됩니다.Max Pooling:필터 크기 내에서 최대 값을'), Document(metadata={}, page_content='\\u200b☑️ 간단한 CNN 모델 정의간단한 CNN 모델 정의 {5px}간단한 CNN 모델 정의 \\ufeff\\u200bPythonCopyclass SimpleCNN(nn.Module):\\ndef __init__(self):\\nsuper(SimpleCNN, self).__init__()'), Document(metadata={}, page_content='알아봅시다Pytorch로 간단한 CNN 모델 구현 실습을 진행해 봅시다[목차]01. CNN의 기본 구조와 동작 원리02. 실습: CNN을 이용한 이미지 분류 (PyTorch) - 입력 이미지에 필터(커널)를 적용하여 특징 맵(feature map)을 생성합니다. - 입력 이미지에 필터(커널)를 적용하여 특징 맵(feature map)을 생성합니다.\\ufeff'), Document(metadata={}, page_content='trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)'), Document(metadata={}, page_content='모멘텀 값을 지정합니다.은 학습률, momentum은 모멘텀 값을 지정합니다.\\ufeff\\u200boptimizer.zero_grad(): 이전 단계에서 계산된 기울기를 초기화합니다.loss.backward(): 역전파를 통해 기울기를 계산합니다.optimizer.step(): 계산된 기울기를 바탕으로 가중치를 업데이트합니다.☑️ 모델  평가모델 평가 {5px}모델 평가'), Document(metadata={}, page_content=\"# CIFAR-10 데이터셋 로드\\ntrainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\"), Document(metadata={}, page_content='텐서의 크기를 변경합니다.x.view(-1, 64 * 8 * 8)은 특징 맵을 1차원 벡터로 변환합니다..view(-1, 64 * 8 * 8)은 특징 맵을 1차원 벡터로 변환합니다.\\ufeff\\u200b☑️ 모델 학습모델 학습 {5px}모델 학습 \\ufeff\\u200bPythonCopy# 모델 초기화'), Document(metadata={}, page_content='크기 내에서 최대 값을 선택합니다.중요한 특징을 강조하고, 불필요한 정보를 제거합니다.Average Pooling:필터 크기 내에서 평균 값을 계산합니다.특징 맵의 크기를 줄이면서, 정보의 손실을 최소화합니다.☑️ 플래튼 레이어의 역할플래튼 층(Flatten Layer)은 2차원 특징 맵을 1차원 벡터로 변환하는 역할을 합니다. 이는 완전 연결 층에')], 'quiz_list': '퀴즈 하나를 생성해줘'}\n",
      "Context output: 각 샘플에 대해 가장 높은 확률을 가진 클래스를 반환합니다.﻿​labels.size(0): 배치 크기를 반환합니다.(predicted == labels).sum().item(): 예측 값과 실제 값이 일치하는 샘플의 수를 계산합니다.Copyright ⓒ TeamSparta All rights reserved. 패턴을 학습합니다.여러 개의 필터를 사용하여 다양한 특징 맵을 생성할 수 있습니다.3) 풀링 레이어, 플래튼☑️ 풀링 레이어의 필요성과 종류풀링 층은 특징 맵의 크기를 줄이고, 중요한 특징을 추출하는 역할을 합니다. 풀링 층은 주로 Max Pooling과 Average Pooling이 사용됩니다.Max Pooling:필터 크기 내에서 최대 값을 ​☑️ 간단한 CNN 모델 정의간단한 CNN 모델 정의 {5px}간단한 CNN 모델 정의 ﻿​PythonCopyclass SimpleCNN(nn.Module):\n",
      "def __init__(self):\n",
      "super(SimpleCNN, self).__init__() 알아봅시다Pytorch로 간단한 CNN 모델 구현 실습을 진행해 봅시다[목차]01. CNN의 기본 구조와 동작 원리02. 실습: CNN을 이용한 이미지 분류 (PyTorch) - 입력 이미지에 필터(커널)를 적용하여 특징 맵(feature map)을 생성합니다. - 입력 이미지에 필터(커널)를 적용하여 특징 맵(feature map)을 생성합니다.﻿ trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True) 모멘텀 값을 지정합니다.은 학습률, momentum은 모멘텀 값을 지정합니다.﻿​optimizer.zero_grad(): 이전 단계에서 계산된 기울기를 초기화합니다.loss.backward(): 역전파를 통해 기울기를 계산합니다.optimizer.step(): 계산된 기울기를 바탕으로 가중치를 업데이트합니다.☑️ 모델  평가모델 평가 {5px}모델 평가 # CIFAR-10 데이터셋 로드\n",
      "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform) 텐서의 크기를 변경합니다.x.view(-1, 64 * 8 * 8)은 특징 맵을 1차원 벡터로 변환합니다..view(-1, 64 * 8 * 8)은 특징 맵을 1차원 벡터로 변환합니다.﻿​☑️ 모델 학습모델 학습 {5px}모델 학습 ﻿​PythonCopy# 모델 초기화 크기 내에서 최대 값을 선택합니다.중요한 특징을 강조하고, 불필요한 정보를 제거합니다.Average Pooling:필터 크기 내에서 평균 값을 계산합니다.특징 맵의 크기를 줄이면서, 정보의 손실을 최소화합니다.☑️ 플래튼 레이어의 역할플래튼 층(Flatten Layer)은 2차원 특징 맵을 1차원 벡터로 변환하는 역할을 합니다. 이는 완전 연결 층에\n",
      "Quiz : Question: 아래 설명에 해당하는 풀링 층의 종류는 무엇인가요? \"필터 크기 내에서 최대 값을 선택하여 중요한 특징을 강조하고, 불필요한 정보를 제거합니다.\"\n",
      "\n",
      "A) Average Pooling  \n",
      "B) Max Pooling  \n",
      "C) Flatten Layer  \n",
      "D) Batch Normalization  \n",
      "\n",
      "정답: B) Max Pooling\n",
      "TEXT 파일 저장 완료: quiz_list_9.txt\n",
      "Updated quiz_list: ['Quiz: 역전파(Backpropagation) 알고리즘에 대한 설명으로 옳지 않은 것은 무엇인가요?\\n\\nA) 역전파는 출력에서 입력 방향으로 손실 함수의 기울기를 계산합니다.  \\nB) 역전파는 연쇄 법칙(Chain Rule)을 사용해 손실 함수의 기울기를 계산합니다.  \\nC) 역전파는 신경망의 가중치를 학습시키기 위해 사용되는 알고리즘입니다.  \\nD) 역전파는 입력에서 출력 방향으로 손실 함수의 기울기를 계산합니다.  \\n\\n정답: D) 역전파는 입력에서 출력 방향으로 손실 함수의 기울기를 계산합니다.', '**Quiz:**\\n\\n가상환경을 생성하기 위한 Conda 명령어는 무엇인가요?\\n\\na) conda start --name myenv python=3.8  \\nb) conda build --name myenv python=3.8  \\nc) conda create --name myenv python=3.8  \\nd) conda init --name myenv python=3.8  \\n\\n**정답:** c) conda create --name myenv python=3.8', 'Q: 다음 중 가상환경을 Jupyter Notebook에 커널로 추가하는 명령어로 알맞은 것은 무엇인가요?\\n\\nA) conda create --name myenv python=3.8  \\nB) conda activate myenv  \\nC) conda install numpy pandas matplotlib  \\nD) python -m ipykernel install --user --name myenv --display-name \"Python (myenv)\"  \\n\\n정답: D) python -m ipykernel install --user --name myenv --display-name \"Python (myenv)\"', \"Quiz: PyTorch를 사용하여 인공 신경망 모델을 구축할 때, 'optimizer.zero_grad()'의 역할은 무엇인가요?\\n\\na) 모델의 가중치를 초기화합니다.\\nb) 이전 단계에서 계산된 기울기를 초기화합니다.\\nc) 역전파를 통해 기울기를 계산합니다.\\nd) 입력 데이터의 특성을 추출합니다.\\n\\n정답: b) 이전 단계에서 계산된 기울기를 초기화합니다.\", \"**퀴즈**: 'PyTorch를 사용하여 간단한 인공 신경망 모델을 구현할 때, 역전파를 통해 기울기를 계산하는 메서드는 무엇인가요?**\\n\\nA) optimizer.zero_grad()\\n\\nB) loss.backward()\\n\\nC) optimizer.step()\\n\\nD) nn.Module\\n\\n정답: B) loss.backward()\", 'Question: 아래 설명에 해당하는 풀링 층의 종류는 무엇인가요? \"필터 크기 내에서 최대 값을 선택하여 중요한 특징을 강조하고, 불필요한 정보를 제거합니다.\"\\n\\nA) Average Pooling  \\nB) Max Pooling  \\nC) Flatten Layer  \\nD) Batch Normalization  \\n\\n정답: B) Max Pooling']\n",
      "대화를 종료합니다.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "j = 0\n",
    "cnt = 0\n",
    "quiz_list = []\n",
    "\n",
    "# 사용자가 \"exit\" 을 입력할 경우, 대화가 종료됩니다.\n",
    "\n",
    "while True: \n",
    "\n",
    "    if (j %2 == 0 and j > 0):\n",
    "        cnt += 1\n",
    "        print(f\"{cnt} 번째 docs 참고\")\n",
    "    print(\"퀴즈를 생성합니다 ===============\")\n",
    "    quiz_list = quiz_list[-5:]  # 최신 5개 퀴즈만 보관\n",
    "    quiz_str = \" \".join(quiz_list)\n",
    "    rag_chain = create_rag_chain(retriever_list[cnt])\n",
    "\n",
    "    query = prompt.format(\n",
    "    context=retriever_list[cnt],  # 'context' 값 전달\n",
    "    quiz_list=quiz_list,          # 'quiz_list' 값 전달\n",
    "    )\n",
    "\n",
    "\n",
    "    try:\n",
    "        response = rag_chain.invoke(\"퀴즈 하나를 생성해줘\")\n",
    "    except Exception as e:\n",
    "        print(f\"Quiz 생성 중 오류 발생: {e}\")\n",
    "        break\n",
    "    \n",
    "    quiz = response\n",
    "    \n",
    "    quiz_list.append(quiz)\n",
    "    print(f\"Quiz : {quiz}\")\n",
    "    j+=1\n",
    "    save_file(''.join(str(quiz)), f\"quiz_list_{j}.txt\")\n",
    "    print(f\"Updated quiz_list: {quiz_list}\")\n",
    "    \n",
    "    \n",
    "    # 2. 사용자 답변 수집\n",
    "    user_answer = input(\"답변을 입력하세요: \").strip()\n",
    "\n",
    "    if user_answer.strip().lower() == \"exit\":\n",
    "        print(\"대화를 종료합니다.\")\n",
    "        break\n",
    "    \n",
    "    if not user_answer:\n",
    "        print(\"답변이 비어 있습니다. 다시 입력해주세요.\")\n",
    "        continue\n",
    "\n",
    "    # 3. 사용자 답변에 대한 피드백 생성\n",
    "    feedback_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", f\"\"\"\n",
    "        AI 강사로서 다음 퀴즈의 정답 여부를 확인하고 피드백을 제공하세요.\n",
    "        피드백은 아래와 같은 형식이어야 합니다:\n",
    "        - 정답 여부: \"N번\" 또는 \"예/아니오\"\n",
    "        - 추가 설명: (정답과 관련된 추가 정보를 제공하세요)\n",
    "         \n",
    "        퀴즈: {quiz}\n",
    "        사용자의 답변: {user_answer}\n",
    "        피드백:\n",
    "        \"\"\")\n",
    "    ])\n",
    "    feedback_chain = feedback_prompt | llm\n",
    "    feedback = feedback_chain.invoke({\"quiz\": quiz, \"answer\": user_answer})\n",
    "    print(\"Feedback:\")\n",
    "    pprint(feedback)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_model",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
