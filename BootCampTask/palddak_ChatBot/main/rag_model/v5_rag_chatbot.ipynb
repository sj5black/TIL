{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "from langchain.schema import Document\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "import json\n",
    "\n",
    "\n",
    "# .env 파일에서 환경변수 로드\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPEN_AI_KEY\")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_txt_list = []\n",
    "dl_txt_list = []\n",
    "llm_txt_list = []\n",
    "python_txt_list = []\n",
    "open_source_txt_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# 파일을 읽어와서 text_list에 저장하는 함수\n",
    "def load_files_to_list(file_path, text_list):\n",
    "    if os.path.exists(file_path):  # 파일이 존재하는지 확인\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:  # 파일 열기\n",
    "            content = file.read()  # 파일 내용 읽기\n",
    "            text_list.append(content)  # text_list에 추가\n",
    "    else:\n",
    "        print(f\"File {file_path} not found.\")\n",
    "\n",
    "def save_txt_list(type_:str, length_:int, list_:list):\n",
    "    file_paths = [f\"dataset/{type_}_dataset_{i}.txt\" for i in range(1, length_+1)]  # 파일 경로 목록 (DL_dataset_1.txt, DL_dataset_2.txt, ...)\n",
    "\n",
    "    for j in range(len(file_paths)):\n",
    "        load_files_to_list(file_paths[j], list_)\n",
    "\n",
    "    print(f\"{type_} 관련 {len(list_)} 개의 파일 저장 완료\")\n",
    "\n",
    "    return list_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML 관련 23 개의 파일 저장 완료\n",
      "DL 관련 16 개의 파일 저장 완료\n",
      "LLM 관련 18 개의 파일 저장 완료\n",
      "PYTHON 관련 16 개의 파일 저장 완료\n",
      "OPENSOURCE 관련 7 개의 파일 저장 완료\n"
     ]
    }
   ],
   "source": [
    "ml_txt_list = save_txt_list(\"ML\", 23, ml_txt_list)\n",
    "dl_txt_list = save_txt_list(\"DL\", 16, dl_txt_list)\n",
    "llm_txt_list = save_txt_list(\"LLM\", 18, llm_txt_list)\n",
    "python_txt_list = save_txt_list(\"PYTHON\", 16, python_txt_list)\n",
    "open_source_txt_list = save_txt_list(\"OPENSOURCE\", 7, open_source_txt_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "import random\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "from langchain.schema import Document\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "def get_retriever(texts: str, current_index:int):\n",
    "\n",
    "    # text_list를 Document 객체로 변환\n",
    "    documents = [Document(page_content=texts)]\n",
    "\n",
    "    recursive_text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=200,\n",
    "        chunk_overlap=20,\n",
    "        length_function=len,\n",
    "        is_separator_regex=False,\n",
    "    )\n",
    "\n",
    "    splits_recur = recursive_text_splitter.split_documents(documents)\n",
    "    total_chunks = len(splits_recur)\n",
    "    # 다음 인덱스 계산\n",
    "    next_index = current_index + 10\n",
    "    if next_index > total_chunks:  # 초과 시 순환 처리\n",
    "        selected_splits = splits_recur[current_index:] + splits_recur[:next_index % total_chunks]\n",
    "    else:\n",
    "        selected_splits = splits_recur[current_index:next_index]\n",
    "\n",
    "    # # current_index 업데이트 (다음 호출을 위한 값)\n",
    "    # current_index = next_index % total_chunks\n",
    "    splits = selected_splits\n",
    "\n",
    "\n",
    "    print(\"Top 10 chunks:\")\n",
    "    for i, chunk in enumerate(splits[:10], 1):\n",
    "        pprint(f\"\\nChunk {i}:\\n{chunk.page_content}\")\n",
    "\n",
    "    # OpenAI 임베딩 모델 초기화\n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\", api_key=api_key)\n",
    "    vectorstore = FAISS.from_documents(documents=splits, embedding=embeddings)\n",
    "    bm25_retriever = BM25Retriever.from_documents(splits)\n",
    "    faiss_retriever = vectorstore.as_retriever()\n",
    "\n",
    "    retriever = EnsembleRetriever(\n",
    "                retrievers=[bm25_retriever, faiss_retriever],\n",
    "                weights=[0.5, 0.5],  # 가중치 설정 (가중치의 합은 1.0)\n",
    "            )\n",
    "\n",
    "    return retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "import random\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "from langchain.schema import Document\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "def get_retriever(texts: str):\n",
    "\n",
    "    # text_list를 Document 객체로 변환\n",
    "    documents = [Document(page_content=texts)]\n",
    "\n",
    "    recursive_text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=200,\n",
    "        chunk_overlap=20,\n",
    "        length_function=len,\n",
    "        is_separator_regex=False,\n",
    "    )\n",
    "\n",
    "    splits_recur = recursive_text_splitter.split_documents(documents)\n",
    "    splits = splits_recur\n",
    "\n",
    "\n",
    "    print(\"Top 10 chunks:\")\n",
    "    for i, chunk in enumerate(splits[:10], 1):\n",
    "        pprint(f\"\\nChunk {i}:\\n{chunk.page_content}\")\n",
    "\n",
    "    # OpenAI 임베딩 모델 초기화\n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\", api_key=api_key)\n",
    "    vectorstore = FAISS.from_documents(documents=splits, embedding=embeddings)\n",
    "    bm25_retriever = BM25Retriever.from_documents(splits)\n",
    "    faiss_retriever = vectorstore.as_retriever()\n",
    "\n",
    "    retriever = EnsembleRetriever(\n",
    "                retrievers=[bm25_retriever, faiss_retriever],\n",
    "                weights=[0.5, 0.5],  # 가중치 설정 (가중치의 합은 1.0)\n",
    "            )\n",
    "\n",
    "    return retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_file(txt:str, file_name:str):\n",
    "\n",
    "    with open(file_name, 'w', encoding='utf-8') as content_file:\n",
    "        content_file.write(txt)\n",
    "\n",
    "    print(f\"TEXT 파일 저장 완료: {file_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FAISS, BM25 저장 후 로드 -> 성능 저하"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_retreiver(type:str, idx:int):\n",
    "\n",
    "\n",
    "#     identifier = f\"{type}_doc_{idx}\"\n",
    "\n",
    "#     # FAISS 로드\n",
    "#     faiss_path = f\"faiss_index_{identifier}\"\n",
    "#     embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\", api_key=api_key)\n",
    "#     vectorstore = FAISS.load_local(faiss_path, embeddings, allow_dangerous_deserialization=True)\n",
    "#     faiss_retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5})\n",
    "\n",
    "#     # BM25 로드\n",
    "#     bm25_path = f\"bm25_documents_{identifier}.json\"\n",
    "#     with open(bm25_path, \"r\", encoding=\"utf-8\") as f:\n",
    "#         loaded_docs = [Document(**doc) for doc in json.load(f)]\n",
    "#     bm25_retriever = BM25Retriever.from_documents(loaded_docs)\n",
    "\n",
    "#     # EnsembleRetriever 재구성\n",
    "#     retriever = EnsembleRetriever(\n",
    "#         retrievers=[bm25_retriever, faiss_retriever],\n",
    "#         weights=[0.5, 0.5],\n",
    "#     )\n",
    "\n",
    "#     return retriever\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "class DebugPassThrough(RunnablePassthrough):\n",
    "    def invoke(self, *args, **kwargs):\n",
    "        output = super().invoke(*args, **kwargs)\n",
    "        print(\"Debug Output:\", output)\n",
    "        return output\n",
    "    \n",
    "# Prompt 및 Chain 구성\n",
    "class ContextToText(RunnablePassthrough):\n",
    "    def invoke(self, inputs, config=None, **kwargs):  # config 인수 추가\n",
    "        # context의 각 문서를 문자열로 결합\n",
    "        context_text = \" \".join([doc.page_content for doc in inputs[\"context\"]])\n",
    "        print(f\"Context output: {context_text}\")\n",
    "        return {\"context\": context_text, \"quiz_list\": inputs[\"quiz_list\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"\n",
    "    당신은 AI 강사입니다.\n",
    "    아래의 {context} 안에서만 반드시 **한국말**로 된, 이전에 물어봤던 문제와 유사하지 않은\n",
    "    단 하나의 질문을 생성해주세요.\n",
    "    \n",
    "    반드시 질문은 질문 내용으로 명확히 답할 수 있는 질문이어야 합니다. \n",
    "    질문을 만들 때에는 코드와 관련된 특정 동작이나 목적에 대해 물어야 하며, 질문 안에 반드시 **코드를 포함**해야 합니다.\n",
    "    에시 코드는 질문에 포함하지마세요.\n",
    "    \n",
    "    예시:\n",
    "        코드:\n",
    "            dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "     \n",
    "        이 코드에서 이미지 데이터를 불러올 때 한 번에 32개의 이미지를 불러오나요? (O/X)\n",
    "     \n",
    "    [중요]\n",
    "    아래의 금지리스트들과 유사한 질문을 절대 생성하지 마시오.\n",
    "    금지리스트: 이전에 만들었던 질문, \"QuizList\"\n",
    "    \n",
    "    주관적인 변수에 대한 의견을 묻는 질문은 절대 생성하지 마세요.\n",
    "    예를 들어, \"타이타닉 데이터셋의 'embarked' 열을 숫자로 매핑할 때, 'S'는 어떤 숫자로 매핑되나요?\", \"2016년 이후의 데이터를 사용했을 때 r2 score와 mse가 더 좋은 점수를 보였다 (O, X 질문)\"와 같은 질문은 피해야 합니다.\n",
    "     \n",
    "    개발 외의 역량을 붇는 질문은 절대 생성하지 마세요.\n",
    "    예를 들어, \"위험중립형 투자자는 kodex골드, tiger나스닥100, kodex 삼성그룹을 각각 몇 개 매수하는 것이 추천되나요?\"와 같은 질문은 피해야 합니다.\n",
    "     \n",
    "    질문에서 제공된 정보로 명확히 답할 수 없는 질문만 절대 생성하지 마세요.\n",
    "    예를 들어, \"데이터가 증가할수록 모델의 평가지표가 안 좋아지는 이유는 무엇인가요? (O, X)\", \"이미지 데이터셋을 불러올 때 한 번에 몇 개의 이미지를 불러오나요? (a) 16개 (b) 32개 (c) 64개 (d) 128개\"와 같은 질문은 피해야 합니다.\n",
    "     \n",
    "    질문의 형태는 반드시 객관식 또는 OX 질문 형태여야만 합니다. (어떤, 무엇을 묻는 질문은 생성하지 마세요.)\n",
    "    예를 들어, \"인스턴트 초기화에 쓰이는 생성자에 __call__ 메소드를 호출하면 어떤 값이 반환되나요? (O/X)\"과 같은 질문은 피해야 합니다.\n",
    "    예를 들어, 주관식과 OX 질문이 결합되거나 객관식과 OX 질문이 결합된 형태는 절대 생성하지 마세요.\n",
    "     \n",
    "    또한, 아래의 제약 조건과 출제 방식에 맞춘 질문을 생성해주세요.\n",
    "     \n",
    "    제약 조건:\n",
    "    1. \"Context\"에서 제공된 내용만 기반으로 질문을 생성하세요.\n",
    "    2. AI와 관련된 질문만 생성하세요.\n",
    "    3. 질문의 형태는 객관식(MCQ) 또는 O,X 형태여야 합니다.\n",
    "    4. 질문은 반드시 질문 내용만 담겨야 합니다. \"quiz:\" 나 \"질문:\" 같은 불필요한 수식어구는 붙이지 마세요.\n",
    "    5. 질문에서 제공된 정보로 명확히 답할 수 있는 질문만 생성하세요.\n",
    "\n",
    "    출제 방식:\n",
    "    - 질문은 반드시 객관식(MCQ) 또는 O,X 형태로 출제합니다.\n",
    "    - \"Context\"에 명시적으로 언급된 개념, 정의, 또는 내용을 활용하세요.\n",
    "    \n",
    "    Context:\n",
    "    {context}\n",
    "    \n",
    "    QuizList:\n",
    "    {quiz_list}\n",
    "\n",
    "    \"\"\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concept_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"\n",
    "    당신은 AI 강사입니다.\n",
    "    아래의 {context} 안에서만 반드시 **한국말**로 된 하나의 질문을 생성해주세요.\n",
    "    (최대한 코드에 관한 시나리오적 질문이면 더 좋습니다.)\n",
    "    {quiz_list}에 존재하는 질문들과는 최대한 덜 유사한 질문을 생성해주세요.\n",
    "    아래의 제약 조건과 출제 방식에 맞춘 질문을 생성해주세요.\n",
    "     \n",
    "    제약 조건:\n",
    "    1. \"Context\"에서 제공된 내용만 기반으로 질문을 생성하세요.\n",
    "    2. AI 관련 내용이 아닌 질문은 생성하지 마세요\n",
    "    3. \"QuizList\"에 이미 있는 질문과 유사하지 않은 새로운 질문을 생성하세요.\n",
    "\n",
    "    출제 방식:\n",
    "    - 질문은 반드시 보기가 있는 객관식(MCQ) 또는 O,X 형태로 출제하세요.\n",
    "    - \"Context\"에 명시적으로 언급된 개념, 정의, 또는 내용을 활용하세요.\n",
    "    - 질문은 반드시 질문 내용만 담겨야 합니다. 정답을 포함하지마세요.\n",
    "    - 질문 내용에는 \"quiz:\" 나 \"질문:\" 같은 불필요한 수식어구는 담겨서는 안됩니다.\n",
    "    \n",
    "    Context:\n",
    "    {context}\n",
    "    \n",
    "    QuizList:\n",
    "    {quiz_list}\n",
    "\n",
    "    \"\"\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import StrOutputParser\n",
    "\n",
    "\n",
    "# RAG Chain 생성 함수\n",
    "def create_rag_chain(retriever):\n",
    "    return (\n",
    "        {\n",
    "            \"context\": retriever,\n",
    "            \"quiz_list\": DebugPassThrough()\n",
    "        }\n",
    "        | DebugPassThrough()  # DebugPassThrough()가 실제로 어떤 역할을 하는지 확인\n",
    "        | ContextToText()     # Text 변환을 위한 ContextToText\n",
    "        | prompt              # prompt 사용\n",
    "        | llm                 # LLM 호출\n",
    "        | StrOutputParser()   # 출력 파서\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG Chain 생성 함수\n",
    "def create_concept_rag_chain(retriever):\n",
    "    return (\n",
    "        {\n",
    "            \"context\": retriever,\n",
    "            \"quiz_list\": DebugPassThrough()\n",
    "        }\n",
    "        | DebugPassThrough()  # DebugPassThrough()가 실제로 어떤 역할을 하는지 확인\n",
    "        | ContextToText()     # Text 변환을 위한 ContextToText\n",
    "        | prompt             # prompt 사용\n",
    "        | llm                 # LLM 호출\n",
    "        | StrOutputParser()   # 출력 파서\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_txt_list(type_:str):\n",
    "\n",
    "    if type_ == \"dl\":\n",
    "        return dl_txt_list\n",
    "    if type_ == \"ml\":\n",
    "        return ml_txt_list\n",
    "    if type_ == \"llm\":\n",
    "        return llm_txt_list\n",
    "    if type_ == \"python\":\n",
    "        return python_txt_list\n",
    "    if type_ == \"open_source\":\n",
    "        return open_source_txt_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def is_similar(new_quiz, quiz_list, threshold=0.8):\n",
    "    vectorizer = TfidfVectorizer().fit_transform([new_quiz] + quiz_list)\n",
    "    vectors = vectorizer.toarray()\n",
    "    similarities = cosine_similarity(vectors[0:1], vectors[1:])\n",
    "    return any(sim >= threshold for sim in similarities[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 chunks:\n",
      "('\\n'\n",
      " 'Chunk 1:\\n'\n",
      " '[스파르타코딩클럽] 5. 합성곱 신경망(CNN)📘[SCC] 기초가 탄탄한 딥러닝/📚[스파르타코딩클럽] 기초가 탄탄한 딥러닝 - '\n",
      " '2주차/📕[스파르타코딩클럽] 5. 합성곱 신경망(CNN)Made with📕[스파르타코딩클럽] 5. 합성곱 신경망(CNN)[수업 '\n",
      " '목표]합성곱 신경망의 개념에 대해서 배워보고 어떤 원리로 동작하는지 알아봅시다Pytorch로 간단한')\n",
      "('\\n'\n",
      " 'Chunk 2:\\n'\n",
      " '알아봅시다Pytorch로 간단한 CNN 모델 구현 실습을 진행해 봅시다[목차]01. CNN의 기본 구조와 동작 원리02. 실습: CNN을 '\n",
      " '이용한 이미지 분류 (PyTorch) - 입력 이미지에 필터(커널)를 적용하여 특징 맵(feature map)을 생성합니다. - 입력 '\n",
      " '이미지에 필터(커널)를 적용하여 특징 맵(feature map)을 생성합니다.\\ufeff')\n",
      "('\\n'\n",
      " 'Chunk 3:\\n'\n",
      " '- 필터는 이미지의 국소적인 패턴을 학습합니다. - 필터는 이미지의 국소적인 패턴을 학습합니다.\\ufeff\\n'\n",
      " '풀링 층 (Pooling Layer)\\n'\n",
      " ' - 특징 맵의 크기를 줄이고, 중요한 특징을 추출합니다. - 특징 맵의 크기를 줄이고, 중요한 특징을 추출합니다.\\ufeff')\n",
      "('\\n'\n",
      " 'Chunk 4:\\n'\n",
      " '- 주로 Max Pooling과 Average Pooling이 사용됩니다. - 주로 Max Pooling과 Average Pooling이 '\n",
      " '사용됩니다.\\ufeff\\n'\n",
      " '완전 연결 층 (Fully Connected Layer)\\n'\n",
      " ' - 추출된 특징을 바탕으로 최종 예측을 수행합니다. - 추출된 특징을 바탕으로 최종 예측을 수행합니다.\\ufeff')\n",
      "('\\n'\n",
      " 'Chunk 5:\\n'\n",
      " '- CNN이라는 분석레이어를 통해 추출한 특성을 바탕으로 결론을 내리는 부분 - CNN이라는 분석레이어를 통해 추출한 특성을 바탕으로 '\n",
      " '결론을 내리는 부분\\ufeff\\u200b2) 합성곱 연산과 필터☑️ 합성곱 연산의 원리와 필터의 역할합성곱 연산은 입력 이미지에 '\n",
      " '필터(커널)를 적용하여 특징 맵을 생성하는 과정입니다. 필터는 작은 크기의 행렬로, 이미지의 국소적인 패턴을')\n",
      "('\\n'\n",
      " 'Chunk 6:\\n'\n",
      " '행렬로, 이미지의 국소적인 패턴을 학습합니다.합성곱 연산:필터를 이미지의 각 위치에 슬라이딩하며, 필터와 이미지의 해당 부분 간의 '\n",
      " '점곱(dot product)을 계산합니다.계산된 값은 특징 맵의 해당 위치에 저장됩니다.필터의 역할:필터는 이미지의 에지(edge), '\n",
      " '코너(corner), 텍스처(texture) 등 다양한 국소적인 패턴을 학습합니다.여러 개의')\n",
      "('\\n'\n",
      " 'Chunk 7:\\n'\n",
      " '패턴을 학습합니다.여러 개의 필터를 사용하여 다양한 특징 맵을 생성할 수 있습니다.3) 풀링 레이어, 플래튼☑️ 풀링 레이어의 필요성과 '\n",
      " '종류풀링 층은 특징 맵의 크기를 줄이고, 중요한 특징을 추출하는 역할을 합니다. 풀링 층은 주로 Max Pooling과 Average '\n",
      " 'Pooling이 사용됩니다.Max Pooling:필터 크기 내에서 최대 값을')\n",
      "('\\n'\n",
      " 'Chunk 8:\\n'\n",
      " '크기 내에서 최대 값을 선택합니다.중요한 특징을 강조하고, 불필요한 정보를 제거합니다.Average Pooling:필터 크기 내에서 평균 '\n",
      " '값을 계산합니다.특징 맵의 크기를 줄이면서, 정보의 손실을 최소화합니다.☑️ 플래튼 레이어의 역할플래튼 층(Flatten Layer)은 '\n",
      " '2차원 특징 맵을 1차원 벡터로 변환하는 역할을 합니다. 이는 완전 연결 층에')\n",
      "('\\n'\n",
      " 'Chunk 9:\\n'\n",
      " '합니다. 이는 완전 연결 층에 입력으로 사용하기 위해 필요합니다.4) CNN 구조와 응용☑️ 다양한 CNN 아키텍처LeNet:최초의 '\n",
      " 'CNN 아키텍처 중 하나로, 손글씨 숫자 인식에 사용되었습니다.합성곱 층과 풀링 층을 반복한 후, 완전 연결 층을 '\n",
      " '사용합니다.AlexNet:2012년 이미지넷 대회에서 우승한 아키텍처로, 딥러닝의 가능성을')\n",
      "('\\n'\n",
      " 'Chunk 10:\\n'\n",
      " '아키텍처로, 딥러닝의 가능성을 입증했습니다.ReLU 활성화 함수와 드롭아웃(dropout)을 도입하여 성능을 향상시켰습니다.VGG:깊고 '\n",
      " '규칙적인 구조를 가진 아키텍처로, 작은 3x3 필터를 사용하여 깊이를 증가시켰습니다.VGG16과 VGG19가 대표적인 모델입니다.02. '\n",
      " '실습: CNN을 이용한 이미지 분류 (PyTorch)✔️ 이제 PyTorch를')\n",
      "Debug Output: 퀴즈 하나를 생성해줘\n",
      "Debug Output: {'context': [Document(metadata={}, page_content='아키텍처로, 딥러닝의 가능성을 입증했습니다.ReLU 활성화 함수와 드롭아웃(dropout)을 도입하여 성능을 향상시켰습니다.VGG:깊고 규칙적인 구조를 가진 아키텍처로, 작은 3x3 필터를 사용하여 깊이를 증가시켰습니다.VGG16과 VGG19가 대표적인 모델입니다.02. 실습: CNN을 이용한 이미지 분류 (PyTorch)✔️ 이제 PyTorch를'), Document(metadata={}, page_content='패턴을 학습합니다.여러 개의 필터를 사용하여 다양한 특징 맵을 생성할 수 있습니다.3) 풀링 레이어, 플래튼☑️ 풀링 레이어의 필요성과 종류풀링 층은 특징 맵의 크기를 줄이고, 중요한 특징을 추출하는 역할을 합니다. 풀링 층은 주로 Max Pooling과 Average Pooling이 사용됩니다.Max Pooling:필터 크기 내에서 최대 값을'), Document(metadata={}, page_content='크기 내에서 최대 값을 선택합니다.중요한 특징을 강조하고, 불필요한 정보를 제거합니다.Average Pooling:필터 크기 내에서 평균 값을 계산합니다.특징 맵의 크기를 줄이면서, 정보의 손실을 최소화합니다.☑️ 플래튼 레이어의 역할플래튼 층(Flatten Layer)은 2차원 특징 맵을 1차원 벡터로 변환하는 역할을 합니다. 이는 완전 연결 층에'), Document(metadata={}, page_content='합니다. 이는 완전 연결 층에 입력으로 사용하기 위해 필요합니다.4) CNN 구조와 응용☑️ 다양한 CNN 아키텍처LeNet:최초의 CNN 아키텍처 중 하나로, 손글씨 숫자 인식에 사용되었습니다.합성곱 층과 풀링 층을 반복한 후, 완전 연결 층을 사용합니다.AlexNet:2012년 이미지넷 대회에서 우승한 아키텍처로, 딥러닝의 가능성을'), Document(metadata={}, page_content='알아봅시다Pytorch로 간단한 CNN 모델 구현 실습을 진행해 봅시다[목차]01. CNN의 기본 구조와 동작 원리02. 실습: CNN을 이용한 이미지 분류 (PyTorch) - 입력 이미지에 필터(커널)를 적용하여 특징 맵(feature map)을 생성합니다. - 입력 이미지에 필터(커널)를 적용하여 특징 맵(feature map)을 생성합니다.\\ufeff')], 'quiz_list': '퀴즈 하나를 생성해줘'}\n",
      "Context output: 아키텍처로, 딥러닝의 가능성을 입증했습니다.ReLU 활성화 함수와 드롭아웃(dropout)을 도입하여 성능을 향상시켰습니다.VGG:깊고 규칙적인 구조를 가진 아키텍처로, 작은 3x3 필터를 사용하여 깊이를 증가시켰습니다.VGG16과 VGG19가 대표적인 모델입니다.02. 실습: CNN을 이용한 이미지 분류 (PyTorch)✔️ 이제 PyTorch를 패턴을 학습합니다.여러 개의 필터를 사용하여 다양한 특징 맵을 생성할 수 있습니다.3) 풀링 레이어, 플래튼☑️ 풀링 레이어의 필요성과 종류풀링 층은 특징 맵의 크기를 줄이고, 중요한 특징을 추출하는 역할을 합니다. 풀링 층은 주로 Max Pooling과 Average Pooling이 사용됩니다.Max Pooling:필터 크기 내에서 최대 값을 크기 내에서 최대 값을 선택합니다.중요한 특징을 강조하고, 불필요한 정보를 제거합니다.Average Pooling:필터 크기 내에서 평균 값을 계산합니다.특징 맵의 크기를 줄이면서, 정보의 손실을 최소화합니다.☑️ 플래튼 레이어의 역할플래튼 층(Flatten Layer)은 2차원 특징 맵을 1차원 벡터로 변환하는 역할을 합니다. 이는 완전 연결 층에 합니다. 이는 완전 연결 층에 입력으로 사용하기 위해 필요합니다.4) CNN 구조와 응용☑️ 다양한 CNN 아키텍처LeNet:최초의 CNN 아키텍처 중 하나로, 손글씨 숫자 인식에 사용되었습니다.합성곱 층과 풀링 층을 반복한 후, 완전 연결 층을 사용합니다.AlexNet:2012년 이미지넷 대회에서 우승한 아키텍처로, 딥러닝의 가능성을 알아봅시다Pytorch로 간단한 CNN 모델 구현 실습을 진행해 봅시다[목차]01. CNN의 기본 구조와 동작 원리02. 실습: CNN을 이용한 이미지 분류 (PyTorch) - 입력 이미지에 필터(커널)를 적용하여 특징 맵(feature map)을 생성합니다. - 입력 이미지에 필터(커널)를 적용하여 특징 맵(feature map)을 생성합니다.﻿\n",
      "quiz_list의 크기:  1\n",
      "Quiz : VGG 아키텍처에서 작은 3x3 필터를 사용하는 주된 이유는 무엇인가요?\n",
      "\n",
      "A) 연산량을 줄이기 위해  \n",
      "B) 네트워크의 깊이를 증가시키기 위해  \n",
      "C) 파라미터 수를 증가시키기 위해  \n",
      "D) 필터의 크기를 다양하게 하기 위해  \n",
      "TEXT 파일 저장 완료: quiz_list_1.txt\n",
      "Feedback:\n",
      "content='- 정답 여부: \"아니오\"\\n- 추가 설명: VGG 아키텍처에서 작은 3x3 필터를 사용하는 주된 이유는 네트워크의 깊이를 증가시키기 위해서입니다. 작은 3x3 필터를 여러 층에 걸쳐 사용하면, 동일한 수의 파라미터로도 더 깊은 네트워크를 구축할 수 있게 됩니다. 이는 B가 정답입니다. 작은 필터를 사용함으로써 네트워크가 더 많은 비선형성을 학습할 수 있고, 결과적으로 더 복잡한 특징을 추출할 수 있습니다. 또한, 여러 개의 3x3 필터를 쌓는 것은 더 큰 필터를 사용하는 것과 비슷한 수용 영역을 가지면서도 더 적은 파라미터를 사용하게 합니다.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 178, 'prompt_tokens': 169, 'total_tokens': 347, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_7f6be3efb0', 'finish_reason': 'stop', 'logprobs': None} id='run-2323184e-ada1-45e0-b7b9-5c0cc118c488-0' usage_metadata={'input_tokens': 169, 'output_tokens': 178, 'total_tokens': 347, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "Top 10 chunks:\n",
      "('\\n'\n",
      " 'Chunk 1:\\n'\n",
      " '행렬로, 이미지의 국소적인 패턴을 학습합니다.합성곱 연산:필터를 이미지의 각 위치에 슬라이딩하며, 필터와 이미지의 해당 부분 간의 '\n",
      " '점곱(dot product)을 계산합니다.계산된 값은 특징 맵의 해당 위치에 저장됩니다.필터의 역할:필터는 이미지의 에지(edge), '\n",
      " '코너(corner), 텍스처(texture) 등 다양한 국소적인 패턴을 학습합니다.여러 개의')\n",
      "('\\n'\n",
      " 'Chunk 2:\\n'\n",
      " '패턴을 학습합니다.여러 개의 필터를 사용하여 다양한 특징 맵을 생성할 수 있습니다.3) 풀링 레이어, 플래튼☑️ 풀링 레이어의 필요성과 '\n",
      " '종류풀링 층은 특징 맵의 크기를 줄이고, 중요한 특징을 추출하는 역할을 합니다. 풀링 층은 주로 Max Pooling과 Average '\n",
      " 'Pooling이 사용됩니다.Max Pooling:필터 크기 내에서 최대 값을')\n",
      "('\\n'\n",
      " 'Chunk 3:\\n'\n",
      " '크기 내에서 최대 값을 선택합니다.중요한 특징을 강조하고, 불필요한 정보를 제거합니다.Average Pooling:필터 크기 내에서 평균 '\n",
      " '값을 계산합니다.특징 맵의 크기를 줄이면서, 정보의 손실을 최소화합니다.☑️ 플래튼 레이어의 역할플래튼 층(Flatten Layer)은 '\n",
      " '2차원 특징 맵을 1차원 벡터로 변환하는 역할을 합니다. 이는 완전 연결 층에')\n",
      "('\\n'\n",
      " 'Chunk 4:\\n'\n",
      " '합니다. 이는 완전 연결 층에 입력으로 사용하기 위해 필요합니다.4) CNN 구조와 응용☑️ 다양한 CNN 아키텍처LeNet:최초의 '\n",
      " 'CNN 아키텍처 중 하나로, 손글씨 숫자 인식에 사용되었습니다.합성곱 층과 풀링 층을 반복한 후, 완전 연결 층을 '\n",
      " '사용합니다.AlexNet:2012년 이미지넷 대회에서 우승한 아키텍처로, 딥러닝의 가능성을')\n",
      "('\\n'\n",
      " 'Chunk 5:\\n'\n",
      " '아키텍처로, 딥러닝의 가능성을 입증했습니다.ReLU 활성화 함수와 드롭아웃(dropout)을 도입하여 성능을 향상시켰습니다.VGG:깊고 '\n",
      " '규칙적인 구조를 가진 아키텍처로, 작은 3x3 필터를 사용하여 깊이를 증가시켰습니다.VGG16과 VGG19가 대표적인 모델입니다.02. '\n",
      " '실습: CNN을 이용한 이미지 분류 (PyTorch)✔️ 이제 PyTorch를')\n",
      "('\\n'\n",
      " 'Chunk 6:\\n'\n",
      " '이제 PyTorch를 사용하여 간단한 CNN 모델을 구축하고, CIFAR-10 데이터셋을 사용하여 이미지 분류를 수행해보겠습니다1)  '\n",
      " '간단한 CNN 모델을 이용한 이미지 분류 실습☑️ PyTorch 및 필요한 라이브러리 임포트PyTorch 및 필요한 라이브러리 임포트 '\n",
      " '{5px}PyTorch 및 필요한 라이브러리 임포트 \\ufeff\\u200bPythonCopyimport')\n",
      "'\\nChunk 7:\\n\\ufeff\\u200bPythonCopyimport torch'\n",
      "('\\n'\n",
      " 'Chunk 8:\\n'\n",
      " 'import torch.nn as nn\\n'\n",
      " 'import torch.optim as optim\\n'\n",
      " 'import torchvision\\n'\n",
      " 'import torchvision.transforms as transforms\\n'\n",
      " '\\u200b☑️데이터셋 로드 및 전처리데이터셋 로드 및 전처리 {5px}데이터셋 로드 및 전처리 '\n",
      " '\\ufeff\\u200bPythonCopy# 데이터셋 전처리')\n",
      "('\\n'\n",
      " 'Chunk 9:\\n'\n",
      " 'transform = transforms.Compose([\\n'\n",
      " '    transforms.ToTensor(),\\n'\n",
      " '    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\\n'\n",
      " '])\\n'\n",
      " '# CIFAR-10 데이터셋 로드')\n",
      "('\\n'\n",
      " 'Chunk 10:\\n'\n",
      " '# CIFAR-10 데이터셋 로드\\n'\n",
      " \"trainset = torchvision.datasets.CIFAR10(root='./data', train=True, \"\n",
      " 'download=True, transform=transform)')\n",
      "Debug Output: 퀴즈 하나를 생성해줘\n",
      "Debug Output: {'context': [Document(metadata={}, page_content=\"# CIFAR-10 데이터셋 로드\\ntrainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\"), Document(metadata={}, page_content='패턴을 학습합니다.여러 개의 필터를 사용하여 다양한 특징 맵을 생성할 수 있습니다.3) 풀링 레이어, 플래튼☑️ 풀링 레이어의 필요성과 종류풀링 층은 특징 맵의 크기를 줄이고, 중요한 특징을 추출하는 역할을 합니다. 풀링 층은 주로 Max Pooling과 Average Pooling이 사용됩니다.Max Pooling:필터 크기 내에서 최대 값을'), Document(metadata={}, page_content='transform = transforms.Compose([\\n    transforms.ToTensor(),\\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\\n])\\n# CIFAR-10 데이터셋 로드'), Document(metadata={}, page_content='크기 내에서 최대 값을 선택합니다.중요한 특징을 강조하고, 불필요한 정보를 제거합니다.Average Pooling:필터 크기 내에서 평균 값을 계산합니다.특징 맵의 크기를 줄이면서, 정보의 손실을 최소화합니다.☑️ 플래튼 레이어의 역할플래튼 층(Flatten Layer)은 2차원 특징 맵을 1차원 벡터로 변환하는 역할을 합니다. 이는 완전 연결 층에'), Document(metadata={}, page_content='import torch.nn as nn\\nimport torch.optim as optim\\nimport torchvision\\nimport torchvision.transforms as transforms\\n\\u200b☑️데이터셋 로드 및 전처리데이터셋 로드 및 전처리 {5px}데이터셋 로드 및 전처리 \\ufeff\\u200bPythonCopy# 데이터셋 전처리'), Document(metadata={}, page_content='이제 PyTorch를 사용하여 간단한 CNN 모델을 구축하고, CIFAR-10 데이터셋을 사용하여 이미지 분류를 수행해보겠습니다1)  간단한 CNN 모델을 이용한 이미지 분류 실습☑️ PyTorch 및 필요한 라이브러리 임포트PyTorch 및 필요한 라이브러리 임포트 {5px}PyTorch 및 필요한 라이브러리 임포트 \\ufeff\\u200bPythonCopyimport'), Document(metadata={}, page_content='\\ufeff\\u200bPythonCopyimport torch'), Document(metadata={}, page_content='아키텍처로, 딥러닝의 가능성을 입증했습니다.ReLU 활성화 함수와 드롭아웃(dropout)을 도입하여 성능을 향상시켰습니다.VGG:깊고 규칙적인 구조를 가진 아키텍처로, 작은 3x3 필터를 사용하여 깊이를 증가시켰습니다.VGG16과 VGG19가 대표적인 모델입니다.02. 실습: CNN을 이용한 이미지 분류 (PyTorch)✔️ 이제 PyTorch를')], 'quiz_list': '퀴즈 하나를 생성해줘'}\n",
      "Context output: # CIFAR-10 데이터셋 로드\n",
      "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform) 패턴을 학습합니다.여러 개의 필터를 사용하여 다양한 특징 맵을 생성할 수 있습니다.3) 풀링 레이어, 플래튼☑️ 풀링 레이어의 필요성과 종류풀링 층은 특징 맵의 크기를 줄이고, 중요한 특징을 추출하는 역할을 합니다. 풀링 층은 주로 Max Pooling과 Average Pooling이 사용됩니다.Max Pooling:필터 크기 내에서 최대 값을 transform = transforms.Compose([\n",
      "    transforms.ToTensor(),\n",
      "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
      "])\n",
      "# CIFAR-10 데이터셋 로드 크기 내에서 최대 값을 선택합니다.중요한 특징을 강조하고, 불필요한 정보를 제거합니다.Average Pooling:필터 크기 내에서 평균 값을 계산합니다.특징 맵의 크기를 줄이면서, 정보의 손실을 최소화합니다.☑️ 플래튼 레이어의 역할플래튼 층(Flatten Layer)은 2차원 특징 맵을 1차원 벡터로 변환하는 역할을 합니다. 이는 완전 연결 층에 import torch.nn as nn\n",
      "import torch.optim as optim\n",
      "import torchvision\n",
      "import torchvision.transforms as transforms\n",
      "​☑️데이터셋 로드 및 전처리데이터셋 로드 및 전처리 {5px}데이터셋 로드 및 전처리 ﻿​PythonCopy# 데이터셋 전처리 이제 PyTorch를 사용하여 간단한 CNN 모델을 구축하고, CIFAR-10 데이터셋을 사용하여 이미지 분류를 수행해보겠습니다1)  간단한 CNN 모델을 이용한 이미지 분류 실습☑️ PyTorch 및 필요한 라이브러리 임포트PyTorch 및 필요한 라이브러리 임포트 {5px}PyTorch 및 필요한 라이브러리 임포트 ﻿​PythonCopyimport ﻿​PythonCopyimport torch 아키텍처로, 딥러닝의 가능성을 입증했습니다.ReLU 활성화 함수와 드롭아웃(dropout)을 도입하여 성능을 향상시켰습니다.VGG:깊고 규칙적인 구조를 가진 아키텍처로, 작은 3x3 필터를 사용하여 깊이를 증가시켰습니다.VGG16과 VGG19가 대표적인 모델입니다.02. 실습: CNN을 이용한 이미지 분류 (PyTorch)✔️ 이제 PyTorch를\n",
      "quiz_list의 크기:  2\n",
      "Quiz : CIFAR-10 데이터셋의 전처리 과정에서 사용된 transforms.Normalize의 역할은 무엇인가요?\n",
      "\n",
      "a) 이미지의 크기를 변경한다.\n",
      "b) 이미지의 채널을 회전시킨다.\n",
      "c) 이미지의 픽셀 값을 정규화한다.\n",
      "d) 이미지에 노이즈를 추가한다.\n",
      "TEXT 파일 저장 완료: quiz_list_2.txt\n",
      "Feedback:\n",
      "content='- 정답 여부: 예\\n- 추가 설명: transforms.Normalize는 이미지의 픽셀 값을 정규화하는 역할을 합니다. 이는 각 채널의 픽셀 값에서 평균을 빼고 표준 편차로 나누어, 데이터의 분포를 평균 0, 분산 1로 맞추는 과정입니다. 이렇게 하면 모델이 학습하는 동안 수렴 속도가 빨라지고 성능도 개선될 수 있습니다. 정규화는 특히 신경망이 다양한 크기의 데이터셋에서 일관되게 작동하도록 돕습니다.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 122, 'prompt_tokens': 166, 'total_tokens': 288, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'stop', 'logprobs': None} id='run-86438b35-a66c-4bdb-8e93-ada190cc1e4c-0' usage_metadata={'input_tokens': 166, 'output_tokens': 122, 'total_tokens': 288, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "Top 10 chunks:\n",
      "('\\n'\n",
      " 'Chunk 1:\\n'\n",
      " '이제 PyTorch를 사용하여 간단한 CNN 모델을 구축하고, CIFAR-10 데이터셋을 사용하여 이미지 분류를 수행해보겠습니다1)  '\n",
      " '간단한 CNN 모델을 이용한 이미지 분류 실습☑️ PyTorch 및 필요한 라이브러리 임포트PyTorch 및 필요한 라이브러리 임포트 '\n",
      " '{5px}PyTorch 및 필요한 라이브러리 임포트 \\ufeff\\u200bPythonCopyimport')\n",
      "'\\nChunk 2:\\n\\ufeff\\u200bPythonCopyimport torch'\n",
      "('\\n'\n",
      " 'Chunk 3:\\n'\n",
      " 'import torch.nn as nn\\n'\n",
      " 'import torch.optim as optim\\n'\n",
      " 'import torchvision\\n'\n",
      " 'import torchvision.transforms as transforms\\n'\n",
      " '\\u200b☑️데이터셋 로드 및 전처리데이터셋 로드 및 전처리 {5px}데이터셋 로드 및 전처리 '\n",
      " '\\ufeff\\u200bPythonCopy# 데이터셋 전처리')\n",
      "('\\n'\n",
      " 'Chunk 4:\\n'\n",
      " 'transform = transforms.Compose([\\n'\n",
      " '    transforms.ToTensor(),\\n'\n",
      " '    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\\n'\n",
      " '])\\n'\n",
      " '# CIFAR-10 데이터셋 로드')\n",
      "('\\n'\n",
      " 'Chunk 5:\\n'\n",
      " '# CIFAR-10 데이터셋 로드\\n'\n",
      " \"trainset = torchvision.datasets.CIFAR10(root='./data', train=True, \"\n",
      " 'download=True, transform=transform)')\n",
      "('\\n'\n",
      " 'Chunk 6:\\n'\n",
      " 'trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, '\n",
      " 'shuffle=True)')\n",
      "('\\n'\n",
      " 'Chunk 7:\\n'\n",
      " \"testset = torchvision.datasets.CIFAR10(root='./data', train=False, \"\n",
      " 'download=True, transform=transform)\\n'\n",
      " 'testloader = torch.utils.data.DataLoader(testset, batch_size=64, '\n",
      " 'shuffle=False)')\n",
      "('\\n'\n",
      " 'Chunk 8:\\n'\n",
      " '\\u200b☑️ 간단한 CNN 모델 정의간단한 CNN 모델 정의 {5px}간단한 CNN 모델 정의 '\n",
      " '\\ufeff\\u200bPythonCopyclass SimpleCNN(nn.Module):\\n'\n",
      " 'def __init__(self):\\n'\n",
      " 'super(SimpleCNN, self).__init__()')\n",
      "('\\n'\n",
      " 'Chunk 9:\\n'\n",
      " 'self.conv1 = nn.Conv2d(3, 32, 3, padding=1) # 입력 채널 3, 출력 채널 32, 커널 크기 3x3\\n'\n",
      " '        self.pool = nn.MaxPool2d(2, 2) # 풀링 크기 2x2')\n",
      "('\\n'\n",
      " 'Chunk 10:\\n'\n",
      " 'self.conv2 = nn.Conv2d(32, 64, 3, padding=1) # 입력 채널 32, 출력 채널 64, 커널 크기 '\n",
      " '3x3\\n'\n",
      " '        self.fc1 = nn.Linear(64 * 8 * 8, 512) # 완전 연결 층\\n'\n",
      " '        self.fc2 = nn.Linear(512, 10) # 출력 층 (10개의 클래스)')\n",
      "Debug Output: 퀴즈 하나를 생성해줘\n",
      "Debug Output: {'context': [Document(metadata={}, page_content='\\u200b☑️ 간단한 CNN 모델 정의간단한 CNN 모델 정의 {5px}간단한 CNN 모델 정의 \\ufeff\\u200bPythonCopyclass SimpleCNN(nn.Module):\\ndef __init__(self):\\nsuper(SimpleCNN, self).__init__()'), Document(metadata={}, page_content='self.conv2 = nn.Conv2d(32, 64, 3, padding=1) # 입력 채널 32, 출력 채널 64, 커널 크기 3x3\\n        self.fc1 = nn.Linear(64 * 8 * 8, 512) # 완전 연결 층\\n        self.fc2 = nn.Linear(512, 10) # 출력 층 (10개의 클래스)'), Document(metadata={}, page_content='이제 PyTorch를 사용하여 간단한 CNN 모델을 구축하고, CIFAR-10 데이터셋을 사용하여 이미지 분류를 수행해보겠습니다1)  간단한 CNN 모델을 이용한 이미지 분류 실습☑️ PyTorch 및 필요한 라이브러리 임포트PyTorch 및 필요한 라이브러리 임포트 {5px}PyTorch 및 필요한 라이브러리 임포트 \\ufeff\\u200bPythonCopyimport'), Document(metadata={}, page_content='self.conv1 = nn.Conv2d(3, 32, 3, padding=1) # 입력 채널 3, 출력 채널 32, 커널 크기 3x3\\n        self.pool = nn.MaxPool2d(2, 2) # 풀링 크기 2x2'), Document(metadata={}, page_content=\"# CIFAR-10 데이터셋 로드\\ntrainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\"), Document(metadata={}, page_content=\"testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\\ntestloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)\"), Document(metadata={}, page_content='import torch.nn as nn\\nimport torch.optim as optim\\nimport torchvision\\nimport torchvision.transforms as transforms\\n\\u200b☑️데이터셋 로드 및 전처리데이터셋 로드 및 전처리 {5px}데이터셋 로드 및 전처리 \\ufeff\\u200bPythonCopy# 데이터셋 전처리')], 'quiz_list': '퀴즈 하나를 생성해줘'}\n",
      "Context output: ​☑️ 간단한 CNN 모델 정의간단한 CNN 모델 정의 {5px}간단한 CNN 모델 정의 ﻿​PythonCopyclass SimpleCNN(nn.Module):\n",
      "def __init__(self):\n",
      "super(SimpleCNN, self).__init__() self.conv2 = nn.Conv2d(32, 64, 3, padding=1) # 입력 채널 32, 출력 채널 64, 커널 크기 3x3\n",
      "        self.fc1 = nn.Linear(64 * 8 * 8, 512) # 완전 연결 층\n",
      "        self.fc2 = nn.Linear(512, 10) # 출력 층 (10개의 클래스) 이제 PyTorch를 사용하여 간단한 CNN 모델을 구축하고, CIFAR-10 데이터셋을 사용하여 이미지 분류를 수행해보겠습니다1)  간단한 CNN 모델을 이용한 이미지 분류 실습☑️ PyTorch 및 필요한 라이브러리 임포트PyTorch 및 필요한 라이브러리 임포트 {5px}PyTorch 및 필요한 라이브러리 임포트 ﻿​PythonCopyimport self.conv1 = nn.Conv2d(3, 32, 3, padding=1) # 입력 채널 3, 출력 채널 32, 커널 크기 3x3\n",
      "        self.pool = nn.MaxPool2d(2, 2) # 풀링 크기 2x2 # CIFAR-10 데이터셋 로드\n",
      "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform) testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
      "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False) import torch.nn as nn\n",
      "import torch.optim as optim\n",
      "import torchvision\n",
      "import torchvision.transforms as transforms\n",
      "​☑️데이터셋 로드 및 전처리데이터셋 로드 및 전처리 {5px}데이터셋 로드 및 전처리 ﻿​PythonCopy# 데이터셋 전처리\n",
      "quiz_list의 크기:  3\n",
      "Quiz : 아래 중 간단한 CNN 모델에서 CIFAR-10 데이터셋을 로드하기 위해 사용하는 PyTorch 모듈은 무엇인가요?\n",
      "\n",
      "a) torch.nn\n",
      "b) torch.optim\n",
      "c) torchvision.datasets\n",
      "d) torch.utils.data.transforms\n",
      "TEXT 파일 저장 완료: quiz_list_3.txt\n",
      "Feedback:\n",
      "content='- 정답 여부: 예\\n- 추가 설명: `torchvision.datasets`은 PyTorch에서 다양한 유명한 데이터셋을 쉽게 로드할 수 있도록 제공하는 모듈입니다. CIFAR-10 데이터셋 또한 `torchvision.datasets`을 통해 쉽게 불러올 수 있습니다. 다른 옵션들인 `torch.nn`은 신경망 모델을 구축하기 위한 모듈, `torch.optim`은 최적화 알고리즘을 제공하는 모듈, `torch.utils.data.transforms`는 데이터 변환을 위한 모듈로, CIFAR-10 데이터셋 로드와 직접적인 관련은 없습니다.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 134, 'prompt_tokens': 149, 'total_tokens': 283, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'stop', 'logprobs': None} id='run-0502e241-ad97-4422-8bf0-ce5888c5934a-0' usage_metadata={'input_tokens': 149, 'output_tokens': 134, 'total_tokens': 283, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "Top 10 chunks:\n",
      "('\\n'\n",
      " 'Chunk 1:\\n'\n",
      " 'trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, '\n",
      " 'shuffle=True)')\n",
      "('\\n'\n",
      " 'Chunk 2:\\n'\n",
      " \"testset = torchvision.datasets.CIFAR10(root='./data', train=False, \"\n",
      " 'download=True, transform=transform)\\n'\n",
      " 'testloader = torch.utils.data.DataLoader(testset, batch_size=64, '\n",
      " 'shuffle=False)')\n",
      "('\\n'\n",
      " 'Chunk 3:\\n'\n",
      " '\\u200b☑️ 간단한 CNN 모델 정의간단한 CNN 모델 정의 {5px}간단한 CNN 모델 정의 '\n",
      " '\\ufeff\\u200bPythonCopyclass SimpleCNN(nn.Module):\\n'\n",
      " 'def __init__(self):\\n'\n",
      " 'super(SimpleCNN, self).__init__()')\n",
      "('\\n'\n",
      " 'Chunk 4:\\n'\n",
      " 'self.conv1 = nn.Conv2d(3, 32, 3, padding=1) # 입력 채널 3, 출력 채널 32, 커널 크기 3x3\\n'\n",
      " '        self.pool = nn.MaxPool2d(2, 2) # 풀링 크기 2x2')\n",
      "('\\n'\n",
      " 'Chunk 5:\\n'\n",
      " 'self.conv2 = nn.Conv2d(32, 64, 3, padding=1) # 입력 채널 32, 출력 채널 64, 커널 크기 '\n",
      " '3x3\\n'\n",
      " '        self.fc1 = nn.Linear(64 * 8 * 8, 512) # 완전 연결 층\\n'\n",
      " '        self.fc2 = nn.Linear(512, 10) # 출력 층 (10개의 클래스)')\n",
      "('\\n'\n",
      " 'Chunk 6:\\n'\n",
      " 'def forward(self, x):\\n'\n",
      " '        x = self.pool(torch.relu(self.conv1(x)))\\n'\n",
      " '        x = self.pool(torch.relu(self.conv2(x)))\\n'\n",
      " '        x = x.view(-1, 64 * 8 * 8) # 플래튼\\n'\n",
      " '        x = torch.relu(self.fc1(x))')\n",
      "'\\nChunk 7:\\nx = self.fc2(x)\\nreturn x'\n",
      "('\\n'\n",
      " 'Chunk 8:\\n'\n",
      " '\\u200bnn.Conv2d: 2차원 합성곱 층을 정의합니다. nn.Conv2d(in_channels, out_channels, '\n",
      " 'kernel_size, padding)은 입력 채널 수, 출력 채널 수, 커널 크기, 패딩을 지정.Conv2d(in_channels, '\n",
      " 'out_channels, kernel_size, padding)은 입력 채널 수, 출력 채널 수, 커널')\n",
      "('\\n'\n",
      " 'Chunk 9:\\n'\n",
      " '채널 수, 출력 채널 수, 커널 크기, 패딩을 지정\\ufeff\\u200bnn.MaxPool2d: 2차원 최대 풀링 층을 '\n",
      " '정의합니다.nn.MaxPool2d(kernel_size, stride)은 풀링 크기와 스트라이드를 '\n",
      " '지정합니다..MaxPool2d(kernel_size, stride)은 풀링 크기와 스트라이드를 지정합니다.\\ufeff\\u200bview: '\n",
      " '텐서의 크기를')\n",
      "('\\n'\n",
      " 'Chunk 10:\\n'\n",
      " '텐서의 크기를 변경합니다.x.view(-1, 64 * 8 * 8)은 특징 맵을 1차원 벡터로 변환합니다..view(-1, 64 * 8 * '\n",
      " '8)은 특징 맵을 1차원 벡터로 변환합니다.\\ufeff\\u200b☑️ 모델 학습모델 학습 {5px}모델 학습 '\n",
      " '\\ufeff\\u200bPythonCopy# 모델 초기화')\n",
      "Debug Output: 퀴즈 하나를 생성해줘\n",
      "Debug Output: {'context': [Document(metadata={}, page_content='텐서의 크기를 변경합니다.x.view(-1, 64 * 8 * 8)은 특징 맵을 1차원 벡터로 변환합니다..view(-1, 64 * 8 * 8)은 특징 맵을 1차원 벡터로 변환합니다.\\ufeff\\u200b☑️ 모델 학습모델 학습 {5px}모델 학습 \\ufeff\\u200bPythonCopy# 모델 초기화'), Document(metadata={}, page_content='채널 수, 출력 채널 수, 커널 크기, 패딩을 지정\\ufeff\\u200bnn.MaxPool2d: 2차원 최대 풀링 층을 정의합니다.nn.MaxPool2d(kernel_size, stride)은 풀링 크기와 스트라이드를 지정합니다..MaxPool2d(kernel_size, stride)은 풀링 크기와 스트라이드를 지정합니다.\\ufeff\\u200bview: 텐서의 크기를'), Document(metadata={}, page_content='\\u200bnn.Conv2d: 2차원 합성곱 층을 정의합니다. nn.Conv2d(in_channels, out_channels, kernel_size, padding)은 입력 채널 수, 출력 채널 수, 커널 크기, 패딩을 지정.Conv2d(in_channels, out_channels, kernel_size, padding)은 입력 채널 수, 출력 채널 수, 커널'), Document(metadata={}, page_content='\\u200b☑️ 간단한 CNN 모델 정의간단한 CNN 모델 정의 {5px}간단한 CNN 모델 정의 \\ufeff\\u200bPythonCopyclass SimpleCNN(nn.Module):\\ndef __init__(self):\\nsuper(SimpleCNN, self).__init__()'), Document(metadata={}, page_content='x = self.fc2(x)\\nreturn x')], 'quiz_list': '퀴즈 하나를 생성해줘'}\n",
      "Context output: 텐서의 크기를 변경합니다.x.view(-1, 64 * 8 * 8)은 특징 맵을 1차원 벡터로 변환합니다..view(-1, 64 * 8 * 8)은 특징 맵을 1차원 벡터로 변환합니다.﻿​☑️ 모델 학습모델 학습 {5px}모델 학습 ﻿​PythonCopy# 모델 초기화 채널 수, 출력 채널 수, 커널 크기, 패딩을 지정﻿​nn.MaxPool2d: 2차원 최대 풀링 층을 정의합니다.nn.MaxPool2d(kernel_size, stride)은 풀링 크기와 스트라이드를 지정합니다..MaxPool2d(kernel_size, stride)은 풀링 크기와 스트라이드를 지정합니다.﻿​view: 텐서의 크기를 ​nn.Conv2d: 2차원 합성곱 층을 정의합니다. nn.Conv2d(in_channels, out_channels, kernel_size, padding)은 입력 채널 수, 출력 채널 수, 커널 크기, 패딩을 지정.Conv2d(in_channels, out_channels, kernel_size, padding)은 입력 채널 수, 출력 채널 수, 커널 ​☑️ 간단한 CNN 모델 정의간단한 CNN 모델 정의 {5px}간단한 CNN 모델 정의 ﻿​PythonCopyclass SimpleCNN(nn.Module):\n",
      "def __init__(self):\n",
      "super(SimpleCNN, self).__init__() x = self.fc2(x)\n",
      "return x\n",
      "quiz_list의 크기:  4\n",
      "Quiz : 다음 중 nn.Conv2d 함수가 정의하는 것이 아닌 것은 무엇인가요?\n",
      "\n",
      "a) 입력 채널 수\n",
      "\n",
      "b) 출력 채널 수\n",
      "\n",
      "c) 풀링 크기\n",
      "\n",
      "d) 커널 크기\n",
      "TEXT 파일 저장 완료: quiz_list_4.txt\n",
      "Feedback:\n",
      "content='- 정답 여부: \"아니오\"\\n- 추가 설명: nn.Conv2d 함수는 입력 채널 수, 출력 채널 수, 커널 크기 등을 정의하지만 풀링 크기는 정의하지 않습니다. 풀링 크기는 풀링 레이어, 예를 들어 nn.MaxPool2d 또는 nn.AvgPool2d에서 정의됩니다. 따라서, nn.Conv2d 함수가 정의하지 않는 것은 \"c) 풀링 크기\"입니다.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 95, 'prompt_tokens': 141, 'total_tokens': 236, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_7f6be3efb0', 'finish_reason': 'stop', 'logprobs': None} id='run-d49ee211-a208-4aa4-91f1-c3291a325594-0' usage_metadata={'input_tokens': 141, 'output_tokens': 95, 'total_tokens': 236, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "Top 10 chunks:\n",
      "('\\n'\n",
      " 'Chunk 1:\\n'\n",
      " 'def forward(self, x):\\n'\n",
      " '        x = self.pool(torch.relu(self.conv1(x)))\\n'\n",
      " '        x = self.pool(torch.relu(self.conv2(x)))\\n'\n",
      " '        x = x.view(-1, 64 * 8 * 8) # 플래튼\\n'\n",
      " '        x = torch.relu(self.fc1(x))')\n",
      "'\\nChunk 2:\\nx = self.fc2(x)\\nreturn x'\n",
      "('\\n'\n",
      " 'Chunk 3:\\n'\n",
      " '\\u200bnn.Conv2d: 2차원 합성곱 층을 정의합니다. nn.Conv2d(in_channels, out_channels, '\n",
      " 'kernel_size, padding)은 입력 채널 수, 출력 채널 수, 커널 크기, 패딩을 지정.Conv2d(in_channels, '\n",
      " 'out_channels, kernel_size, padding)은 입력 채널 수, 출력 채널 수, 커널')\n",
      "('\\n'\n",
      " 'Chunk 4:\\n'\n",
      " '채널 수, 출력 채널 수, 커널 크기, 패딩을 지정\\ufeff\\u200bnn.MaxPool2d: 2차원 최대 풀링 층을 '\n",
      " '정의합니다.nn.MaxPool2d(kernel_size, stride)은 풀링 크기와 스트라이드를 '\n",
      " '지정합니다..MaxPool2d(kernel_size, stride)은 풀링 크기와 스트라이드를 지정합니다.\\ufeff\\u200bview: '\n",
      " '텐서의 크기를')\n",
      "('\\n'\n",
      " 'Chunk 5:\\n'\n",
      " '텐서의 크기를 변경합니다.x.view(-1, 64 * 8 * 8)은 특징 맵을 1차원 벡터로 변환합니다..view(-1, 64 * 8 * '\n",
      " '8)은 특징 맵을 1차원 벡터로 변환합니다.\\ufeff\\u200b☑️ 모델 학습모델 학습 {5px}모델 학습 '\n",
      " '\\ufeff\\u200bPythonCopy# 모델 초기화')\n",
      "('\\n'\n",
      " 'Chunk 6:\\n'\n",
      " 'model = SimpleCNN()\\n'\n",
      " '# 손실 함수와 최적화 알고리즘 정의\\n'\n",
      " 'criterion = nn.CrossEntropyLoss()\\n'\n",
      " 'optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\\n'\n",
      " '# 모델 학습\\n'\n",
      " 'for epoch in range(10): # 10 에포크 동안 학습')\n",
      "('\\n'\n",
      " 'Chunk 7:\\n'\n",
      " 'running_loss = 0.0\\n'\n",
      " 'for i, data in enumerate(trainloader, 0):\\n'\n",
      " '        inputs, labels = data')\n",
      "('\\n'\n",
      " 'Chunk 8:\\n'\n",
      " '# 기울기 초기화\\n'\n",
      " '        optimizer.zero_grad()\\n'\n",
      " '# 순전파 + 역전파 + 최적화\\n'\n",
      " '        outputs = model(inputs)\\n'\n",
      " '        loss = criterion(outputs, labels)\\n'\n",
      " '        loss.backward()\\n'\n",
      " '        optimizer.step()\\n'\n",
      " '# 손실 출력')\n",
      "('\\n'\n",
      " 'Chunk 9:\\n'\n",
      " '# 손실 출력\\n'\n",
      " '        running_loss += loss.item()\\n'\n",
      " 'if i % 100 == 99: # 매 100 미니배치마다 출력\\n'\n",
      " \"print(f'[Epoch {epoch + 1}, Batch {i + 1}] loss: {running_loss / 100:.3f}')\\n\"\n",
      " '            running_loss = 0.0')\n",
      "\"\\nChunk 10:\\nprint('Finished Training')\"\n",
      "Debug Output: 퀴즈 하나를 생성해줘\n",
      "Debug Output: {'context': [Document(metadata={}, page_content=\"print('Finished Training')\"), Document(metadata={}, page_content='텐서의 크기를 변경합니다.x.view(-1, 64 * 8 * 8)은 특징 맵을 1차원 벡터로 변환합니다..view(-1, 64 * 8 * 8)은 특징 맵을 1차원 벡터로 변환합니다.\\ufeff\\u200b☑️ 모델 학습모델 학습 {5px}모델 학습 \\ufeff\\u200bPythonCopy# 모델 초기화'), Document(metadata={}, page_content=\"# 손실 출력\\n        running_loss += loss.item()\\nif i % 100 == 99: # 매 100 미니배치마다 출력\\nprint(f'[Epoch {epoch + 1}, Batch {i + 1}] loss: {running_loss / 100:.3f}')\\n            running_loss = 0.0\"), Document(metadata={}, page_content='채널 수, 출력 채널 수, 커널 크기, 패딩을 지정\\ufeff\\u200bnn.MaxPool2d: 2차원 최대 풀링 층을 정의합니다.nn.MaxPool2d(kernel_size, stride)은 풀링 크기와 스트라이드를 지정합니다..MaxPool2d(kernel_size, stride)은 풀링 크기와 스트라이드를 지정합니다.\\ufeff\\u200bview: 텐서의 크기를'), Document(metadata={}, page_content='# 기울기 초기화\\n        optimizer.zero_grad()\\n# 순전파 + 역전파 + 최적화\\n        outputs = model(inputs)\\n        loss = criterion(outputs, labels)\\n        loss.backward()\\n        optimizer.step()\\n# 손실 출력'), Document(metadata={}, page_content='model = SimpleCNN()\\n# 손실 함수와 최적화 알고리즘 정의\\ncriterion = nn.CrossEntropyLoss()\\noptimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\\n# 모델 학습\\nfor epoch in range(10): # 10 에포크 동안 학습'), Document(metadata={}, page_content='running_loss = 0.0\\nfor i, data in enumerate(trainloader, 0):\\n        inputs, labels = data'), Document(metadata={}, page_content='\\u200bnn.Conv2d: 2차원 합성곱 층을 정의합니다. nn.Conv2d(in_channels, out_channels, kernel_size, padding)은 입력 채널 수, 출력 채널 수, 커널 크기, 패딩을 지정.Conv2d(in_channels, out_channels, kernel_size, padding)은 입력 채널 수, 출력 채널 수, 커널')], 'quiz_list': '퀴즈 하나를 생성해줘'}\n",
      "Context output: print('Finished Training') 텐서의 크기를 변경합니다.x.view(-1, 64 * 8 * 8)은 특징 맵을 1차원 벡터로 변환합니다..view(-1, 64 * 8 * 8)은 특징 맵을 1차원 벡터로 변환합니다.﻿​☑️ 모델 학습모델 학습 {5px}모델 학습 ﻿​PythonCopy# 모델 초기화 # 손실 출력\n",
      "        running_loss += loss.item()\n",
      "if i % 100 == 99: # 매 100 미니배치마다 출력\n",
      "print(f'[Epoch {epoch + 1}, Batch {i + 1}] loss: {running_loss / 100:.3f}')\n",
      "            running_loss = 0.0 채널 수, 출력 채널 수, 커널 크기, 패딩을 지정﻿​nn.MaxPool2d: 2차원 최대 풀링 층을 정의합니다.nn.MaxPool2d(kernel_size, stride)은 풀링 크기와 스트라이드를 지정합니다..MaxPool2d(kernel_size, stride)은 풀링 크기와 스트라이드를 지정합니다.﻿​view: 텐서의 크기를 # 기울기 초기화\n",
      "        optimizer.zero_grad()\n",
      "# 순전파 + 역전파 + 최적화\n",
      "        outputs = model(inputs)\n",
      "        loss = criterion(outputs, labels)\n",
      "        loss.backward()\n",
      "        optimizer.step()\n",
      "# 손실 출력 model = SimpleCNN()\n",
      "# 손실 함수와 최적화 알고리즘 정의\n",
      "criterion = nn.CrossEntropyLoss()\n",
      "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
      "# 모델 학습\n",
      "for epoch in range(10): # 10 에포크 동안 학습 running_loss = 0.0\n",
      "for i, data in enumerate(trainloader, 0):\n",
      "        inputs, labels = data ​nn.Conv2d: 2차원 합성곱 층을 정의합니다. nn.Conv2d(in_channels, out_channels, kernel_size, padding)은 입력 채널 수, 출력 채널 수, 커널 크기, 패딩을 지정.Conv2d(in_channels, out_channels, kernel_size, padding)은 입력 채널 수, 출력 채널 수, 커널\n",
      "quiz_list의 크기:  5\n",
      "Quiz : nn.MaxPool2d의 kernel_size와 stride를 지정할 때, 이 층의 주요 기능은 무엇인가요?\n",
      "\n",
      "a) 입력 이미지의 크기를 늘려주는 것  \n",
      "b) 채널 수를 증가시키는 것  \n",
      "c) 특징 맵의 공간적 차원을 줄이는 것  \n",
      "d) 기울기를 초기화하는 것  \n",
      "TEXT 파일 저장 완료: quiz_list_5.txt\n",
      "Feedback:\n",
      "content='- 정답 여부: \"아니오\"\\n- 추가 설명: nn.MaxPool2d의 주요 기능은 주어진 커널 크기와 스트라이드를 사용하여 입력 이미지의 공간적 차원을 줄이는 것입니다. 이는 주로 특징 맵을 간소화하고, 계산 비용을 줄이며, 과적합을 방지하기 위해 사용됩니다. 따라서 정답은 c) 특징 맵의 공간적 차원을 줄이는 것입니다.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 93, 'prompt_tokens': 169, 'total_tokens': 262, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'stop', 'logprobs': None} id='run-6ee08f62-ad7b-45a4-9d21-375a5144265c-0' usage_metadata={'input_tokens': 169, 'output_tokens': 93, 'total_tokens': 262, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "Top 10 chunks:\n",
      "('\\n'\n",
      " 'Chunk 1:\\n'\n",
      " 'model = SimpleCNN()\\n'\n",
      " '# 손실 함수와 최적화 알고리즘 정의\\n'\n",
      " 'criterion = nn.CrossEntropyLoss()\\n'\n",
      " 'optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\\n'\n",
      " '# 모델 학습\\n'\n",
      " 'for epoch in range(10): # 10 에포크 동안 학습')\n",
      "('\\n'\n",
      " 'Chunk 2:\\n'\n",
      " 'running_loss = 0.0\\n'\n",
      " 'for i, data in enumerate(trainloader, 0):\\n'\n",
      " '        inputs, labels = data')\n",
      "('\\n'\n",
      " 'Chunk 3:\\n'\n",
      " '# 기울기 초기화\\n'\n",
      " '        optimizer.zero_grad()\\n'\n",
      " '# 순전파 + 역전파 + 최적화\\n'\n",
      " '        outputs = model(inputs)\\n'\n",
      " '        loss = criterion(outputs, labels)\\n'\n",
      " '        loss.backward()\\n'\n",
      " '        optimizer.step()\\n'\n",
      " '# 손실 출력')\n",
      "('\\n'\n",
      " 'Chunk 4:\\n'\n",
      " '# 손실 출력\\n'\n",
      " '        running_loss += loss.item()\\n'\n",
      " 'if i % 100 == 99: # 매 100 미니배치마다 출력\\n'\n",
      " \"print(f'[Epoch {epoch + 1}, Batch {i + 1}] loss: {running_loss / 100:.3f}')\\n\"\n",
      " '            running_loss = 0.0')\n",
      "\"\\nChunk 5:\\nprint('Finished Training')\"\n",
      "('\\n'\n",
      " 'Chunk 6:\\n'\n",
      " '\\u200bnn.CrossEntropyLoss: 다중 클래스 분류 문제에서 주로 사용되는 손실 함수입니다. 예측 값과 실제 값 사이의 '\n",
      " '교차 엔트로피 손실을 계산합니다.optim.SGD: 확률적 경사 하강법(Stochastic Gradient Descent) 최적화 '\n",
      " '알고리즘을 정의합니다.  lr은 학습률, momentum은 모멘텀 값을 지정합니다.은 학습률,')\n",
      "('\\n'\n",
      " 'Chunk 7:\\n'\n",
      " '모멘텀 값을 지정합니다.은 학습률, momentum은 모멘텀 값을 '\n",
      " '지정합니다.\\ufeff\\u200boptimizer.zero_grad(): 이전 단계에서 계산된 기울기를 '\n",
      " '초기화합니다.loss.backward(): 역전파를 통해 기울기를 계산합니다.optimizer.step(): 계산된 기울기를 바탕으로 '\n",
      " '가중치를 업데이트합니다.☑️ 모델  평가모델 평가 {5px}모델 평가')\n",
      "'\\nChunk 8:\\n평가모델 평가 {5px}모델 평가 \\ufeff\\u200bPythonCopycorrect = 0'\n",
      "('\\n'\n",
      " 'Chunk 9:\\n'\n",
      " 'total = 0\\n'\n",
      " 'with torch.no_grad():\\n'\n",
      " 'for data in testloader:\\n'\n",
      " '        images, labels = data\\n'\n",
      " '        outputs = model(images)\\n'\n",
      " '        _, predicted = torch.max(outputs.data, 1)\\n'\n",
      " '        total += labels.size(0)')\n",
      "('\\n'\n",
      " 'Chunk 10:\\n'\n",
      " 'correct += (predicted == labels).sum().item()\\n'\n",
      " \"print(f'Accuracy of the network on the 10000 test images: {100 * correct / \"\n",
      " \"total:.2f}%')\")\n",
      "Debug Output: 퀴즈 하나를 생성해줘\n",
      "Debug Output: {'context': [Document(metadata={}, page_content='모멘텀 값을 지정합니다.은 학습률, momentum은 모멘텀 값을 지정합니다.\\ufeff\\u200boptimizer.zero_grad(): 이전 단계에서 계산된 기울기를 초기화합니다.loss.backward(): 역전파를 통해 기울기를 계산합니다.optimizer.step(): 계산된 기울기를 바탕으로 가중치를 업데이트합니다.☑️ 모델  평가모델 평가 {5px}모델 평가'), Document(metadata={}, page_content='평가모델 평가 {5px}모델 평가 \\ufeff\\u200bPythonCopycorrect = 0'), Document(metadata={}, page_content=\"correct += (predicted == labels).sum().item()\\nprint(f'Accuracy of the network on the 10000 test images: {100 * correct / total:.2f}%')\"), Document(metadata={}, page_content='total = 0\\nwith torch.no_grad():\\nfor data in testloader:\\n        images, labels = data\\n        outputs = model(images)\\n        _, predicted = torch.max(outputs.data, 1)\\n        total += labels.size(0)'), Document(metadata={}, page_content='\\u200bnn.CrossEntropyLoss: 다중 클래스 분류 문제에서 주로 사용되는 손실 함수입니다. 예측 값과 실제 값 사이의 교차 엔트로피 손실을 계산합니다.optim.SGD: 확률적 경사 하강법(Stochastic Gradient Descent) 최적화 알고리즘을 정의합니다.  lr은 학습률, momentum은 모멘텀 값을 지정합니다.은 학습률,'), Document(metadata={}, page_content='model = SimpleCNN()\\n# 손실 함수와 최적화 알고리즘 정의\\ncriterion = nn.CrossEntropyLoss()\\noptimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\\n# 모델 학습\\nfor epoch in range(10): # 10 에포크 동안 학습')], 'quiz_list': '퀴즈 하나를 생성해줘'}\n",
      "Context output: 모멘텀 값을 지정합니다.은 학습률, momentum은 모멘텀 값을 지정합니다.﻿​optimizer.zero_grad(): 이전 단계에서 계산된 기울기를 초기화합니다.loss.backward(): 역전파를 통해 기울기를 계산합니다.optimizer.step(): 계산된 기울기를 바탕으로 가중치를 업데이트합니다.☑️ 모델  평가모델 평가 {5px}모델 평가 평가모델 평가 {5px}모델 평가 ﻿​PythonCopycorrect = 0 correct += (predicted == labels).sum().item()\n",
      "print(f'Accuracy of the network on the 10000 test images: {100 * correct / total:.2f}%') total = 0\n",
      "with torch.no_grad():\n",
      "for data in testloader:\n",
      "        images, labels = data\n",
      "        outputs = model(images)\n",
      "        _, predicted = torch.max(outputs.data, 1)\n",
      "        total += labels.size(0) ​nn.CrossEntropyLoss: 다중 클래스 분류 문제에서 주로 사용되는 손실 함수입니다. 예측 값과 실제 값 사이의 교차 엔트로피 손실을 계산합니다.optim.SGD: 확률적 경사 하강법(Stochastic Gradient Descent) 최적화 알고리즘을 정의합니다.  lr은 학습률, momentum은 모멘텀 값을 지정합니다.은 학습률, model = SimpleCNN()\n",
      "# 손실 함수와 최적화 알고리즘 정의\n",
      "criterion = nn.CrossEntropyLoss()\n",
      "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
      "# 모델 학습\n",
      "for epoch in range(10): # 10 에포크 동안 학습\n",
      "quiz_list의 크기:  6\n",
      "Quiz : 다음 중 확률적 경사 하강법(Stochastic Gradient Descent) 알고리즘에서 사용되는 주요 매개변수는 무엇인가요?  \n",
      "A) 손실 함수와 가중치  \n",
      "B) 학습률과 모멘텀  \n",
      "C) 이미지와 레이블  \n",
      "D) 예측 값과 실제 값  \n",
      "TEXT 파일 저장 완료: quiz_list_6.txt\n",
      "Feedback:\n",
      "content='- 정답 여부: \"아니오\"\\n- 추가 설명: 확률적 경사 하강법(Stochastic Gradient Descent, SGD)에서 사용되는 주요 매개변수는 B) 학습률과 모멘텀입니다. 학습률은 모델이 가중치를 업데이트할 때 얼마나 크게 조정할지를 결정하는 매개변수이며, 모멘텀은 이전 업데이트의 방향을 고려하여 학습을 가속화하거나 안정화하는 데 사용됩니다. C) 이미지와 레이블은 데이터셋에 관한 것으로, SGD의 매개변수라고 할 수 없습니다.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 128, 'prompt_tokens': 166, 'total_tokens': 294, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'stop', 'logprobs': None} id='run-3cf2855c-76d8-481a-a403-082f37faecbe-0' usage_metadata={'input_tokens': 166, 'output_tokens': 128, 'total_tokens': 294, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "Top 10 chunks:\n",
      "('\\n'\n",
      " 'Chunk 1:\\n'\n",
      " '\\u200bnn.CrossEntropyLoss: 다중 클래스 분류 문제에서 주로 사용되는 손실 함수입니다. 예측 값과 실제 값 사이의 '\n",
      " '교차 엔트로피 손실을 계산합니다.optim.SGD: 확률적 경사 하강법(Stochastic Gradient Descent) 최적화 '\n",
      " '알고리즘을 정의합니다.  lr은 학습률, momentum은 모멘텀 값을 지정합니다.은 학습률,')\n",
      "('\\n'\n",
      " 'Chunk 2:\\n'\n",
      " '모멘텀 값을 지정합니다.은 학습률, momentum은 모멘텀 값을 '\n",
      " '지정합니다.\\ufeff\\u200boptimizer.zero_grad(): 이전 단계에서 계산된 기울기를 '\n",
      " '초기화합니다.loss.backward(): 역전파를 통해 기울기를 계산합니다.optimizer.step(): 계산된 기울기를 바탕으로 '\n",
      " '가중치를 업데이트합니다.☑️ 모델  평가모델 평가 {5px}모델 평가')\n",
      "'\\nChunk 3:\\n평가모델 평가 {5px}모델 평가 \\ufeff\\u200bPythonCopycorrect = 0'\n",
      "('\\n'\n",
      " 'Chunk 4:\\n'\n",
      " 'total = 0\\n'\n",
      " 'with torch.no_grad():\\n'\n",
      " 'for data in testloader:\\n'\n",
      " '        images, labels = data\\n'\n",
      " '        outputs = model(images)\\n'\n",
      " '        _, predicted = torch.max(outputs.data, 1)\\n'\n",
      " '        total += labels.size(0)')\n",
      "('\\n'\n",
      " 'Chunk 5:\\n'\n",
      " 'correct += (predicted == labels).sum().item()\\n'\n",
      " \"print(f'Accuracy of the network on the 10000 test images: {100 * correct / \"\n",
      " \"total:.2f}%')\")\n",
      "('\\n'\n",
      " 'Chunk 6:\\n'\n",
      " '\\u200btorch.no_grad(): 평가 단계에서는 기울기를 계산할 필요가 없으므로, 이를 비활성화하여 메모리 사용을 '\n",
      " '줄입니다.torch.max: 텐서의 최대 값을 찾습니다. torch.max(outputs.data, 1)은 각 샘플에 대해 가장 높은 '\n",
      " '확률을 가진 클래스를 반환합니다..max(outputs.data, 1)은 각 샘플에 대해 가장 높은 확률을')\n",
      "('\\n'\n",
      " 'Chunk 7:\\n'\n",
      " '각 샘플에 대해 가장 높은 확률을 가진 클래스를 반환합니다.\\ufeff\\u200blabels.size(0): 배치 크기를 '\n",
      " '반환합니다.(predicted == labels).sum().item(): 예측 값과 실제 값이 일치하는 샘플의 수를 '\n",
      " '계산합니다.Copyright ⓒ TeamSparta All rights reserved.')\n",
      "('\\n'\n",
      " 'Chunk 8:\\n'\n",
      " '[스파르타코딩클럽] 5. 합성곱 신경망(CNN)📘[SCC] 기초가 탄탄한 딥러닝/📚[스파르타코딩클럽] 기초가 탄탄한 딥러닝 - '\n",
      " '2주차/📕[스파르타코딩클럽] 5. 합성곱 신경망(CNN)Made with📕[스파르타코딩클럽] 5. 합성곱 신경망(CNN)[수업 '\n",
      " '목표]합성곱 신경망의 개념에 대해서 배워보고 어떤 원리로 동작하는지 알아봅시다Pytorch로 간단한')\n",
      "('\\n'\n",
      " 'Chunk 9:\\n'\n",
      " '알아봅시다Pytorch로 간단한 CNN 모델 구현 실습을 진행해 봅시다[목차]01. CNN의 기본 구조와 동작 원리02. 실습: CNN을 '\n",
      " '이용한 이미지 분류 (PyTorch) - 입력 이미지에 필터(커널)를 적용하여 특징 맵(feature map)을 생성합니다. - 입력 '\n",
      " '이미지에 필터(커널)를 적용하여 특징 맵(feature map)을 생성합니다.\\ufeff')\n",
      "('\\n'\n",
      " 'Chunk 10:\\n'\n",
      " '- 필터는 이미지의 국소적인 패턴을 학습합니다. - 필터는 이미지의 국소적인 패턴을 학습합니다.\\ufeff\\n'\n",
      " '풀링 층 (Pooling Layer)\\n'\n",
      " ' - 특징 맵의 크기를 줄이고, 중요한 특징을 추출합니다. - 특징 맵의 크기를 줄이고, 중요한 특징을 추출합니다.\\ufeff')\n",
      "Debug Output: 퀴즈 하나를 생성해줘\n",
      "Debug Output: {'context': [Document(metadata={}, page_content='알아봅시다Pytorch로 간단한 CNN 모델 구현 실습을 진행해 봅시다[목차]01. CNN의 기본 구조와 동작 원리02. 실습: CNN을 이용한 이미지 분류 (PyTorch) - 입력 이미지에 필터(커널)를 적용하여 특징 맵(feature map)을 생성합니다. - 입력 이미지에 필터(커널)를 적용하여 특징 맵(feature map)을 생성합니다.\\ufeff'), Document(metadata={}, page_content='- 필터는 이미지의 국소적인 패턴을 학습합니다. - 필터는 이미지의 국소적인 패턴을 학습합니다.\\ufeff\\n풀링 층 (Pooling Layer)\\n - 특징 맵의 크기를 줄이고, 중요한 특징을 추출합니다. - 특징 맵의 크기를 줄이고, 중요한 특징을 추출합니다.\\ufeff'), Document(metadata={}, page_content='모멘텀 값을 지정합니다.은 학습률, momentum은 모멘텀 값을 지정합니다.\\ufeff\\u200boptimizer.zero_grad(): 이전 단계에서 계산된 기울기를 초기화합니다.loss.backward(): 역전파를 통해 기울기를 계산합니다.optimizer.step(): 계산된 기울기를 바탕으로 가중치를 업데이트합니다.☑️ 모델  평가모델 평가 {5px}모델 평가'), Document(metadata={}, page_content='[스파르타코딩클럽] 5. 합성곱 신경망(CNN)📘[SCC] 기초가 탄탄한 딥러닝/📚[스파르타코딩클럽] 기초가 탄탄한 딥러닝 - 2주차/📕[스파르타코딩클럽] 5. 합성곱 신경망(CNN)Made with📕[스파르타코딩클럽] 5. 합성곱 신경망(CNN)[수업 목표]합성곱 신경망의 개념에 대해서 배워보고 어떤 원리로 동작하는지 알아봅시다Pytorch로 간단한'), Document(metadata={}, page_content='각 샘플에 대해 가장 높은 확률을 가진 클래스를 반환합니다.\\ufeff\\u200blabels.size(0): 배치 크기를 반환합니다.(predicted == labels).sum().item(): 예측 값과 실제 값이 일치하는 샘플의 수를 계산합니다.Copyright ⓒ TeamSparta All rights reserved.'), Document(metadata={}, page_content='평가모델 평가 {5px}모델 평가 \\ufeff\\u200bPythonCopycorrect = 0')], 'quiz_list': '퀴즈 하나를 생성해줘'}\n",
      "Context output: 알아봅시다Pytorch로 간단한 CNN 모델 구현 실습을 진행해 봅시다[목차]01. CNN의 기본 구조와 동작 원리02. 실습: CNN을 이용한 이미지 분류 (PyTorch) - 입력 이미지에 필터(커널)를 적용하여 특징 맵(feature map)을 생성합니다. - 입력 이미지에 필터(커널)를 적용하여 특징 맵(feature map)을 생성합니다.﻿ - 필터는 이미지의 국소적인 패턴을 학습합니다. - 필터는 이미지의 국소적인 패턴을 학습합니다.﻿\n",
      "풀링 층 (Pooling Layer)\n",
      " - 특징 맵의 크기를 줄이고, 중요한 특징을 추출합니다. - 특징 맵의 크기를 줄이고, 중요한 특징을 추출합니다.﻿ 모멘텀 값을 지정합니다.은 학습률, momentum은 모멘텀 값을 지정합니다.﻿​optimizer.zero_grad(): 이전 단계에서 계산된 기울기를 초기화합니다.loss.backward(): 역전파를 통해 기울기를 계산합니다.optimizer.step(): 계산된 기울기를 바탕으로 가중치를 업데이트합니다.☑️ 모델  평가모델 평가 {5px}모델 평가 [스파르타코딩클럽] 5. 합성곱 신경망(CNN)📘[SCC] 기초가 탄탄한 딥러닝/📚[스파르타코딩클럽] 기초가 탄탄한 딥러닝 - 2주차/📕[스파르타코딩클럽] 5. 합성곱 신경망(CNN)Made with📕[스파르타코딩클럽] 5. 합성곱 신경망(CNN)[수업 목표]합성곱 신경망의 개념에 대해서 배워보고 어떤 원리로 동작하는지 알아봅시다Pytorch로 간단한 각 샘플에 대해 가장 높은 확률을 가진 클래스를 반환합니다.﻿​labels.size(0): 배치 크기를 반환합니다.(predicted == labels).sum().item(): 예측 값과 실제 값이 일치하는 샘플의 수를 계산합니다.Copyright ⓒ TeamSparta All rights reserved. 평가모델 평가 {5px}모델 평가 ﻿​PythonCopycorrect = 0\n",
      "quiz_list의 크기:  6\n",
      "Quiz : 다음 중 CNN의 풀링 층(Pooling Layer)의 주요 역할로 올바른 것은 무엇인가요?\n",
      "\n",
      "a) 입력 이미지에 필터를 적용하여 특징 맵(feature map)을 생성한다.\n",
      "b) 학습률과 모멘텀 값을 지정하여 가중치를 업데이트한다.\n",
      "c) 특징 맵의 크기를 줄이고, 중요한 특징을 추출한다.\n",
      "d) 각 샘플에 대해 가장 높은 확률을 가진 클래스를 반환한다.\n",
      "TEXT 파일 저장 완료: quiz_list_7.txt\n",
      "대화를 종료합니다.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain.globals import set_llm_cache, get_llm_cache\n",
    "from langchain.cache import InMemoryCache\n",
    "\n",
    "type_ = input(\"선택하실 AI 교재 타입 (dl, ml, llm, python, open_source) 를 입력해주세요!\")\n",
    "order = int(input(\"선택하실 AI 교쟈 챕터를 입력해주세요! 종료를 원하신다면 0을 입력해주세요!\"))\n",
    "# query = input(\"어떤 내용을 질문하고 싶으신가요?\")\n",
    "# set_llm_cache(InMemoryCache()) # 캐시 메모리 설정\n",
    "# llm_cache = get_llm_cache()\n",
    "j = 0\n",
    "valid_type = [\"dl\", \"ml\", \"llm\", \"python\", \"open_source\"]\n",
    "quiz_list = []\n",
    "txt_list = choose_txt_list(type_)\n",
    "current_index = 0\n",
    "\n",
    "while True: \n",
    "\n",
    "    if (order == 0):\n",
    "        break\n",
    "\n",
    "    elif (type_ not in valid_type):\n",
    "        type_ = input(\"교재 타입을 반드시!(dl, ml, llm, python, open_source) 안에서 입력해주세요!\")\n",
    "        order = int(input(\"선택하실 딥러닝 챕터의 교재 번호를 입력해주세요! 종료를 원하신다면 0을 입력해주세요!\"))\n",
    "        continue\n",
    "\n",
    "    elif (type_ in valid_type):\n",
    "        break\n",
    "\n",
    "while True: \n",
    "        \n",
    "    quiz_list = quiz_list[-5:]  # 최신 5개 퀴즈만 보관\n",
    "    quiz_str = \" \".join(quiz_list)\n",
    "    # retriever = get_retriever(txt_list[order-1])\n",
    "    retriever = get_retriever(txt_list[order-1], current_index)\n",
    "    rag_chain = create_concept_rag_chain(retriever)\n",
    "\n",
    "\n",
    "    query = concept_prompt.format(\n",
    "        context=retriever,\n",
    "        quiz_list=quiz_list,       \n",
    "    )\n",
    "\n",
    "\n",
    "    try:\n",
    "        response = rag_chain.invoke(\"퀴즈 하나를 생성해줘\")\n",
    "    except Exception as e:\n",
    "        print(f\"Quiz 생성 중 오류 발생: {e}\")\n",
    "        continue\n",
    "    \n",
    "    if len(quiz_list) > 0 and is_similar(response, quiz_list, 0.7):\n",
    "        continue\n",
    "\n",
    "    quiz = response\n",
    "    quiz_list.append(quiz)\n",
    "    print(\"quiz_list의 크기: \", len(quiz_list))\n",
    "\n",
    "    print(f\"Quiz : {quiz}\")\n",
    "    j+=1\n",
    "    save_file(''.join(quiz), f\"quiz_list_{j}.txt\")\n",
    "    \n",
    "    \n",
    "    # 2. 사용자 답변 수집\n",
    "    user_answer = input(\"답변을 입력하세요 힌트를 원한다면 help를, 종료를 원하시면 exit을 입력해주세요.: \").strip()\n",
    "\n",
    "\n",
    "    if user_answer.strip().lower() == \"exit\":\n",
    "        print(\"대화를 종료합니다.\")\n",
    "        break\n",
    "\n",
    "    elif user_answer.strip().lower() == \"help\":\n",
    "        \n",
    "    \n",
    "    if not user_answer:\n",
    "        print(\"답변이 비어 있습니다. 다시 입력해주세요.\")\n",
    "        continue\n",
    "\n",
    "    # 3. 사용자 답변에 대한 피드백 생성\n",
    "    # 3. 사용자 답변에 대한 피드백 생성\n",
    "    feedback_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", f\"\"\"\n",
    "        AI 강사로서 다음 퀴즈의 정답 여부를 확인하고 피드백을 제공하세요.\n",
    "        피드백은 아래와 같은 형식이어야 합니다:\n",
    "        \n",
    "        - 정답 여부: \"N번\" 또는 \"예/아니오\"\n",
    "        - 추가 설명: (정답과 관련된 추가 정보를 제공하세요)\n",
    "        \n",
    "        퀴즈 : {{quiz}}\n",
    "        답변 : {{user_answer}}\n",
    "        \n",
    "        \"\"\")\n",
    "    ])\n",
    "\n",
    "    feedback_chain = feedback_prompt | llm\n",
    "    feedback = feedback_chain.invoke({\"quiz\": quiz, \"user_answer\": user_answer})\n",
    "    print(\"Feedback:\")\n",
    "    print(feedback)\n",
    "    current_index += 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.globals import set_llm_cache, get_llm_cache\n",
    "from langchain.cache import InMemoryCache\n",
    "\n",
    "type_ = input(\"선택하실 딥러닝 챕터의 교재 타입 (dl, ml, llm, python, open_source) 를 입력해주세요!\")\n",
    "order = int(input(\"선택하실 딥러닝 챕터의 교재 번호를 입력해주세요! 종료를 원하신다면 0을 입력해주세요!\"))\n",
    "# query = input(\"어떤 내용을 질문하고 싶으신가요?\")\n",
    "# set_llm_cache(InMemoryCache()) # 캐시 메모리 설정\n",
    "# llm_cache = get_llm_cache()\n",
    "j = 0\n",
    "valid_type = [\"dl\", \"ml\", \"llm\", \"python\", \"open_source\"]\n",
    "quiz_list = []\n",
    "txt_list = choose_txt_list(type_)\n",
    "current_index = 0\n",
    "\n",
    "while True: \n",
    "\n",
    "    if (order == 0):\n",
    "        break\n",
    "\n",
    "    elif (type_ not in valid_type):\n",
    "        type_ = input(\"교재 타입을 반드시!(dl, ml, llm, python, open_source) 안에서 입력해주세요!\")\n",
    "        order = int(input(\"선택하실 딥러닝 챕터의 교재 번호를 입력해주세요! 종료를 원하신다면 0을 입력해주세요!\"))\n",
    "        continue\n",
    "\n",
    "    elif (type_ in valid_type):\n",
    "        break\n",
    "\n",
    "while True: \n",
    "        \n",
    "    quiz_list = quiz_list[-5:]  # 최신 5개 퀴즈만 보관\n",
    "    quiz_str = \" \".join(quiz_list)\n",
    "    retriever = get_retriever(txt_list[order-1])\n",
    "    # retriever = get_retriever(txt_list[order-1], current_index)\n",
    "    rag_chain = create_concept_rag_chain(retriever)\n",
    "\n",
    "    try:\n",
    "        response = rag_chain.invoke(\"질문 하나를 생성해주세요.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Quiz 생성 중 오류 발생: {e}\")\n",
    "        continue\n",
    "    \n",
    "    if len(quiz_list) > 0 and is_similar(response, quiz_list, 0.5):\n",
    "        continue\n",
    "\n",
    "    quiz = response\n",
    "    quiz_list.append(quiz)\n",
    "    print(\"quiz_list의 크기: \", len(quiz_list))\n",
    "\n",
    "    # discription_prompt = ChatPromptTemplate.from_messages([\n",
    "    #     (\"system\", f\"\"\"\n",
    "    #     quiz에 대해 정답을 찾을 수 있는 부분을 context에서만 찾아서 한국말로 보여주세요.\n",
    "    #     되도록이면 context 중에서도 코드 부분을 보여주세요.\n",
    "    #     단, quiz와는 내용이 정확하게 일치하는 부분은 제외해주세요.\n",
    "         \n",
    "    #     [주의]\n",
    "    #     코드외의 정답에 대한 직접적인 설명적인 힌트는 포함시키지 마세요.\n",
    "        \n",
    "    #     quiz : {{quiz}}\n",
    "    #     context : {{context}}\n",
    "        \n",
    "    #     \"\"\")\n",
    "    # ])\n",
    "\n",
    "    # discription_chain = discription_prompt | llm\n",
    "    # discription = discription_chain.invoke({\"quiz\": quiz, \"context\": retriever})\n",
    "\n",
    "    print(f\"Quiz : {quiz}\")\n",
    "    j+=1\n",
    "    save_file(''.join(quiz), f\"quiz_list_{j}.txt\")\n",
    "    # save_file(''.join([discription.content, str(quiz)]), f\"quiz_list_{j}.txt\")\n",
    "    \n",
    "    \n",
    "    # 2. 사용자 답변 수집\n",
    "    user_answer = input(\"답변을 입력하세요 종료를 원하시면 exit을 입력해주세요.: \").strip()\n",
    "\n",
    "    if user_answer.strip().lower() == \"exit\":\n",
    "        print(\"대화를 종료합니다.\")\n",
    "        break\n",
    "    \n",
    "    if not user_answer:\n",
    "        print(\"답변이 비어 있습니다. 다시 입력해주세요.\")\n",
    "        continue\n",
    "\n",
    "    # 3. 사용자 답변에 대한 피드백 생성\n",
    "    # 3. 사용자 답변에 대한 피드백 생성\n",
    "    feedback_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", f\"\"\"\n",
    "        AI 강사로서 다음 퀴즈의 정답 여부를 확인하고 피드백을 제공하세요.\n",
    "        피드백은 아래와 같은 형식이어야 합니다:\n",
    "        \n",
    "        - 정답 여부: \"N번\" 또는 \"예/아니오\"\n",
    "        - 추가 설명: (정답과 관련된 추가 정보를 제공하세요)\n",
    "        \n",
    "        퀴즈 : {{quiz}}\n",
    "        답변 : {{user_answer}}\n",
    "        \n",
    "        \"\"\")\n",
    "    ])\n",
    "\n",
    "    feedback_chain = feedback_prompt | llm\n",
    "    feedback = feedback_chain.invoke({\"quiz\": quiz, \"user_answer\": user_answer})\n",
    "    print(\"Feedback:\")\n",
    "    print(feedback)\n",
    "    current_index += 5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_model",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
