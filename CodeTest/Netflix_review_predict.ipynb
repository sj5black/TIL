{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "df = pd.read_csv(\"netflix_reviews.csv\")  # 파일 불러오기\n",
    "\n",
    "# 전처리 함수\n",
    "def preprocess_text(text):\n",
    "    if isinstance(text, float):\n",
    "        return \"\"\n",
    "    text = text.lower()  # 대문자를 소문자로\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # 구두점 제거\n",
    "    text = re.sub(r'\\d+', '', text)  # 숫자 제거\n",
    "    text = text.strip()  # 띄어쓰기 제외하고 빈 칸 제거\n",
    "    return text\n",
    "\n",
    "# content 컬럼에 전처리 함수 적용\n",
    "df['content'] = df['content'].apply(preprocess_text)\n",
    "\n",
    "# 필요한 열 선택 및 결측값 처리\n",
    "df = df[['content', 'score']].dropna().reset_index(drop=True)\n",
    "df = df[df['score'].isin([1,2,3,4,5])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "6\n",
      "44\n",
      "711\n",
      "320\n"
     ]
    }
   ],
   "source": [
    "# 특성과 타겟 분리\n",
    "X = df['content']\n",
    "y = df['score']\n",
    "\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "\n",
    "# 데이터셋 클래스 정의\n",
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, reviews, ratings, text_pipeline):\n",
    "        self.reviews = reviews.reset_index(drop=True)\n",
    "        self.ratings = ratings.reset_index(drop=True)\n",
    "        self.text_pipeline = text_pipeline\n",
    "        # self.label_pipeline = label_pipeline\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.reviews)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        review = self.text_pipeline(self.reviews.iloc[idx])\n",
    "        rating = self.ratings.iloc[idx]\n",
    "        rating_tensor = torch.tensor(rating, dtype=torch.float)\n",
    "        return review, rating_tensor\n",
    "\n",
    "# 데이터 분할\n",
    "train_reviews, test_reviews, train_ratings, test_ratings = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "# basic english를 기반으로 한 토큰 함수를 tokenizer로 선언\n",
    "# tokens = tokenizer(\"This is a sample sentence.\")\n",
    "# >> 이제 이 코드의 결과는 ['this', 'is', 'a', 'sample', 'sentence']와 같은 형태의 리스트를 tokens에 저장한다\n",
    "\n",
    "# 어휘 생성 함수\n",
    "def yield_tokens(data_iter):\n",
    "    for text in data_iter:\n",
    "        yield tokenizer(text)\n",
    "# 문장으로 이루어진 list(data_iter)가 입력되면, 각 문장마다 단어 형태로 분리해서 리스트로 묶은걸 반환해준다.\n",
    "\n",
    "# train_reviews에 있는 모든 문장들이 토큰화되어 사전 형태로 vocab에 추가된다.\n",
    "# 첫번째 값으로 <unk> 을 저장한다. 이 때, 각 단어마다 인덱스가 부여된다.\n",
    "# 예시) vocab = {\"<unk>\": 0, \"this\": 1, \"is\": 2, \"a\": 3, \"great\": 4, \"test\": 5}\n",
    "vocab = build_vocab_from_iterator(yield_tokens(train_reviews), specials=[\"<unk>\"])\n",
    "\n",
    "#vocab에 모르는 단어를 입력받을 경우, <unk>으로 저장한다.\n",
    "vocab.set_default_index(vocab[\"<unk>\"])\n",
    "\n",
    "# vocab.get_itos() 를 통해 확인 가능\n",
    "print(vocab['netflix'])  # 8\n",
    "print(vocab['is'])       # 6\n",
    "print(vocab['great'])    # 44\n",
    "print(vocab['ott'])      # 711\n",
    "print(vocab['platform']) # 320"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 파이프라인 정의\n",
    "def text_pipeline(text):\n",
    "    return torch.tensor([vocab[token] for token in tokenizer(text)], dtype=torch.long)\n",
    "\n",
    "# 레이블 파이프라인 정의\n",
    "# cat -> 0, dog -> 1, bird -> 2와 같은 식으로 카테고리를 숫자로 변환하는 것을 레이블 인코딩\n",
    "# label_encoder = LabelEncoder() # 라벨인코더 함수 생성\n",
    "# label_encoder.fit(df['score'].unique())  # 예시 레이블\n",
    "# def label_pipeline(label):\n",
    "#     return label_encoder.transform([label])[0]\n",
    "\n",
    "# 데이터 로더 정의\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# collate 함수 정의\n",
    "def collate_review_rating(batch):\n",
    "    reviews, ratings = zip(*batch)  # 배치에서 리뷰와 레이블 분리\n",
    "    reviews_padded = torch.nn.utils.rnn.pad_sequence(reviews, batch_first=True)  # 패딩 적용\n",
    "    ratings_tensor = torch.stack(ratings)  # 레이블은 스택\n",
    "    return reviews_padded, ratings_tensor\n",
    "\n",
    "# 데이터셋 정의\n",
    "train_dataset = ReviewDataset(train_reviews, train_ratings, text_pipeline)\n",
    "test_dataset = ReviewDataset(test_reviews, test_ratings, text_pipeline)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_review_rating)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_review_rating)\n",
    "\n",
    "# LSTM 모델 정의\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, output_dim):\n",
    "        super(LSTMModel, self).__init__()                             # 상속 클래스(Module에 대한 초기화 실행)\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, text):\n",
    "        embedded = self.embedding(text)\n",
    "        output, (hidden, cell) = self.lstm(embedded)\n",
    "        return self.fc(hidden[-1])\n",
    "\n",
    "# 하이퍼파라미터 정의\n",
    "VOCAB_SIZE = len(vocab)\n",
    "EMBED_DIM = 64\n",
    "HIDDEN_DIM = 128\n",
    "OUTPUT_DIM = 1  # 예측할 점수 개수\n",
    "\n",
    "# 모델 초기화\n",
    "model = LSTMModel(VOCAB_SIZE, EMBED_DIM, HIDDEN_DIM, OUTPUT_DIM)\n",
    "\n",
    "# 손실 함수와 옵티마이저 정의\n",
    "# criterion = nn.CrossEntropyLoss() # 분류 문제에 적합\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Train Loss: 0.9917, Test Loss: 1.0793\n",
      "Epoch [2/10], Train Loss: 0.9648, Test Loss: 1.1027\n",
      "Epoch [3/10], Train Loss: 0.9247, Test Loss: 1.0726\n",
      "Epoch [4/10], Train Loss: 0.9149, Test Loss: 1.0686\n",
      "Epoch [5/10], Train Loss: 0.8977, Test Loss: 1.0550\n",
      "Epoch [6/10], Train Loss: 0.8913, Test Loss: 1.0542\n",
      "Epoch [7/10], Train Loss: 0.8805, Test Loss: 1.0753\n",
      "Epoch [8/10], Train Loss: 0.8867, Test Loss: 1.0684\n",
      "Epoch [9/10], Train Loss: 0.8766, Test Loss: 1.0797\n",
      "Epoch [10/10], Train Loss: 0.8821, Test Loss: 1.0664\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# GPU 가동이 가능한 경우(CUDA), GPU 로 구동\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "# 모델 학습/평가\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0\n",
    "    test_loss = 0\n",
    "    \n",
    "    # 학습 데이터 로드\n",
    "    model.train()\n",
    "    for reviews_padded, ratings_tensor in train_dataloader:\n",
    "        #GPU 변환\n",
    "        reviews_padded = reviews_padded.to(device)\n",
    "        ratings_tensor = ratings_tensor.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(reviews_padded)\n",
    "        ratings_tensor = ratings_tensor.unsqueeze(1)\n",
    "        loss = criterion(outputs, ratings_tensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    # 평가 데이터 로드\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for reviews_padded, ratings_tensor in test_dataloader:\n",
    "            #GPU 변환\n",
    "            reviews_padded = reviews_padded.to(device)\n",
    "            ratings_tensor = ratings_tensor.to(device)\n",
    "\n",
    "            outputs = model(reviews_padded)\n",
    "            ratings_tensor = ratings_tensor.unsqueeze(1)\n",
    "            loss = criterion(outputs, ratings_tensor)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss/len(train_dataloader):.4f}, Test Loss: {test_loss/len(test_dataloader):.4f}')\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Score: 4.8705549240112305\n",
      "Predicted Score: 1.2798094749450684\n",
      "Predicted Score: 3.95182728767395\n"
     ]
    }
   ],
   "source": [
    "# 예측 함수(예시)\n",
    "def predict_review(model, new_review):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        review_tensor = text_pipeline(new_review)\n",
    "        # review_tensor = review_tensor.unsqueeze(0)  # 배치 차원 추가\n",
    "        output = model(review_tensor)\n",
    "        # prediction = output.argmax(1).item()\n",
    "        return output.item()\n",
    "    \n",
    "# 새로운 리뷰에 대한 예측 (1)\n",
    "new_review = \"It's very amazing ott platform. Almost every single contents are so creative and awesome.\"\n",
    "print(f'Predicted Score: {predict_review(model, new_review)}')\n",
    "\n",
    "# 새로운 리뷰에 대한 예측 (2)\n",
    "new_review = \"It's so terrible. I couldn't apply 4K UHD although I paid premium membership.\"\n",
    "print(f'Predicted Score: {predict_review(model, new_review)}')\n",
    "\n",
    "# 새로운 리뷰에 대한 예측 (3)\n",
    "new_review = \"I couldn't find some movies, but Netflix was good overall.\"\n",
    "print(f'Predicted Score: {predict_review(model, new_review)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python myenv1014",
   "language": "python",
   "name": "myenv1014"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
