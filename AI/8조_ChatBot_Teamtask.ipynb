{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 트러블 슈팅\n",
    "---\n",
    "1. WebBaseLoader 로 레퍼런스가 정상적으로 인식되지 않는 문제  \n",
    " - 원인 : WebBaseLoader의 한계로 인한 실패 가능성. WebBaseLoader는 간단한 텍스트 추출에 적합하며, 복잡한 HTML 구조나 JavaScript 기반의 동적 콘텐츠를 처리하지 못할 수 있다. \n",
    "\n",
    "    1_1. WebBaseLoader 대신 request를 사용한 HTML 크롤링 시도 -> 실패  \n",
    "     - 원인 : Notion 페이지는 JavaScript를 활용한 동적 렌더링을 사용하는 구조여서 requests만 사용해서는 JavaScript로 렌더링된 내용을 가져올 수 없었다.\n",
    "\n",
    "    1_2. Selenium 사용 --> 부분 성공  \n",
    "     - 원인 : implicitly_wait 으로 대기 후 로드 시 데이터를 가져오는 경우가 있고, 못가져오는 경우가 있었음..\n",
    "\n",
    "    1_3. 대기 방식 변경 (WebDriverWait.until() 사용) --> 성공  \n",
    "     - 로드하려는 웹페이지의 html 중 특정 요소가 로드될 때까지 wait하는 방식 사용\n",
    "\n",
    "2. soup.get_text() 에서 노션 문서의 헤드라인만 추출되는 문제  \n",
    " - 원인 : 노션 페이지에 진입했을 때, 토글(Ctrl+Alt+T)이 닫힌 상태로 텍스트가 추출되고 있었음\n",
    "\n",
    "    2_1. 단축키 입력을 선언하는 방법 (헤드리스 상태에서 사용 불가)  \n",
    "\n",
    "    2_2. html 내에 토글 버튼을 찾아 여는 방법 (헤드리스 상태에서 사용 가능) --> 선택 (성공)  \n",
    "     - drive.find_elements 로 버튼 탐색 후 클릭 (지연시간 1초)\n",
    "\n",
    "3. 추출된 텍스트 파일에 일부 문법 구문이 남아있는 문제  \n",
    " - re (regular expression) 을 활용해 삭제/전처리 (성공)\n",
    "\n",
    "4. AI 가 질문에 대한 사용자의 답변을 인식하지 못하는 문제  \n",
    " - 사용자의 답변을 질문과 함께 feedback_prompt 형식으로 묶어서 다시 AI에게 전달하는 방식으로 문제 해결\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from pprint import pprint\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import re\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# .env 파일에서 환경변수 로드\n",
    "load_dotenv(\"C:/.env\")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# Selenium 옵션 설정 (헤드리스 모드로 실행)\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")  # 브라우저 창을 띄우지 않음\n",
    "chrome_options.add_argument(\"--disable-gpu\")  # GPU 비활성화 (일부 환경에서 필요)\n",
    "\n",
    "# WebDriver 경로 설정 (자동 설치)\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "\n",
    "url_list=[]\n",
    "txt_list=[]\n",
    "\n",
    "# 환경변수에 저장된 URL 로드\n",
    "for i in range(1, 17):  # URL_1 ~ URL_16\n",
    "    url = os.getenv(f\"URL_{i}\")\n",
    "    if url:  # 환경변수가 존재하면 추가\n",
    "        url_list.append(url)\n",
    "\n",
    "# 웹페이지 요청\n",
    "for url in url_list:\n",
    "    driver.get(url)  # 페이지 로드\n",
    "\n",
    "    # 특정 요소가 로드될 때까지 기다림 (예: Notion 페이지에서 주요 콘텐츠가 담길 요소)\n",
    "    try:\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, \".notion-page-content\"))\n",
    "        )\n",
    "    except TimeoutException:\n",
    "        print(f\"페이지 로딩 실패: {url}\")\n",
    "        continue\n",
    "    \n",
    "    # 토글이 닫혀 있으면 토글을 열기\n",
    "    try:\n",
    "        # 모든 토글 버튼을 찾음 (Ctrl+Alt+T에 해당하는 토글을 찾아서 열기)\n",
    "        toggle_buttons = driver.find_elements(By.XPATH, \"//div[@role='button' and contains(@aria-label, '열기')]\")\n",
    "        \n",
    "        # 각 토글을 클릭하여 열기\n",
    "        for button in toggle_buttons:\n",
    "            button.click()\n",
    "            time.sleep(1)  # 토글이 열리기 전에 잠깐 대기\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"토글을 여는 데 실패했습니다: {e}\")\n",
    "\n",
    "    # 페이지의 HTML 가져오기\n",
    "    html_code = driver.page_source\n",
    "\n",
    "    # BeautifulSoup으로 HTML 파싱\n",
    "    soup = BeautifulSoup(html_code, 'html.parser')\n",
    "\n",
    "    txt = soup.get_text()\n",
    "\n",
    "    # 1. \\xa0를 공백으로 변환\n",
    "    txt = txt.replace('\\xa0', ' ')\n",
    "\n",
    "    # 2. 정규식을 사용해 \\\\로 시작하는 LaTeX 명령어 제거\n",
    "    txt = re.sub(r'\\\\[a-zA-Z]+\\{.*?\\}', '', txt)  # \\command{...} 형식 제거\n",
    "    txt = re.sub(r'\\\\[a-zA-Z]+', '', txt)        # \\command 형식 제거\n",
    "\n",
    "    # 3. 불필요한 공백 제거 (코드 개행 유지를 위해 주석처리)\n",
    "    # txt = re.sub(r'\\s+', ' ', txt).strip()\n",
    "\n",
    "    # 텍스트만 가져오기\n",
    "    txt_list.append(txt)\n",
    "\n",
    "\n",
    "driver.quit()  # 브라우저 종료\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('[스파르타코딩클럽] 6. 순환 신경망(RNN)[SCC] 기초가 탄탄한 딥러닝/[스파르타코딩클럽] 기초가 탄탄한 딥러닝 - '\n",
      " '2주차/[스파르타코딩클럽] 6. 순환 신경망(RNN)제작:[스파르타코딩클럽] 6. 순환 신경망(RNN)[수업 목표]순환 신경망(RNN) '\n",
      " '개념에 대해서 배워보고 어떤 원리로 동작하는지 알아봅시다Pytorch로 간단한 RNN 모델 구현 실습을 진행해 봅시다[목차]01. '\n",
      " 'RNN의 기본 구조와 동작 원리02. RNN과 LSTM을 이용한 시계열 데이터 예측 (PyTorch)💡모든 토글을 열고 닫는 단축키\\n'\n",
      " 'Windows : Ctrl + alt + t \\n'\n",
      " 'Mac : ⌘ + ⌥ + t 01. RNN의 기본 구조와 동작 원리✔️RNN의 기본 구성요소와 어떤 방식으로 동작하는지 배워보고, '\n",
      " 'LSTM 과 GRU에 대해 알아보고 비교해 봅시다.1) RNN의 기본 구조와 작동 방식 RNN의 기본 구조순환 신경망(Recurrent '\n",
      " 'Neural Network, RNN)은 시계열 데이터나 순차적인 데이터를 처리하기 위해 설계된 신경망입니다RNN은 이전 시간 단계의 '\n",
      " '정보를 현재 시간 단계로 전달해, 시퀀스 데이터의 패턴을 학습할 수 있습니다.ALT RNN의 동작 원리순환 구조RNN은 입력 데이터와 '\n",
      " '이전 시간 단계의 은닉 상태(hidden state)를 입력으로 받아, 현재 시간 단계의 은닉 상태를 출력합니다.은닉 상태는 시퀀스의 '\n",
      " '정보를 저장하고, 다음 시간 단계로 전달됩니다.동작 원리RNN은 시퀀스의 각 시간 단계에서 동일한 가중치를 공유하여, 시퀀스의 패턴을 '\n",
      " '학습합니다.순전파(Forward Propagation)와 역전파(Backpropagation Through Time, BPTT)를 통해 '\n",
      " '가중치를 학습합니다.2) LSTM 및 GRU LSTM & GRURNN은 장기 의존성 문제(long-term dependency '\n",
      " 'problem)를 겪을 수 있습니다. 이를 해결하기 위해 LSTM과 GRU가 개발되었습니다. LSTM(Long Short-Term '\n",
      " 'Memory)LSTM은 셀 상태(cell state)와 게이트(gate) 구조를 도입, 장기 의존성을 효과적으로 학습가능 '\n",
      " '합니다.LSTM은 입력 게이트(input gate), 출력 게이트(output gate), 망각 게이트(forget gate)를 사용하여 '\n",
      " '정보를 조절합니다. GRU (Gated Recurrent Unit)GRU는 LSTM의 변형으로, 셀 상태 대신 은닉 상태(hidden '\n",
      " 'state)만을 사용하여 구조를 단순화합니다.GRU는 업데이트 게이트(update gate)와 리셋 게이트(reset gate)를 '\n",
      " '사용하여 정보를 조절합니다. 차이점LSTM은 셀 상태와 은닉 상태를 모두 사용하며, 더 복잡한 게이트 구조를 가집니다.GRU는 은닉 '\n",
      " '상태만을 사용하며, 더 간단한 게이트 구조를 가집니다. 따라서 계산 비용이 적고, 학습이 빠를 수 있습니다.ALT3) 시계열 데이터 처리 '\n",
      " 'RNN을 이용한 시계열 데이터 처리 방법RNN은 시계열 데이터나 순차적인 데이터를 처리하는 데 적합합니다. 예를 들어, 주식 가격 예측, '\n",
      " '날씨 예측, 텍스트 생성 등이 있습니다.데이터 전처리:시계열 데이터를 적절한 형태로 변환하고, '\n",
      " '정규화(normalization)합니다.입력 시퀀스와 출력 시퀀스를 정의합니다.모델 구축:RNN, LSTM, GRU 등의 모델을 '\n",
      " '정의합니다.입력 크기, 은닉 상태 크기, 출력 크기 등을 설정합니다.모델 학습:손실 함수와 최적화 알고리즘을 정의합니다.순전파와 역전파를 '\n",
      " '통해 모델을 학습시킵니다.모델 평가:테스트 데이터를 사용하여 모델의 성능을 평가합니다.02. RNN과 LSTM을 이용한 시계열 데이터 '\n",
      " '예측 (PyTorch)✔️ 이제 PyTorch를 사용하여 간단한 RNN과 LSTM 모델을 구축하고, 시계열 데이터를 예측해보겠습니다. '\n",
      " '예제로는 Sine 파형 데이터를 사용하겠습니다.1)  간단한 RNN/LSTM 모델을 이용한 시계열 데이터 예측 실습 PyTorch 및 '\n",
      " '필요한 라이브러리 임포트PyTorch 및 필요한 라이브러리 임포트 {5px}PyTorch 및 필요한 라이브러리 임포트 '\n",
      " '\\ufeff\\u200bPython복사import torch\\n'\n",
      " 'import torch.nn as nn\\n'\n",
      " 'import torch.optim as optim\\n'\n",
      " 'import numpy as np\\n'\n",
      " 'import matplotlib.pyplot as plt\\n'\n",
      " '\\u200b데이터셋 생성 및 전처리데이터셋 생성 및 전처리 {5px}데이터셋 생성 및 전처리 \\ufeff\\u200bPython복사# '\n",
      " 'Sine 파형 데이터 생성\\n'\n",
      " 'def create_sine_wave_data(seq_length, num_samples):\\n'\n",
      " '    X = []\\n'\n",
      " '    y = []\\n'\n",
      " 'for _ in range(num_samples):\\n'\n",
      " '        start = np.random.rand()\\n'\n",
      " '        x = np.linspace(start, start + 2 * np.pi, seq_length)\\n'\n",
      " '        X.append(np.sin(x))\\n'\n",
      " '        y.append(np.sin(x + 0.1))\\n'\n",
      " 'return np.array(X), np.array(y)\\n'\n",
      " '\\n'\n",
      " 'seq_length = 50\\n'\n",
      " 'num_samples = 1000\\n'\n",
      " 'X, y = create_sine_wave_data(seq_length, num_samples)\\n'\n",
      " '# 데이터셋을 PyTorch 텐서로 변환\\n'\n",
      " 'X = torch.tensor(X, dtype=torch.float32).unsqueeze(-1)\\n'\n",
      " 'y = torch.tensor(y, dtype=torch.float32).unsqueeze(-1)\\n'\n",
      " '\\u200b 간단한 RNN 모델 정의간단한 RNN 모델 정의 {5px}간단한 RNN 모델 정의 '\n",
      " '\\ufeff\\u200bPython복사class SimpleRNN(nn.Module):\\n'\n",
      " 'def __init__(self, input_size, hidden_size, output_size):\\n'\n",
      " 'super(SimpleRNN, self).__init__()\\n'\n",
      " '        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\\n'\n",
      " '        self.fc = nn.Linear(hidden_size, output_size)\\n'\n",
      " 'def forward(self, x):\\n'\n",
      " '        h0 = torch.zeros(1, x.size(0), hidden_size) # 초기 은닉 상태\\n'\n",
      " '        out, _ = self.rnn(x, h0)\\n'\n",
      " '        out = self.fc(out[:, -1, :]) # 마지막 시간 단계의 출력\\n'\n",
      " 'return out\\n'\n",
      " '\\n'\n",
      " 'input_size = 1\\n'\n",
      " 'hidden_size = 32\\n'\n",
      " 'output_size = 1\\n'\n",
      " 'model = SimpleRNN(input_size, hidden_size, output_size)\\n'\n",
      " '\\u200bnn.RNN: 순환 신경망(RNN) 층을 정의합니다.nn.RNN(input_size, hidden_size, '\n",
      " 'batch_first)는 입력 크기, 은닉 상태 크기, 배치 차원을 첫 번째로 설정합니다..RNN(input_size, '\n",
      " 'hidden_size, batch_first)는 입력 크기, 은닉 상태 크기, 배치 차원을 첫 번째로 '\n",
      " '설정합니다.\\ufeff\\u200bnn.Linear: 선형 변환을 적용하는 완전 연결(fully connected) 레이어를 '\n",
      " '정의합니다.nn.Linear(in_features, out_features)는 입력 특징의 수와 출력 특징의 수를 '\n",
      " '지정합니다..Linear(in_features, out_features)는 입력 특징의 수와 출력 특징의 수를 '\n",
      " '지정합니다.\\ufeff\\u200b 간단한 LSTM 모델 정의간단한 LSTM 모델 정의 {5px}간단한 LSTM 모델 정의 '\n",
      " '\\ufeff\\u200bPython복사class SimpleLSTM(nn.Module):\\n'\n",
      " 'def __init__(self, input_size, hidden_size, output_size):\\n'\n",
      " 'super(SimpleLSTM, self).__init__()\\n'\n",
      " '        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\\n'\n",
      " '        self.fc = nn.Linear(hidden_size, output_size)\\n'\n",
      " 'def forward(self, x):\\n'\n",
      " '        h0 = torch.zeros(1, x.size(0), hidden_size) # 초기 은닉 상태\\n'\n",
      " '        c0 = torch.zeros(1, x.size(0), hidden_size) # 초기 셀 상태\\n'\n",
      " '        out, _ = self.lstm(x, (h0, c0))\\n'\n",
      " '        out = self.fc(out[:, -1, :]) # 마지막 시간 단계의 출력\\n'\n",
      " 'return out\\n'\n",
      " '\\n'\n",
      " 'model = SimpleLSTM(input_size, hidden_size, output_size)\\n'\n",
      " '\\u200bnn.LSTM: 장단기 메모리(LSTM) 층을 정의합니다.nn.LSTM(input_size, hidden_size, '\n",
      " 'batch_first)는 입력 크기, 은닉 상태 크기, 배치 차원을 첫 번째로 설정합니다..LSTM(input_size, '\n",
      " 'hidden_size, batch_first)는 입력 크기, 은닉 상태 크기, 배치 차원을 첫 번째로 설정합니다.\\ufeff\\u200b '\n",
      " '모델 학습모델 학습 {5px}모델 학습 \\ufeff\\u200bPython복사# 손실 함수와 최적화 알고리즘 정의\\n'\n",
      " 'criterion = nn.MSELoss()\\n'\n",
      " 'optimizer = optim.Adam(model.parameters(), lr=0.01)\\n'\n",
      " '# 모델 학습\\n'\n",
      " 'num_epochs = 100\\n'\n",
      " 'for epoch in range(num_epochs):\\n'\n",
      " '    outputs = model(X)\\n'\n",
      " '    optimizer.zero_grad()\\n'\n",
      " '    loss = criterion(outputs, y)\\n'\n",
      " '    loss.backward()\\n'\n",
      " '    optimizer.step()\\n'\n",
      " 'if (epoch + 1) % 10 == 0:\\n'\n",
      " \"print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\\n\"\n",
      " \"print('Finished Training')\\n\"\n",
      " '\\u200bnn.MSELoss: 평균 제곱 오차(MSE) 손실 함수를 정의합니다.optim.Adam: Adam 최적화 알고리즘을 '\n",
      " '정의합니다. lr은 학습률을 지정합니다.optimizer.zero_grad(): 이전 단계에서 계산된 기울기를 '\n",
      " '초기화합니다.loss.backward(): 역전파를 통해 기울기를 계산합니다.optimizer.step(): 계산된 기울기를 바탕으로 '\n",
      " '가중치를 업데이트합니다. 모델 평가 및 시각화모델 평가 및 시각화 {5px}모델 평가 및 시각화 \\ufeff\\u200bPython복사# '\n",
      " '모델 평가\\n'\n",
      " 'model.eval()\\n'\n",
      " 'with torch.no_grad():\\n'\n",
      " '    predicted = model(X).detach().numpy()\\n'\n",
      " '# 시각화\\n'\n",
      " 'plt.figure(figsize=(10, 5))\\n'\n",
      " \"plt.plot(y.numpy().flatten(), label='True')\\n\"\n",
      " \"plt.plot(predicted.flatten(), label='Predicted')\\n\"\n",
      " 'plt.legend()\\n'\n",
      " 'plt.show()\\n'\n",
      " '\\u200bmodel.eval(): 모델을 평가 모드로 전환합니다.torch.no_grad(): 평가 단계에서는 기울기를 계산할 필요가 '\n",
      " '없으므로, 이를 비활성화하여 메모리 사용을 줄입니다.detach(): 텐서를 계산 그래프에서 분리합니다.Copyright ⓒ '\n",
      " 'TeamSparta All rights reserved.')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 결과 출력\n",
    "pprint(txt_list[5])  # 두 번째 URL의 텍스트 내용 출력\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of document chunks: 16\n",
      "Top 10 chunks:\n",
      "('\\n'\n",
      " 'Chunk 1:\\n'\n",
      " '[스파르타코딩클럽] 1. 딥러닝 개념을 잡아봅시다![SCC] 기초가 탄탄한 딥러닝/[스파르타코딩클럽] 기초가 탄탄한 딥러닝 - '\n",
      " '1주차/[스파르타코딩클럽] 1. 딥러닝 개념을 잡아봅시다!제작:[스파르타코딩클럽] 1. 딥러닝 개념을 잡아봅시다![수업 목표]딥러닝이 '\n",
      " '무엇인지 개념에 대해 알아봅시다.딥러닝의 역사와 어디에 사용할 수 있을지 알아봅시다[목차]01. 딥러닝이란 무엇일까요?02. 딥러닝의 '\n",
      " '역사와 활용 방안03. 딥러닝을 배워야 하는 이유모든 토글을 열고 닫는 단축키\\n'\n",
      " 'Windows : Ctrl + alt + t \\n'\n",
      " 'Mac : ⌘ + ⌥ + t 01. 딥러닝이란 무엇일까요?딥러닝이란 무엇인지 개념에 대해서 알아봅시다!1) 딥러닝이란? 딥러닝 '\n",
      " '개념딥러닝은 인공신경망(Artificial Neural Networks)을 기반으로 한 기계 학습의 한 분야입니다.다층 신경망을 사용하여 '\n",
      " '데이터로부터 특징을 자동으로 학습하고, 이를 통해 복잡한 문제를 해결합니다.입력 데이터에서 중요한 패턴을 추출하고, 이를 바탕으로 예측, '\n",
      " '분류, 생성 등의 다양한 작업을 수행할 수 있습니다.ALT 딥러닝의 특징비선형 추론: 딥러닝은 비선형 추론을 통해 복잡한 데이터의 패턴을 '\n",
      " '학습할 수 있습니다.다층 구조: 여러 층의 신경망을 사용하여 데이터의 고차원 특징을 학습합니다.자동 특징 추출: 데이터로부터 중요한 '\n",
      " '특징을 자동으로 추출하여 별도의 특징 공학(feature engineering) 과정이 필요 없습니다.02. 딥러닝의 역사와 활용 '\n",
      " '방안딥러닝의 역사와 어디에 딥러닝을 쓸 수 있을지 배워봅시다!1) 딥러닝의 역사와 발전 발전 과정ALT 인공지능, 머신러닝, 딥러닝의 '\n",
      " '관계인공지능(AI) : 인공지능은 인간의 지능을 모방하여 문제를 해결하는 기술을 의미합니다. AI는 규칙 기반 시스템부터 자율 학습 '\n",
      " '시스템까지 다양한 접근 방식을 포함합니다.머신러닝(ML) : 머신러닝은 데이터를 이용해 모델을 학습하고, 이를 통해 예측이나 결정을 '\n",
      " '내리는 기술입니다. 머신러닝은 AI의 하위 분야로, 지도 학습, 비지도 학습, 강화 학습 등의 방법을 포함합니다.딥러닝(DL) : '\n",
      " '딥러닝은 머신러닝의 하위 분야로, 다층 신경망을 사용하여 데이터를 학습합니다. 딥러닝은 특히 대규모 데이터와 복잡한 문제를 다루는 데 '\n",
      " '강력한 성능을 발휘합니다.ALT2) 최근의 활용 방안 이미지 인식딥러닝은 이미지 분류, 객체 검출, 이미지 생성 등 다양한 이미지 처리 '\n",
      " '작업에 활용됩니다. 예를 들어, 자율 주행 자동차는 딥러닝을 사용하여 도로 상황을 인식하고, 보행자와 차량을 감지합니다. 자연어 '\n",
      " '처리번역, 요약, 감정 분석 등 자연어 처리 작업에 사용됩니다. 예를 들어, 구글 번역은 딥러닝 모델을 사용하여 다양한 언어 간의 번역을 '\n",
      " '수행합니다. 음성 인식딥러닝은 음성 인식 시스템의 성능을 크게 향상시켰습니다.예를 들어, 애플의 Siri, 아마존의 Alexa와 같은 '\n",
      " '가상 비서는 딥러닝을 사용하여 사용자의 음성을 인식하고 명령을 수행합니다. 의료 분야의료 영상 분석, 질병 예측, 신약 개발 등 다양한 '\n",
      " '의료 분야에서도 활용됩니다.예를 들어, 딥러닝 모델은 MRI나 CT 스캔 이미지를 분석하여 암을 조기에 발견할 수 있습니다.03. '\n",
      " '딥러닝을 배워야 하는 이유그러면 왜? 딥러닝을 배워야 하는지 이유를 알아 봅시다1) 딥러닝을 배워야 하는 이유ALTCopyright ⓒ '\n",
      " 'TeamSparta All rights reserved.')\n",
      "('\\n'\n",
      " 'Chunk 2:\\n'\n",
      " '[스파르타코딩클럽] 2. 신경망의 기본 원리[SCC] 기초가 탄탄한 딥러닝/[스파르타코딩클럽] 기초가 탄탄한 딥러닝 - '\n",
      " '1주차/[스파르타코딩클럽] 2. 신경망의 기본 원리제작:[스파르타코딩클럽] 2. 신경망의 기본 원리[수업 목표]퍼셉트론의 개념과 다층 '\n",
      " '퍼셉트론에 대해 배워봅시다.신경망을 강화하기 위한 활성화 함수/손실 함수/역전파/최적화 알고리즘에 대해 배워봅시다[목차]01. 퍼셉트론과 '\n",
      " '다층 퍼셉트론(XOR 문제 포함)02. 다층 퍼셉트론(MLP)03. 활성화 함수04. 손실 함수와 최적화 알고리즘05. 역전파에 대해 '\n",
      " '알아볼까요?💡모든 토글을 열고 닫는 단축키\\n'\n",
      " 'Windows : Ctrl + alt + t \\n'\n",
      " 'Mac : ⌘ + ⌥ + t 01. 퍼셉트론과 다층 퍼셉트론(XOR 문제 포함)✔️인공신공망의 가장 기본 단위인 퍼셉트론에 대해 '\n",
      " '배워봅시다1) 단일 퍼셉트론의 원리 단일 퍼셉트론의 개념퍼셉트론(Perceptron)은 인공 신경망의 가장 기본적인 단위로, 하나의 '\n",
      " '뉴런을 모델링한 것입니다.퍼셉트론은 입력 값을 받아 가중치(weight)를 곱하고, 이를 모두 더한 후 활성화 함수(activation '\n",
      " 'function)를 통해 출력 값을 결정합니다.ALT 퍼셉트론의 수학적 표현y=f(∑i=1nwixi+b)y = f(_{i=1}^{n} '\n",
      " 'w_i x_i + b) y=f(i=1∑n\\u200bwi\\u200bxi\\u200b+b)여기서 xi는 입력 값, wi는 가중치, b는 '\n",
      " '바이어스(bias), f는 활성화 함수입니다.여기서 xi\\u200b는 입력 값, wi\\u200b는 가중치, b는 바이어스(bias), '\n",
      " 'f는 활성화 함수입니다.\\ufeff\\u200b02. 다층 퍼셉트론(MLP)✔️다층 퍼셉트론에 대해 배워봅시다1) 다층 퍼셉트론(MLP)과 '\n",
      " 'XOR 문제 해결 다층 퍼셉트론(MLP)의 개념다층 퍼셉트론(Multi-Layer Perceptron, MLP)은 여러 층의 퍼셉트론을 '\n",
      " '쌓아 올린 신경망 구조입니다.MLP는 입력층(input layer), 은닉층(hidden layer), 출력층(output '\n",
      " 'layer)으로 구성되며, 각 층의 뉴런들이 서로 연결되어 있습니다.ALT 입력, 은닉, 출력 레이어의 개념입력 레이어(Input '\n",
      " 'Layer) : 외부 데이터가 신경망에 입력되는 부분입니다. 입력 레이어의 뉴런 수는 입력 데이터의 특징 수와 동일합니다.은닉 '\n",
      " '레이어(Hidden Layer) : 은닉 레이어는 입력 레이어와 출력 레이어 사이에 위치한 층으로, 입력 데이터를 처리하고 특징을 '\n",
      " '추출하는 역할을 합니다. 은닉 레이어의 뉴런 수와 층 수는 모델의 복잡성과 성능에 영향을 미칩니다.출력 레이어(Output Layer) '\n",
      " ': 출력 레이어는 신경망의 마지막 층으로, 최종 예측 값을 출력합니다. 출력 레이어의 뉴런 수는 예측하려는 클래스 수 또는 회귀 문제의 '\n",
      " '출력 차원과 동일합니다. XOR 문제와 MLP단일 퍼셉트론은 선형 분류기이기 때문에 XOR 문제와 같은 비선형 문제를 해결할 수 '\n",
      " '없습니다.XOR 문제는 두 입력 값이 다를 때만 1을 출력하는 문제로, 단일 퍼셉트론으로는 해결할 수 없습니다. 그러나 MLP는 은닉층을 '\n",
      " '통해 비선형성을 학습할 수 있어 XOR 문제를 해결할 수 있습니다.03. 활성화 함수✔️활성화 함수라는게 무엇인지, 신경망에서 어떤 '\n",
      " '역할을 하는지 알아보고, 어떤 종류의 활성화 함수가 있는지 배워봅시다1) 활성화 함수의 필요성과 종류 활성화 함수의 필요성활성화 함수는 '\n",
      " '신경망의 각 뉴런에서 입력값을 출력값으로 변환하는 역할을 합니다.활성화 함수가 없다면 신경망은 단순 선형변환만 수행하게 되어 복잡한 '\n",
      " '패턴을 학습할 수 없습니다.활성화 함수는 비 선형성을 도입하여 신경망이 복잡한 패턴을 학습할 수 있게합니다. 활성화 함수의 종류ReLU '\n",
      " '(Rectified Linear Unit)f(x)=max\\u2061(0,x)f(x) = (0, x)f(x)=max(0,x)장점: 계산이 '\n",
      " '간단하고, 기울기 소실 문제(vanishing gradient problem)를 완화합니다.단점: 음수 입력에 대해 기울기가 0이 되는 '\n",
      " \"'죽은 ReLU' 문제가 발생할 수 있습니다.Sigmoidf(x)=11+e−xf(x) = {1 + e^{-x}} \"\n",
      " 'f(x)=1+e−x1\\u200b장점: 출력 값이 0과 1 사이로 제한되어 확률을 표현하기에 적합합니다.단점: 기울기 소실 문제와 출력 '\n",
      " '값이 0 또는 1에 가까워질 때 학습이 느려지는 문제가 있습니다.Tanh (Hyperbolic '\n",
      " 'Tangent)f(x)=tanh\\u2061(x)=ex−e−xex+e−xf(x) = (x) = }{e^x + '\n",
      " 'e^{-x}}f(x)=tanh(x)=ex+e−xex−e−x\\u200b장점: 출력 값이 -1과 1 사이로 제한되어 중심이 0에 '\n",
      " '가까워집니다.단점: 기울기 소실 문제가 발생할 수 있습니다.04. 손실 함수와 최적화 알고리즘✔️손실함수와 최적화 알고리즘이 무엇인지 '\n",
      " '배우고 주요 사용하는 함수의 종류를 배워봅시다.1) 손실 함수의 역할과 주요 종류 손실함수의 역할손실 함수(Loss Function)는 '\n",
      " '모델의 예측 값과 실제 값 사이의 차이를 측정하는 함수입니다.손실 함수는 모델의 성능을 평가하고, 최적화 알고리즘을 통해 모델을 '\n",
      " '학습시키는 데 사용됩니다. 주요 손실 함수의 종류MSE (Mean Squared Error)MSE=1n∑i=1n(yi−y^i)2 = '\n",
      " '{n} _{i=1}^{n} (y_i - _i)^2 '\n",
      " 'MSE=n1\\u200bi=1∑n\\u200b(yi\\u200b−y^\\u200bi\\u200b)2사용 분야: 회귀 문제에서 주로 '\n",
      " '사용됩니다.특징: 예측 값과 실제 값의 차이를 제곱하여 평균을 '\n",
      " '구합니다.Cross-EntropyCross-Entropy=−∑i=1nyilog\\u2061(y^i) = -_{i=1}^{n} y_i '\n",
      " '(_i)Cross-Entropy=−i=1∑n\\u200byi\\u200blog(y^\\u200bi\\u200b)사용 분야: 분류 문제에서 주로 '\n",
      " '사용됩니다.특징: 예측 확률과 실제 클래스 간의 차이를 측정합니다.2) 최적화 알고리즘의 개념과 종류 최적화 알고리즘의 개념최적화 '\n",
      " '알고리즘(Optimization Algorithm)은 손실 함수를 최소화하기 위해 모델의 가중치를 조정하는 방법입니다.최적화 알고리즘은 '\n",
      " '손실 함수의 기울기를 계산하고, 이를 바탕으로 가중치를 업데이트합니다. 주요 최적화 알고리즘의 종류SGD (Stochastic '\n",
      " 'Gradient Descent)개념: 전체 데이터셋이 아닌 무작위로 선택된 일부 데이터(미니배치)를 사용하여 기울기를 계산하고 가중치를 '\n",
      " '업데이트합니다.장점: 계산이 빠르고, 큰 데이터셋에서도 효율적으로 동작합니다.단점: 최적점에 도달하기까지 진동이 발생할 수 '\n",
      " '있습니다.Adam (Adaptive Moment Estimation)개념: 모멘텀과 RMSProp을 결합한 알고리즘으로, 학습률을 '\n",
      " '적응적으로 조정합니다.장점: 빠른 수렴 속도와 안정적인 학습을 제공합니다.단점: 하이퍼파라미터 설정이 복잡할 수 있습니다.05. 역전파에 '\n",
      " '대해 알아볼까요?✔️역전파에 대해 배워봅시다1) 역전파 알고리즘의 개념과 수학적 원리 역전파 알고리즘의 '\n",
      " '개념역전파(Backpropagation)는 신경망의 가중치를 학습시키기 위해 사용되는 알고리즘입니다. 출력에서 입력 방향으로 손실 함수의 '\n",
      " '기울기를 계산하고, 이를 바탕으로 가중치를 업데이트합니다. 역전파의 수학적 원리연쇄 법칙(Chain Rule)을 사용해 손실함수의 '\n",
      " '기울기를 계산합니다.각 층의 기울기는 이전 층의 기울기와 현재 층의 기울기를 곱하여 계산합니다.이를 통해 신경망의 모든 가중치가 업데이트 '\n",
      " '됩니다ALTCopyright ⓒ TeamSparta All rights reserved.')\n",
      "('\\n'\n",
      " 'Chunk 3:\\n'\n",
      " '[스파르타코딩클럽] 3. 딥러닝 실습 환경 구축[SCC] 기초가 탄탄한 딥러닝/[스파르타코딩클럽] 기초가 탄탄한 딥러닝 - '\n",
      " '1주차/[스파르타코딩클럽] 3. 딥러닝 실습 환경 구축제작:[스파르타코딩클럽] 3. 딥러닝 실습 환경 구축[수업 목표]딥러닝 실습을 위한 '\n",
      " '환경을 구축해 봅시다[목차]01. conda를 이용한 환경 설정02. jupyter notebook 03. 가상환경 설치 및 '\n",
      " 'jupyter notebook 연결 04. pytorch 설치💡모든 토글을 열고 닫는 단축키\\n'\n",
      " 'Windows : Ctrl + alt + t \\n'\n",
      " 'Mac : ⌘ + ⌥ + t 01. conda를 이용한 환경 설정✔️conda를 설치하고 환경설정을 진행해 봅시다1) conda를 이용한 '\n",
      " '환경 설정 conda란 무엇인가?Conda는 패키지 관리와 환경 관리를 위한 오픈 소스 플랫폼입니다. 다양한 라이브러리와 패키지를 쉽게 '\n",
      " '설치하고 관리할 수 있으며, 서로 다른 프로젝트 간의 종속성을 격리할 수 있습니다. conda '\n",
      " '설치Anacondahttps://www.anaconda.com/downloadALTMinicondahttps://docs.anaconda.com/miniconda/ALT '\n",
      " 'conda 환경 설정다음과 같이 새로운 환경을 생성하고 필요한 패키지를 설치 합니다.새로운 환경 생성 {5px}새로운 환경 생성 '\n",
      " '\\ufeff\\u200bPython복사conda create --name myenv python=3.8\\n'\n",
      " '\\u200b환경 활성화 {5px}환경 활성화 \\ufeff\\u200bPython복사conda activate myenv\\n'\n",
      " '\\u200b필요한 패키지 설치 {5px}필요한 패키지 설치 \\ufeff\\u200bPython복사conda install numpy '\n",
      " 'pandas matplotlib\\n'\n",
      " '\\u200b02. jupyter notebook ✔️jupyter notebook이 무엇인지 알아보고 설치해 봅시다.1)  jupyter '\n",
      " 'notebook 사용법 jupyter notebook이란?Jupyter Notebook은 데이터 과학자와 연구자들이 코드를 작성하고 '\n",
      " '실행하며, 결과를 시각화하고 문서화할 수 있는 대화형 환경입니다. jupyter notebook 설치Jupyter Notebook은 '\n",
      " 'conda를 통해 쉽게 설치할 수 있습니다jupyter notebook 설치 {5px}jupyter notebook 설치 '\n",
      " '\\ufeff\\u200bPython복사conda install jupyter\\n'\n",
      " '\\u200b jupyter notebook 시작하기Jupyter Notebook 실행jupyter notebook 실행 '\n",
      " '{5px}jupyter notebook 실행 \\ufeff\\u200bPython복사jupyter notebook\\n'\n",
      " '\\u200b이 명령어를 실행하면 웹 브라우저가 열리고, Jupyter Notebook 인터페이스가 나타납니다.새로운 노트북 '\n",
      " '생성:Jupyter Notebook 인터페이스에서 \"New\" 버튼을 클릭하고, \"Python (myenv)\"를 선택하여 새로운 노트북을 '\n",
      " '생성합니다.코드 작성 및 실행:셀(Cell)에 코드를 작성하고, 셀을 선택한 후 \"Shift + Enter\"를 눌러 코드를 '\n",
      " '실행합니다.03. 가상환경 설치 및 jupyter notebook 연결 ✔️가상환경이 무엇인지 알아보고 jupyter notebook과 '\n",
      " '가상환경을 연결해 봅시다1) 가상환경 설치  가상환경이란 무엇인가?가상환경(Virtual Environment)은 프로젝트마다 독립적인 '\n",
      " '파이썬 환경을 제공합니다.가상환경을 이용해 서로 다른 프로젝트 간의 패키지 충돌을 방지할 수 있습니다. Conda를 이용하면 쉽게 '\n",
      " '가상환경을 생성하고 관리할 수 있습니다. 가상환경 생성 및 관리가상 환경 생성 {5px}가상 환경 생성 '\n",
      " '\\ufeff\\u200bPython복사conda create --name myenv python=3.8\\n'\n",
      " '\\u200b여기서 myenv 는 가상환경의 이름이며 python=3.8은 설치할 파이썬 버전입니다여기서 myenv 는 가상환경의 이름이며 '\n",
      " 'python=3.8은 설치할 파이썬 버전입니다\\ufeff\\u200b가상 환경 비활성화 {5px}가상 환경 비활성화 '\n",
      " '\\ufeff\\u200bPython복사conda deactivate\\n'\n",
      " '\\u200b가상 환경 삭제 {5px}가상 환경 삭제 \\ufeff\\u200bPython복사conda remove --name myenv '\n",
      " '--all\\n'\n",
      " '\\u200b2) jupyter notebook 연결 jupyter notebook 연결가상환경을 Jupyter Notebook과 연결하여 '\n",
      " '사용할 수 있습니다이를 위해 ipykernel 패키지를 설치하고, 가상환경을 Jupyter Notebook에 커널로 '\n",
      " '추가합니다.ipykernel 설치 {5px}ipykernel 설치 \\ufeff\\u200bPython복사conda install '\n",
      " 'ipykernel\\n'\n",
      " '\\u200b가상환경을 Jupyter Notebook에 커널로 추가 {5px}가상환경을 Jupyter Notebook에 커널로 추가 '\n",
      " '\\ufeff\\u200bPython복사python -m ipykernel install --user --name myenv '\n",
      " '--display-name \"Python (myenv)\"\\n'\n",
      " '\\u200b여기서 myenv는 가상환경의 이름이며, \"Python (myenv)\"는 Jupyter Notebook에서 표시될 커널 '\n",
      " '이름입니다.여기서 myenv는 가상환경의 이름이며, \"Python (myenv)\"는 Jupyter Notebook에서 표시될 커널 '\n",
      " '이름입니다.\\ufeff\\u200b04. pytorch 설치✔️conda를 이용해 pytorch 설치해 봅시다1) pytorch 설치 '\n",
      " 'pytorch란 무엇인가?PyTorch는 Facebook에서 개발한 오픈 소스 딥러닝 라이브러리로, 동적 계산 그래프(dynamic '\n",
      " 'computation graph)를 지원하여 유연하고 직관적인 모델 설계가 가능합니다. pytorch 설치PyTorch는 conda를 '\n",
      " '통해 쉽게 설치할 수 있습니다.설치 명령어는 운영체제와 CUDA 버전에 따라 다르므로, PyTorch 공식 웹사이트에서 설치 명령어를 '\n",
      " '확인할 수 있습니다. 예를 들어, CUDA 10.2를 사용하는 Windows 환경에서는 다음과 같이 설치할 수 있습니다:pytorch '\n",
      " '설치 {5px}pytorch 설치 \\ufeff\\u200bPython복사conda install pytorch torchvision '\n",
      " 'torchaudio cudatoolkit=10.2 -c pytorch\\n'\n",
      " '\\u200bCopyright ⓒ TeamSparta All rights reserved.')\n",
      "('\\n'\n",
      " 'Chunk 4:\\n'\n",
      " '[스파르타코딩클럽] 4. 인공 신경망(ANN)[SCC] 기초가 탄탄한 딥러닝/[스파르타코딩클럽] 기초가 탄탄한 딥러닝 - '\n",
      " '2주차/[스파르타코딩클럽] 4. 인공 신경망(ANN)제작:[스파르타코딩클럽] 4. 인공 신경망(ANN)[수업 목표]인공신경망의 개념에 '\n",
      " '대해서 배워보고 어떤 원리로 동작하는지 알아봅시다Pytorch로 간단한 인공신경망 모델 구현 실습을 진행해 봅시다[목차]01. 기본 '\n",
      " '구조와 동작원리02. 실습: 간단한 인공 신경망 모델 구현 (PyTorch)모든 토글을 열고 닫는 단축키\\n'\n",
      " 'Windows : Ctrl + alt + t \\n'\n",
      " 'Mac : ⌘ + ⌥ + t 01. 기본 구조와 동작원리ANN의 기본 구성요소와 어떤 방식으로 동작하는지 배워보고, ANN의 출력 '\n",
      " '레이어의 유형에 따라 어떻게 활용 할 수 있는지 확인해 봅시다1) ANN의 기본 구성 요소와 동작 방식 ANN의 기본 구성 요소인공 '\n",
      " '신경망(Artificial Neural Network, ANN)은 생물학적 신경망을 모방하여 설계된 컴퓨팅 시스템입니다ANN은 '\n",
      " '입력층(Input Layer), 은닉층(Hidden Layer), 출력층(Output Layer)으로 구성되며, 각 층은 '\n",
      " '뉴런(Neuron)으로 이루어져 있습니다.ALT입력층\\n'\n",
      " ' - 입력데이터를 받아들이는 층, 입력층의 뉴런수는 입력데이터 피쳐수와 동일 - 입력데이터를 받아들이는 층, 입력층의 뉴런수는 입력데이터 '\n",
      " '피쳐수와 동일\\ufeff\\n'\n",
      " '은닉층\\n'\n",
      " ' - 입력데이터를 처리하고 특징을 추출하는 층, 은닉층의 뉴런수와 층수는 모델의 복잡성과 성능에 영향 - 입력데이터를 처리하고 특징을 '\n",
      " '추출하는 층, 은닉층의 뉴런수와 층수는 모델의 복잡성과 성능에 영향\\ufeff\\n'\n",
      " '출력층\\n'\n",
      " ' - 최종 예측값을 출력하는 층, 출력층의 뉴런 수는 예측하려는 클래스 수 또는 회귀문제 출력차원과 동일 - 최종 예측값을 출력하는 층, '\n",
      " '출력층의 뉴런 수는 예측하려는 클래스 수 또는 회귀문제 출력차원과 동일\\ufeff\\u200b 동작 방식순전파 (Forward '\n",
      " 'Propagation)입력 데이터를 통해 각 층의 뉴런이 활성화되고, 최종 출력 값을 계산합니다.각 뉴런은 입력 값에 '\n",
      " '가중치(weight)를 곱하고, 바이어스(bias)를 더한 후 활성화 함수(activation function)를 통해 출력 값을 '\n",
      " '결정합니다.손실 계산 (Loss Calculation)예측 값과 실제 값의 차이를 손실 함수(Loss Function)로 '\n",
      " '계산합니다.역전파 (Backpropagation)손실 함수의 기울기를 출력층에서 입력층 방향으로 계산하고, 이를 바탕으로 가중치를 '\n",
      " '업데이트합니다.ALT2) 출력 레이어의 구성 출력레이어의 유형과 활용출력 레이어는 신경망의 최종 예측 값을 출력하는 층으로, 문제의 '\n",
      " '유형에 따라 다양한 형태로 구성될 수 있습니다.회귀 문제 (Regression):출력 레이어의 뉴런 수는 예측하려는 연속적인 값의 차원과 '\n",
      " '동일합니다.활성화 함수로는 주로 선형 함수(linear function)를 사용합니다.이진 분류 문제 (Binary '\n",
      " 'Classification):출력 레이어의 뉴런 수는 1입니다.활성화 함수로는 시그모이드 함수(Sigmoid Function)를 사용하여 '\n",
      " '출력 값을 0과 1 사이의 확률로 변환합니다.다중 클래스 분류 문제 (Multi-Class Classification):출력 레이어의 '\n",
      " '뉴런 수는 예측하려는 클래스 수와 동일합니다.활성화 함수로는 소프트맥스 함수(Softmax Function)를 사용하여 각 클래스에 대한 '\n",
      " '확률을 출력합니다.02. 실습: 간단한 인공 신경망 모델 구현 (PyTorch) PyTorch를 사용하여 간단한 인공 신경망 모델을 '\n",
      " '구축하고 학습해보겠습니다. 예제로는 MNIST 데이터셋을 사용하여 숫자 이미지를 분류하는 모델을 구현하겠습니다.1)  간단한 ANN 모델 '\n",
      " '구축 및 학습 PyTorch 및 필요한 라이브러리 임포트PyTorch 및 필요한 라이브러리 임포트 {5px}PyTorch 및 필요한 '\n",
      " '라이브러리 임포트 \\ufeff\\u200bPython복사import torch\\n'\n",
      " 'import torch.nn as nn\\n'\n",
      " 'import torch.optim as optim\\n'\n",
      " 'import torchvision\\n'\n",
      " 'import torchvision.transforms as transforms\\n'\n",
      " '\\u200b데이터셋 로드 및 전처리데이터셋 로드 및 전처리 {5px}데이터셋 로드 및 전처리 \\ufeff\\u200bPython복사# '\n",
      " '데이터셋 전처리\\n'\n",
      " 'transform = transforms.Compose([\\n'\n",
      " '    transforms.ToTensor(),\\n'\n",
      " '    transforms.Normalize((0.5,), (0.5,))\\n'\n",
      " '])\\n'\n",
      " '# MNIST 데이터셋 로드\\n'\n",
      " \"trainset = torchvision.datasets.MNIST(root='./data', train=True, \"\n",
      " 'download=True, transform=transform)\\n'\n",
      " 'trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, '\n",
      " 'shuffle=True)\\n'\n",
      " '\\n'\n",
      " \"testset = torchvision.datasets.MNIST(root='./data', train=False, \"\n",
      " 'download=True, transform=transform)\\n'\n",
      " 'testloader = torch.utils.data.DataLoader(testset, batch_size=64, '\n",
      " 'shuffle=False)\\n'\n",
      " '\\u200b 간단한 ANN 모델 정의간단한 ANN 모델 정의 {5px}간단한 ANN 모델 정의 '\n",
      " '\\ufeff\\u200bPython복사class SimpleANN(nn.Module):\\n'\n",
      " 'def __init__(self):\\n'\n",
      " 'super(SimpleANN, self).__init__()\\n'\n",
      " '        self.fc1 = nn.Linear(28 * 28, 128) # 입력층에서 은닉층으로\\n'\n",
      " '        self.fc2 = nn.Linear(128, 64) # 은닉층에서 은닉층으로\\n'\n",
      " '        self.fc3 = nn.Linear(64, 10) # 은닉층에서 출력층으로\\n'\n",
      " 'def forward(self, x):\\n'\n",
      " '        x = x.view(-1, 28 * 28) # 입력 이미지를 1차원 벡터로 변환\\n'\n",
      " '        x = torch.relu(self.fc1(x))\\n'\n",
      " '        x = torch.relu(self.fc2(x))\\n'\n",
      " '        x = self.fc3(x)\\n'\n",
      " 'return x\\n'\n",
      " '\\u200btorch.nn.Module: 모든 신경망 모듈의 기본 클래스입니다.  사용자 정의 신경망은 이 클래스를 상속받아야 '\n",
      " '합니다.nn.Linear: 선형 변환을 적용하는 완전 연결(fully connected) 레이어를 '\n",
      " '정의합니다.nn.Linear(in_features, out_features)는 입력 특징의 수와 출력 특징의 수를 '\n",
      " '지정합니다..Linear(in_features, out_features)는 입력 특징의 수와 출력 특징의 수를 '\n",
      " '지정합니다.\\ufeff\\u200btorch.relu: ReLU 활성화 함수를 적용합니다.view: 텐서의 크기를 '\n",
      " '변경합니다.x.view(-1, 28 * 28)은 입력 이미지를 1차원 벡터로 변환합니다..view(-1, 28 * 28)은 입력 이미지를 '\n",
      " '1차원 벡터로 변환합니다.\\ufeff\\u200b 모델 학습모델 학습 {5px}모델 학습 \\ufeff\\u200bPython복사# 모델 '\n",
      " '초기화\\n'\n",
      " 'model = SimpleANN()\\n'\n",
      " '# 손실 함수와 최적화 알고리즘 정의\\n'\n",
      " 'criterion = nn.CrossEntropyLoss()\\n'\n",
      " 'optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\\n'\n",
      " '# 모델 학습\\n'\n",
      " 'for epoch in range(10): # 10 에포크 동안 학습\\n'\n",
      " '    running_loss = 0.0\\n'\n",
      " 'for i, data in enumerate(trainloader, 0):\\n'\n",
      " '        inputs, labels = data\\n'\n",
      " '\\n'\n",
      " '        # 기울기 초기화\\n'\n",
      " '        optimizer.zero_grad()\\n'\n",
      " '# 순전파 + 역전파 + 최적화\\n'\n",
      " '        outputs = model(inputs)\\n'\n",
      " '        loss = criterion(outputs, labels)\\n'\n",
      " '        loss.backward()\\n'\n",
      " '        optimizer.step()\\n'\n",
      " '# 손실 출력\\n'\n",
      " '        running_loss += loss.item()\\n'\n",
      " 'if i % 100 == 99: # 매 100 미니배치마다 출력\\n'\n",
      " \"print(f'[Epoch {epoch + 1}, Batch {i + 1}] loss: {running_loss / 100:.3f}')\\n\"\n",
      " '            running_loss = 0.0\\n'\n",
      " \"print('Finished Training')\\n\"\n",
      " '\\u200bnn.CrossEntropyLoss: 다중 클래스 분류 문제에서 주로 사용되는 손실 함수입니다. 예측 값과 실제 값 사이의 '\n",
      " '교차 엔트로피 손실을 계산합니다.optim.SGD: 확률적 경사 하강법(Stochastic Gradient Descent) 최적화 '\n",
      " '알고리즘을 정의합니다.  lr은 학습률, momentum은 모멘텀 값을 지정합니다.은 학습률, momentum은 모멘텀 값을 '\n",
      " '지정합니다.\\ufeff\\u200boptimizer.zero_grad(): 이전 단계에서 계산된 기울기를 '\n",
      " '초기화합니다.loss.backward(): 역전파를 통해 기울기를 계산합니다.optimizer.step(): 계산된 기울기를 바탕으로 '\n",
      " '가중치를 업데이트합니다. 모델  평가모델 평가 {5px}모델 평가 \\ufeff\\u200bPython복사correct = 0\\n'\n",
      " 'total = 0\\n'\n",
      " 'with torch.no_grad():\\n'\n",
      " 'for data in testloader:\\n'\n",
      " '        images, labels = data\\n'\n",
      " '        outputs = model(images)\\n'\n",
      " '        _, predicted = torch.max(outputs.data, 1)\\n'\n",
      " '        total += labels.size(0)\\n'\n",
      " '        correct += (predicted == labels).sum().item()\\n'\n",
      " \"print(f'Accuracy of the network on the 10000 test images: {100 * correct / \"\n",
      " \"total:.2f}%')\\n\"\n",
      " '\\n'\n",
      " '\\u200btorch.no_grad(): 평가 단계에서는 기울기를 계산할 필요가 없으므로, 이를 비활성화하여 메모리 사용을 '\n",
      " '줄입니다.torch.max: 텐서의 최대 값을 찾습니다. torch.max(outputs.data, 1)은 각 샘플에 대해 가장 높은 '\n",
      " '확률을 가진 클래스를 반환합니다..max(outputs.data, 1)은 각 샘플에 대해 가장 높은 확률을 가진 클래스를 '\n",
      " '반환합니다.\\ufeff\\u200blabels.size(0): 배치 크기를 반환합니다.(predicted == '\n",
      " 'labels).sum().item(): 예측 값과 실제 값이 일치하는 샘플의 수를 계산합니다.Copyright ⓒ TeamSparta '\n",
      " 'All rights reserved.')\n",
      "('\\n'\n",
      " 'Chunk 5:\\n'\n",
      " '[스파르타코딩클럽] 5. 합성곱 신경망(CNN)[SCC] 기초가 탄탄한 딥러닝/[스파르타코딩클럽] 기초가 탄탄한 딥러닝 - '\n",
      " '2주차/[스파르타코딩클럽] 5. 합성곱 신경망(CNN)제작:[스파르타코딩클럽] 5. 합성곱 신경망(CNN)[수업 목표]합성곱 신경망의 '\n",
      " '개념에 대해서 배워보고 어떤 원리로 동작하는지 알아봅시다Pytorch로 간단한 CNN 모델 구현 실습을 진행해 봅시다[목차]01. '\n",
      " 'CNN의 기본 구조와 동작 원리02. 실습: CNN을 이용한 이미지 분류 (PyTorch)💡모든 토글을 열고 닫는 단축키\\n'\n",
      " 'Windows : Ctrl + alt + t \\n'\n",
      " 'Mac : ⌘ + ⌥ + t 01. CNN의 기본 구조와 동작 원리✔️CNN의 기본 구성요소와 어떤 방식으로 동작하는지 배워봅시다1) '\n",
      " 'CNN의 기본 구조 CNN의 기본 구조합성곱 신경망(Convolutional Neural Network, CNN)은 이미지와 같은 2차원 '\n",
      " '데이터의 특징을 효과적으로 추출하기 위해 설계된 신경망입니다.CNN은 주로 합성곱 층(Convolutional Layer), 풀링 '\n",
      " '층(Pooling Layer), 완전 연결 층(Fully Connected Layer)으로 구성됩니다.ALT합성곱 층 '\n",
      " '(Convolutional Layer):\\n'\n",
      " ' - 입력 이미지에 필터(커널)를 적용하여 특징 맵(feature map)을 생성합니다. - 입력 이미지에 필터(커널)를 적용하여 특징 '\n",
      " '맵(feature map)을 생성합니다.\\ufeff\\n'\n",
      " ' - 필터는 이미지의 국소적인 패턴을 학습합니다. - 필터는 이미지의 국소적인 패턴을 학습합니다.\\ufeff\\n'\n",
      " '풀링 층 (Pooling Layer)\\n'\n",
      " ' - 특징 맵의 크기를 줄이고, 중요한 특징을 추출합니다. - 특징 맵의 크기를 줄이고, 중요한 특징을 추출합니다.\\ufeff\\n'\n",
      " ' - 주로 Max Pooling과 Average Pooling이 사용됩니다. - 주로 Max Pooling과 Average '\n",
      " 'Pooling이 사용됩니다.\\ufeff\\n'\n",
      " '완전 연결 층 (Fully Connected Layer)\\n'\n",
      " ' - 추출된 특징을 바탕으로 최종 예측을 수행합니다. - 추출된 특징을 바탕으로 최종 예측을 수행합니다.\\ufeff\\n'\n",
      " ' - CNN이라는 분석레이어를 통해 추출한 특성을 바탕으로 결론을 내리는 부분 - CNN이라는 분석레이어를 통해 추출한 특성을 바탕으로 '\n",
      " '결론을 내리는 부분\\ufeff\\u200b2) 합성곱 연산과 필터 합성곱 연산의 원리와 필터의 역할합성곱 연산은 입력 이미지에 '\n",
      " '필터(커널)를 적용하여 특징 맵을 생성하는 과정입니다. 필터는 작은 크기의 행렬로, 이미지의 국소적인 패턴을 학습합니다.합성곱 '\n",
      " '연산:필터를 이미지의 각 위치에 슬라이딩하며, 필터와 이미지의 해당 부분 간의 점곱(dot product)을 계산합니다.계산된 값은 특징 '\n",
      " '맵의 해당 위치에 저장됩니다.필터의 역할:필터는 이미지의 에지(edge), 코너(corner), 텍스처(texture) 등 다양한 '\n",
      " '국소적인 패턴을 학습합니다.여러 개의 필터를 사용하여 다양한 특징 맵을 생성할 수 있습니다.3) 풀링 레이어, 플래튼 풀링 레이어의 '\n",
      " '필요성과 종류풀링 층은 특징 맵의 크기를 줄이고, 중요한 특징을 추출하는 역할을 합니다. 풀링 층은 주로 Max Pooling과 '\n",
      " 'Average Pooling이 사용됩니다.Max Pooling:필터 크기 내에서 최대 값을 선택합니다.중요한 특징을 강조하고, 불필요한 '\n",
      " '정보를 제거합니다.Average Pooling:필터 크기 내에서 평균 값을 계산합니다.특징 맵의 크기를 줄이면서, 정보의 손실을 '\n",
      " '최소화합니다. 플래튼 레이어의 역할플래튼 층(Flatten Layer)은 2차원 특징 맵을 1차원 벡터로 변환하는 역할을 합니다. 이는 '\n",
      " '완전 연결 층에 입력으로 사용하기 위해 필요합니다.4) CNN 구조와 응용 다양한 CNN 아키텍처LeNet:최초의 CNN 아키텍처 중 '\n",
      " '하나로, 손글씨 숫자 인식에 사용되었습니다.합성곱 층과 풀링 층을 반복한 후, 완전 연결 층을 사용합니다.AlexNet:2012년 '\n",
      " '이미지넷 대회에서 우승한 아키텍처로, 딥러닝의 가능성을 입증했습니다.ReLU 활성화 함수와 드롭아웃(dropout)을 도입하여 성능을 '\n",
      " '향상시켰습니다.VGG:깊고 규칙적인 구조를 가진 아키텍처로, 작은 3x3 필터를 사용하여 깊이를 증가시켰습니다.VGG16과 VGG19가 '\n",
      " '대표적인 모델입니다.02. 실습: CNN을 이용한 이미지 분류 (PyTorch)✔️ 이제 PyTorch를 사용하여 간단한 CNN 모델을 '\n",
      " '구축하고, CIFAR-10 데이터셋을 사용하여 이미지 분류를 수행해보겠습니다1)  간단한 CNN 모델을 이용한 이미지 분류 실습 '\n",
      " 'PyTorch 및 필요한 라이브러리 임포트PyTorch 및 필요한 라이브러리 임포트 {5px}PyTorch 및 필요한 라이브러리 임포트 '\n",
      " '\\ufeff\\u200bPython복사import torch\\n'\n",
      " 'import torch.nn as nn\\n'\n",
      " 'import torch.optim as optim\\n'\n",
      " 'import torchvision\\n'\n",
      " 'import torchvision.transforms as transforms\\n'\n",
      " '\\u200b데이터셋 로드 및 전처리데이터셋 로드 및 전처리 {5px}데이터셋 로드 및 전처리 \\ufeff\\u200bPython복사# '\n",
      " '데이터셋 전처리\\n'\n",
      " 'transform = transforms.Compose([\\n'\n",
      " '    transforms.ToTensor(),\\n'\n",
      " '    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\\n'\n",
      " '])\\n'\n",
      " '# CIFAR-10 데이터셋 로드\\n'\n",
      " \"trainset = torchvision.datasets.CIFAR10(root='./data', train=True, \"\n",
      " 'download=True, transform=transform)\\n'\n",
      " 'trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, '\n",
      " 'shuffle=True)\\n'\n",
      " '\\n'\n",
      " \"testset = torchvision.datasets.CIFAR10(root='./data', train=False, \"\n",
      " 'download=True, transform=transform)\\n'\n",
      " 'testloader = torch.utils.data.DataLoader(testset, batch_size=64, '\n",
      " 'shuffle=False)\\n'\n",
      " '\\u200b 간단한 CNN 모델 정의간단한 CNN 모델 정의 {5px}간단한 CNN 모델 정의 '\n",
      " '\\ufeff\\u200bPython복사class SimpleCNN(nn.Module):\\n'\n",
      " 'def __init__(self):\\n'\n",
      " 'super(SimpleCNN, self).__init__()\\n'\n",
      " '        self.conv1 = nn.Conv2d(3, 32, 3, padding=1) # 입력 채널 3, 출력 채널 32, 커널 '\n",
      " '크기 3x3\\n'\n",
      " '        self.pool = nn.MaxPool2d(2, 2) # 풀링 크기 2x2\\n'\n",
      " '        self.conv2 = nn.Conv2d(32, 64, 3, padding=1) # 입력 채널 32, 출력 채널 64, '\n",
      " '커널 크기 3x3\\n'\n",
      " '        self.fc1 = nn.Linear(64 * 8 * 8, 512) # 완전 연결 층\\n'\n",
      " '        self.fc2 = nn.Linear(512, 10) # 출력 층 (10개의 클래스)\\n'\n",
      " 'def forward(self, x):\\n'\n",
      " '        x = self.pool(torch.relu(self.conv1(x)))\\n'\n",
      " '        x = self.pool(torch.relu(self.conv2(x)))\\n'\n",
      " '        x = x.view(-1, 64 * 8 * 8) # 플래튼\\n'\n",
      " '        x = torch.relu(self.fc1(x))\\n'\n",
      " '        x = self.fc2(x)\\n'\n",
      " 'return x\\n'\n",
      " '\\u200bnn.Conv2d: 2차원 합성곱 층을 정의합니다. nn.Conv2d(in_channels, out_channels, '\n",
      " 'kernel_size, padding)은 입력 채널 수, 출력 채널 수, 커널 크기, 패딩을 지정.Conv2d(in_channels, '\n",
      " 'out_channels, kernel_size, padding)은 입력 채널 수, 출력 채널 수, 커널 크기, 패딩을 '\n",
      " '지정\\ufeff\\u200bnn.MaxPool2d: 2차원 최대 풀링 층을 정의합니다.nn.MaxPool2d(kernel_size, '\n",
      " 'stride)은 풀링 크기와 스트라이드를 지정합니다..MaxPool2d(kernel_size, stride)은 풀링 크기와 스트라이드를 '\n",
      " '지정합니다.\\ufeff\\u200bview: 텐서의 크기를 변경합니다.x.view(-1, 64 * 8 * 8)은 특징 맵을 1차원 벡터로 '\n",
      " '변환합니다..view(-1, 64 * 8 * 8)은 특징 맵을 1차원 벡터로 변환합니다.\\ufeff\\u200b 모델 학습모델 학습 '\n",
      " '{5px}모델 학습 \\ufeff\\u200bPython복사# 모델 초기화\\n'\n",
      " 'model = SimpleCNN()\\n'\n",
      " '# 손실 함수와 최적화 알고리즘 정의\\n'\n",
      " 'criterion = nn.CrossEntropyLoss()\\n'\n",
      " 'optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\\n'\n",
      " '# 모델 학습\\n'\n",
      " 'for epoch in range(10): # 10 에포크 동안 학습\\n'\n",
      " '    running_loss = 0.0\\n'\n",
      " 'for i, data in enumerate(trainloader, 0):\\n'\n",
      " '        inputs, labels = data\\n'\n",
      " '\\n'\n",
      " '        # 기울기 초기화\\n'\n",
      " '        optimizer.zero_grad()\\n'\n",
      " '# 순전파 + 역전파 + 최적화\\n'\n",
      " '        outputs = model(inputs)\\n'\n",
      " '        loss = criterion(outputs, labels)\\n'\n",
      " '        loss.backward()\\n'\n",
      " '        optimizer.step()\\n'\n",
      " '# 손실 출력\\n'\n",
      " '        running_loss += loss.item()\\n'\n",
      " 'if i % 100 == 99: # 매 100 미니배치마다 출력\\n'\n",
      " \"print(f'[Epoch {epoch + 1}, Batch {i + 1}] loss: {running_loss / 100:.3f}')\\n\"\n",
      " '            running_loss = 0.0\\n'\n",
      " \"print('Finished Training')\\n\"\n",
      " '\\u200bnn.CrossEntropyLoss: 다중 클래스 분류 문제에서 주로 사용되는 손실 함수입니다. 예측 값과 실제 값 사이의 '\n",
      " '교차 엔트로피 손실을 계산합니다.optim.SGD: 확률적 경사 하강법(Stochastic Gradient Descent) 최적화 '\n",
      " '알고리즘을 정의합니다.  lr은 학습률, momentum은 모멘텀 값을 지정합니다.은 학습률, momentum은 모멘텀 값을 '\n",
      " '지정합니다.\\ufeff\\u200boptimizer.zero_grad(): 이전 단계에서 계산된 기울기를 '\n",
      " '초기화합니다.loss.backward(): 역전파를 통해 기울기를 계산합니다.optimizer.step(): 계산된 기울기를 바탕으로 '\n",
      " '가중치를 업데이트합니다. 모델  평가모델 평가 {5px}모델 평가 \\ufeff\\u200bPython복사correct = 0\\n'\n",
      " 'total = 0\\n'\n",
      " 'with torch.no_grad():\\n'\n",
      " 'for data in testloader:\\n'\n",
      " '        images, labels = data\\n'\n",
      " '        outputs = model(images)\\n'\n",
      " '        _, predicted = torch.max(outputs.data, 1)\\n'\n",
      " '        total += labels.size(0)\\n'\n",
      " '        correct += (predicted == labels).sum().item()\\n'\n",
      " \"print(f'Accuracy of the network on the 10000 test images: {100 * correct / \"\n",
      " \"total:.2f}%')\\n\"\n",
      " '\\n'\n",
      " '\\u200btorch.no_grad(): 평가 단계에서는 기울기를 계산할 필요가 없으므로, 이를 비활성화하여 메모리 사용을 '\n",
      " '줄입니다.torch.max: 텐서의 최대 값을 찾습니다. torch.max(outputs.data, 1)은 각 샘플에 대해 가장 높은 '\n",
      " '확률을 가진 클래스를 반환합니다..max(outputs.data, 1)은 각 샘플에 대해 가장 높은 확률을 가진 클래스를 '\n",
      " '반환합니다.\\ufeff\\u200blabels.size(0): 배치 크기를 반환합니다.(predicted == '\n",
      " 'labels).sum().item(): 예측 값과 실제 값이 일치하는 샘플의 수를 계산합니다.Copyright ⓒ TeamSparta '\n",
      " 'All rights reserved.')\n",
      "('\\n'\n",
      " 'Chunk 6:\\n'\n",
      " '[스파르타코딩클럽] 6. 순환 신경망(RNN)[SCC] 기초가 탄탄한 딥러닝/[스파르타코딩클럽] 기초가 탄탄한 딥러닝 - '\n",
      " '2주차/[스파르타코딩클럽] 6. 순환 신경망(RNN)제작:[스파르타코딩클럽] 6. 순환 신경망(RNN)[수업 목표]순환 신경망(RNN) '\n",
      " '개념에 대해서 배워보고 어떤 원리로 동작하는지 알아봅시다Pytorch로 간단한 RNN 모델 구현 실습을 진행해 봅시다[목차]01. '\n",
      " 'RNN의 기본 구조와 동작 원리02. RNN과 LSTM을 이용한 시계열 데이터 예측 (PyTorch)💡모든 토글을 열고 닫는 단축키\\n'\n",
      " 'Windows : Ctrl + alt + t \\n'\n",
      " 'Mac : ⌘ + ⌥ + t 01. RNN의 기본 구조와 동작 원리✔️RNN의 기본 구성요소와 어떤 방식으로 동작하는지 배워보고, '\n",
      " 'LSTM 과 GRU에 대해 알아보고 비교해 봅시다.1) RNN의 기본 구조와 작동 방식 RNN의 기본 구조순환 신경망(Recurrent '\n",
      " 'Neural Network, RNN)은 시계열 데이터나 순차적인 데이터를 처리하기 위해 설계된 신경망입니다RNN은 이전 시간 단계의 '\n",
      " '정보를 현재 시간 단계로 전달해, 시퀀스 데이터의 패턴을 학습할 수 있습니다.ALT RNN의 동작 원리순환 구조RNN은 입력 데이터와 '\n",
      " '이전 시간 단계의 은닉 상태(hidden state)를 입력으로 받아, 현재 시간 단계의 은닉 상태를 출력합니다.은닉 상태는 시퀀스의 '\n",
      " '정보를 저장하고, 다음 시간 단계로 전달됩니다.동작 원리RNN은 시퀀스의 각 시간 단계에서 동일한 가중치를 공유하여, 시퀀스의 패턴을 '\n",
      " '학습합니다.순전파(Forward Propagation)와 역전파(Backpropagation Through Time, BPTT)를 통해 '\n",
      " '가중치를 학습합니다.2) LSTM 및 GRU LSTM & GRURNN은 장기 의존성 문제(long-term dependency '\n",
      " 'problem)를 겪을 수 있습니다. 이를 해결하기 위해 LSTM과 GRU가 개발되었습니다. LSTM(Long Short-Term '\n",
      " 'Memory)LSTM은 셀 상태(cell state)와 게이트(gate) 구조를 도입, 장기 의존성을 효과적으로 학습가능 '\n",
      " '합니다.LSTM은 입력 게이트(input gate), 출력 게이트(output gate), 망각 게이트(forget gate)를 사용하여 '\n",
      " '정보를 조절합니다. GRU (Gated Recurrent Unit)GRU는 LSTM의 변형으로, 셀 상태 대신 은닉 상태(hidden '\n",
      " 'state)만을 사용하여 구조를 단순화합니다.GRU는 업데이트 게이트(update gate)와 리셋 게이트(reset gate)를 '\n",
      " '사용하여 정보를 조절합니다. 차이점LSTM은 셀 상태와 은닉 상태를 모두 사용하며, 더 복잡한 게이트 구조를 가집니다.GRU는 은닉 '\n",
      " '상태만을 사용하며, 더 간단한 게이트 구조를 가집니다. 따라서 계산 비용이 적고, 학습이 빠를 수 있습니다.ALT3) 시계열 데이터 처리 '\n",
      " 'RNN을 이용한 시계열 데이터 처리 방법RNN은 시계열 데이터나 순차적인 데이터를 처리하는 데 적합합니다. 예를 들어, 주식 가격 예측, '\n",
      " '날씨 예측, 텍스트 생성 등이 있습니다.데이터 전처리:시계열 데이터를 적절한 형태로 변환하고, '\n",
      " '정규화(normalization)합니다.입력 시퀀스와 출력 시퀀스를 정의합니다.모델 구축:RNN, LSTM, GRU 등의 모델을 '\n",
      " '정의합니다.입력 크기, 은닉 상태 크기, 출력 크기 등을 설정합니다.모델 학습:손실 함수와 최적화 알고리즘을 정의합니다.순전파와 역전파를 '\n",
      " '통해 모델을 학습시킵니다.모델 평가:테스트 데이터를 사용하여 모델의 성능을 평가합니다.02. RNN과 LSTM을 이용한 시계열 데이터 '\n",
      " '예측 (PyTorch)✔️ 이제 PyTorch를 사용하여 간단한 RNN과 LSTM 모델을 구축하고, 시계열 데이터를 예측해보겠습니다. '\n",
      " '예제로는 Sine 파형 데이터를 사용하겠습니다.1)  간단한 RNN/LSTM 모델을 이용한 시계열 데이터 예측 실습 PyTorch 및 '\n",
      " '필요한 라이브러리 임포트PyTorch 및 필요한 라이브러리 임포트 {5px}PyTorch 및 필요한 라이브러리 임포트 '\n",
      " '\\ufeff\\u200bPython복사import torch\\n'\n",
      " 'import torch.nn as nn\\n'\n",
      " 'import torch.optim as optim\\n'\n",
      " 'import numpy as np\\n'\n",
      " 'import matplotlib.pyplot as plt\\n'\n",
      " '\\u200b데이터셋 생성 및 전처리데이터셋 생성 및 전처리 {5px}데이터셋 생성 및 전처리 \\ufeff\\u200bPython복사# '\n",
      " 'Sine 파형 데이터 생성\\n'\n",
      " 'def create_sine_wave_data(seq_length, num_samples):\\n'\n",
      " '    X = []\\n'\n",
      " '    y = []\\n'\n",
      " 'for _ in range(num_samples):\\n'\n",
      " '        start = np.random.rand()\\n'\n",
      " '        x = np.linspace(start, start + 2 * np.pi, seq_length)\\n'\n",
      " '        X.append(np.sin(x))\\n'\n",
      " '        y.append(np.sin(x + 0.1))\\n'\n",
      " 'return np.array(X), np.array(y)\\n'\n",
      " '\\n'\n",
      " 'seq_length = 50\\n'\n",
      " 'num_samples = 1000\\n'\n",
      " 'X, y = create_sine_wave_data(seq_length, num_samples)\\n'\n",
      " '# 데이터셋을 PyTorch 텐서로 변환\\n'\n",
      " 'X = torch.tensor(X, dtype=torch.float32).unsqueeze(-1)\\n'\n",
      " 'y = torch.tensor(y, dtype=torch.float32).unsqueeze(-1)\\n'\n",
      " '\\u200b 간단한 RNN 모델 정의간단한 RNN 모델 정의 {5px}간단한 RNN 모델 정의 '\n",
      " '\\ufeff\\u200bPython복사class SimpleRNN(nn.Module):\\n'\n",
      " 'def __init__(self, input_size, hidden_size, output_size):\\n'\n",
      " 'super(SimpleRNN, self).__init__()\\n'\n",
      " '        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\\n'\n",
      " '        self.fc = nn.Linear(hidden_size, output_size)\\n'\n",
      " 'def forward(self, x):\\n'\n",
      " '        h0 = torch.zeros(1, x.size(0), hidden_size) # 초기 은닉 상태\\n'\n",
      " '        out, _ = self.rnn(x, h0)\\n'\n",
      " '        out = self.fc(out[:, -1, :]) # 마지막 시간 단계의 출력\\n'\n",
      " 'return out\\n'\n",
      " '\\n'\n",
      " 'input_size = 1\\n'\n",
      " 'hidden_size = 32\\n'\n",
      " 'output_size = 1\\n'\n",
      " 'model = SimpleRNN(input_size, hidden_size, output_size)\\n'\n",
      " '\\u200bnn.RNN: 순환 신경망(RNN) 층을 정의합니다.nn.RNN(input_size, hidden_size, '\n",
      " 'batch_first)는 입력 크기, 은닉 상태 크기, 배치 차원을 첫 번째로 설정합니다..RNN(input_size, '\n",
      " 'hidden_size, batch_first)는 입력 크기, 은닉 상태 크기, 배치 차원을 첫 번째로 '\n",
      " '설정합니다.\\ufeff\\u200bnn.Linear: 선형 변환을 적용하는 완전 연결(fully connected) 레이어를 '\n",
      " '정의합니다.nn.Linear(in_features, out_features)는 입력 특징의 수와 출력 특징의 수를 '\n",
      " '지정합니다..Linear(in_features, out_features)는 입력 특징의 수와 출력 특징의 수를 '\n",
      " '지정합니다.\\ufeff\\u200b 간단한 LSTM 모델 정의간단한 LSTM 모델 정의 {5px}간단한 LSTM 모델 정의 '\n",
      " '\\ufeff\\u200bPython복사class SimpleLSTM(nn.Module):\\n'\n",
      " 'def __init__(self, input_size, hidden_size, output_size):\\n'\n",
      " 'super(SimpleLSTM, self).__init__()\\n'\n",
      " '        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\\n'\n",
      " '        self.fc = nn.Linear(hidden_size, output_size)\\n'\n",
      " 'def forward(self, x):\\n'\n",
      " '        h0 = torch.zeros(1, x.size(0), hidden_size) # 초기 은닉 상태\\n'\n",
      " '        c0 = torch.zeros(1, x.size(0), hidden_size) # 초기 셀 상태\\n'\n",
      " '        out, _ = self.lstm(x, (h0, c0))\\n'\n",
      " '        out = self.fc(out[:, -1, :]) # 마지막 시간 단계의 출력\\n'\n",
      " 'return out\\n'\n",
      " '\\n'\n",
      " 'model = SimpleLSTM(input_size, hidden_size, output_size)\\n'\n",
      " '\\u200bnn.LSTM: 장단기 메모리(LSTM) 층을 정의합니다.nn.LSTM(input_size, hidden_size, '\n",
      " 'batch_first)는 입력 크기, 은닉 상태 크기, 배치 차원을 첫 번째로 설정합니다..LSTM(input_size, '\n",
      " 'hidden_size, batch_first)는 입력 크기, 은닉 상태 크기, 배치 차원을 첫 번째로 설정합니다.\\ufeff\\u200b '\n",
      " '모델 학습모델 학습 {5px}모델 학습 \\ufeff\\u200bPython복사# 손실 함수와 최적화 알고리즘 정의\\n'\n",
      " 'criterion = nn.MSELoss()\\n'\n",
      " 'optimizer = optim.Adam(model.parameters(), lr=0.01)\\n'\n",
      " '# 모델 학습\\n'\n",
      " 'num_epochs = 100\\n'\n",
      " 'for epoch in range(num_epochs):\\n'\n",
      " '    outputs = model(X)\\n'\n",
      " '    optimizer.zero_grad()\\n'\n",
      " '    loss = criterion(outputs, y)\\n'\n",
      " '    loss.backward()\\n'\n",
      " '    optimizer.step()\\n'\n",
      " 'if (epoch + 1) % 10 == 0:\\n'\n",
      " \"print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\\n\"\n",
      " \"print('Finished Training')\\n\"\n",
      " '\\u200bnn.MSELoss: 평균 제곱 오차(MSE) 손실 함수를 정의합니다.optim.Adam: Adam 최적화 알고리즘을 '\n",
      " '정의합니다. lr은 학습률을 지정합니다.optimizer.zero_grad(): 이전 단계에서 계산된 기울기를 '\n",
      " '초기화합니다.loss.backward(): 역전파를 통해 기울기를 계산합니다.optimizer.step(): 계산된 기울기를 바탕으로 '\n",
      " '가중치를 업데이트합니다. 모델 평가 및 시각화모델 평가 및 시각화 {5px}모델 평가 및 시각화 \\ufeff\\u200bPython복사# '\n",
      " '모델 평가\\n'\n",
      " 'model.eval()\\n'\n",
      " 'with torch.no_grad():\\n'\n",
      " '    predicted = model(X).detach().numpy()\\n'\n",
      " '# 시각화\\n'\n",
      " 'plt.figure(figsize=(10, 5))\\n'\n",
      " \"plt.plot(y.numpy().flatten(), label='True')\\n\"\n",
      " \"plt.plot(predicted.flatten(), label='Predicted')\\n\"\n",
      " 'plt.legend()\\n'\n",
      " 'plt.show()\\n'\n",
      " '\\u200bmodel.eval(): 모델을 평가 모드로 전환합니다.torch.no_grad(): 평가 단계에서는 기울기를 계산할 필요가 '\n",
      " '없으므로, 이를 비활성화하여 메모리 사용을 줄입니다.detach(): 텐서를 계산 그래프에서 분리합니다.Copyright ⓒ '\n",
      " 'TeamSparta All rights reserved.')\n",
      "('\\n'\n",
      " 'Chunk 7:\\n'\n",
      " '[스파르타코딩클럽] 7. 어텐션 (Attention) 메커니즘[SCC] 기초가 탄탄한 딥러닝/[스파르타코딩클럽] 기초가 탄탄한 딥러닝 - '\n",
      " '3주차/[스파르타코딩클럽] 7. 어텐션 (Attention) 메커니즘제작:[스파르타코딩클럽] 7. 어텐션 (Attention) '\n",
      " '메커니즘[수업 목표]최근 가장 성능 좋은 매커니즘! 어텐션 메커니즘에 대해 알아봅시다Pytorch의 구현 예시를 살펴봅시다[목차]01. '\n",
      " '개념02. 실습:  Attention 메커니즘의 구현💡모든 토글을 열고 닫는 단축키\\n'\n",
      " 'Windows : Ctrl + alt + t \\n'\n",
      " 'Mac : ⌘ + ⌥ + t 01. 개념✔️어텐션 메커니즘의 기본 개념과 동작 방식에 대해 알아봅시다1) 어텐션의 기본 구성 요소와 동작 '\n",
      " '방식 Attention 메커니즘이란?Attention 메커니즘은 시퀀스 데이터에서 중요한 부분에 더 많은 가중치를 할당하여 정보를 '\n",
      " '효율적으로 처리하는 기법주로 자연어 처리(NLP)와 시계열 데이터에서 사용되며, 기계 번역, 요약, 질의응답 시스템 등 다양한 분야에서 '\n",
      " '뛰어난 성능을 발휘 동작 방식개요Attention 메커니즘은 입력 시퀀스의 각 요소에 대해 중요도를 계산하여 가중치를 부여합니다. 이를 '\n",
      " '통해 중요한 정보에 집중하고, 불필요한 정보를 무시할 수 있습니다. Attention 메커니즘은 주로 세 가지 주요 구성 요소로 '\n",
      " '이루어집니다: Query, Key, Value.Attention 스코어 계산Attention 스코어는 Query와 Key 간의 유사도를 '\n",
      " '측정하여 중요도를 계산합니다. 이 유사도는 내적(dot product) 등을 사용하여 계산할 수 '\n",
      " '있습니다.score(Q,K)=Q⋅KT(Q, K) = Q  K^Tscore(Q,K)=Q⋅KT\\ufeff\\u200bSoftmax를 통한 '\n",
      " '가중치 계산계산된 Attention 스코어는 Softmax 함수를 통해 확률 분포로 변환됩니다. 이를 통해 가중치의 합이 1이 되도록 '\n",
      " '합니다.αi=exp\\u2061(score(Q,Ki))∑jexp\\u2061(score(Q,Kj))_i = (Q, K_i))}{_{j} '\n",
      " '((Q, '\n",
      " 'K_j))}αi\\u200b=∑j\\u200bexp(score(Q,Kj\\u200b))exp(score(Q,Ki\\u200b))\\u200b\\ufeff\\u200bSoftmax를 '\n",
      " '통한 가중치 계산Softmax를 통해 얻어진 가중치를 Value에 곱하여 최종 Attention 출력을 '\n",
      " '계산합니다.Attention(Q,K,V)=∑iαiVi(Q, K, V) = _{i} _i '\n",
      " 'V_iAttention(Q,K,V)=∑i\\u200bαi\\u200bVi\\u200b\\ufeff\\u200b2)  Self-Attention과 '\n",
      " 'Multi-Head Attention Self-AttentionSelf-Attention은 시퀀스 내의 각 요소가 서로를 참조하는 '\n",
      " '메커니즘입니다. 입력 시퀀스의 모든 요소가 Query, Key, Value로 사용됩니다. 이를 통해 각 요소가 시퀀스 내 다른 요소들과의 '\n",
      " '관계를 학습할 수 있습니다.예를 들어, 문장 내에서 단어 간의 관계를 학습하여 번역이나 요약에 활용할 수 있습니다. Multi-Head '\n",
      " 'AttentionMulti-Head Attention은 여러 개의 Self-Attention을 병렬로 수행하는 메커니즘입니다. 각 헤드는 '\n",
      " '서로 다른 부분의 정보를 학습하며, 이를 통해 모델이 다양한 관점에서 데이터를 처리할 수 있습니다.02. 실습:  Attention '\n",
      " '메커니즘의 구현✔️ 어텐션의 구현에 대한 코드입니다! 사실 어텐션을 직접 구현하는 일은 굉장히 적어요.\\n'\n",
      " '한번 훑는 정도로 넘어갑시다!1)  Attention Scaled Dot-Product AttentionScaled Dot-Product '\n",
      " 'attention 메커니즘 구현{5px}Scaled Dot-Product attention 메커니즘 '\n",
      " '구현\\ufeff\\u200bPython복사import torch\\n'\n",
      " 'import torch.nn.functional as F\\n'\n",
      " '\\n'\n",
      " 'def scaled_dot_product_attention(Q, K, V):\\n'\n",
      " '    d_k = Q.size(-1) # Key의 차원 수\\n'\n",
      " '    scores = torch.matmul(Q, K.transpose(-2, -1)) / '\n",
      " 'torch.sqrt(torch.tensor(d_k, dtype=torch.float32)) # 유사도 계산 및 스케일링\\n'\n",
      " '    attn_weights = F.softmax(scores, dim=-1) # Softmax를 통한 가중치 계산\\n'\n",
      " '    output = torch.matmul(attn_weights, V) # 가중합을 통한 최종 출력 계산\\n'\n",
      " 'return output, attn_weights\\n'\n",
      " '\\n'\n",
      " '\\u200b Multi-Head Attention Multi-Head Attention 메커니즘 구현{5px} Multi-Head '\n",
      " 'Attention 메커니즘 구현\\ufeff\\u200bPython복사class MultiHeadAttention(nn.Module):\\n'\n",
      " 'def __init__(self, embed_size, heads):\\n'\n",
      " 'super(MultiHeadAttention, self).__init__()\\n'\n",
      " '        self.embed_size = embed_size\\n'\n",
      " '        self.heads = heads\\n'\n",
      " '        self.head_dim = embed_size // heads\\n'\n",
      " '\\n'\n",
      " '        assert (\\n'\n",
      " '            self.head_dim * heads == embed_size\\n'\n",
      " '        ), \"Embedding size needs to be divisible by heads\"\\n'\n",
      " '\\n'\n",
      " '        self.values = nn.Linear(self.head_dim, self.head_dim, bias=False)\\n'\n",
      " '        self.keys = nn.Linear(self.head_dim, self.head_dim, bias=False)\\n'\n",
      " '        self.queries = nn.Linear(self.head_dim, self.head_dim, bias=False)\\n'\n",
      " '        self.fc_out = nn.Linear(heads * self.head_dim, embed_size)\\n'\n",
      " 'def forward(self, values, keys, query, mask=None):\\n'\n",
      " '        N = query.shape[0]\\n'\n",
      " '        value_len, key_len, query_len = values.shape[1], keys.shape[1], '\n",
      " 'query.shape[1]\\n'\n",
      " '# Linear transformations\\n'\n",
      " '        values = self.values(values).view(N, value_len, self.heads, '\n",
      " 'self.head_dim)\\n'\n",
      " '        keys = self.keys(keys).view(N, key_len, self.heads, self.head_dim)\\n'\n",
      " '        queries = self.queries(query).view(N, query_len, self.heads, '\n",
      " 'self.head_dim)\\n'\n",
      " '# Scaled dot-product attention\\n'\n",
      " '        out, _ = scaled_dot_product_attention(queries, keys, values)\\n'\n",
      " '\\n'\n",
      " '        out = out.view(N, query_len, self.heads * self.head_dim)\\n'\n",
      " '        out = self.fc_out(out)\\n'\n",
      " 'return out\\n'\n",
      " '\\n'\n",
      " '\\u200bCopyright ⓒ TeamSparta All rights reserved.')\n",
      "('\\n'\n",
      " 'Chunk 8:\\n'\n",
      " '[스파르타코딩클럽] 8. 자연어 처리(NLP) 모델[SCC] 기초가 탄탄한 딥러닝/[스파르타코딩클럽] 기초가 탄탄한 딥러닝 - '\n",
      " '3주차/[스파르타코딩클럽] 8. 자연어 처리(NLP) 모델제작:[스파르타코딩클럽] 8. 자연어 처리(NLP) 모델[수업 목표]자연어 처리 '\n",
      " '모델에 대해서 알아보고 동작 원리에 대해서 학습해 봅시다Pytorch로 간단한 텍스트 분류 및 생성 모델 구현 실습을 진행해 '\n",
      " '봅시다[목차]01. 워드 임베딩과 시퀀스 모델링02. Transformer와 BERT💡모든 토글을 열고 닫는 단축키\\n'\n",
      " 'Windows : Ctrl + alt + t \\n'\n",
      " 'Mac : ⌘ + ⌥ + t 01. 워드 임베딩과 시퀀스 모델링✔️워드임베딩 기법이 무엇인지 알아보고 시퀀스 모델링이 무엇인지 학습해 '\n",
      " '봅시다1) 워드 임베딩 기법 워드 임베딩 기법워드 임베딩(Word Embedding)은 단어를 고정된 크기의 벡터로 변환하는 기법으로, '\n",
      " '단어 간의 의미적 유사성을 반영합니다.대표적인 워드 임베딩 기법으로는 Word2Vec과 GloVe가 있습니다.ALT '\n",
      " 'Word2VecWord2Vec은 단어를 벡터로 변환하는 두 가지 모델(CBOW와 Skip-gram)을 제공합니다.CBOW '\n",
      " '(Continuous Bag of Words): 주변 단어(context)로 중심 단어(target)를 예측합니다.Skip-gram: '\n",
      " '중심 단어(target)로 주변 단어(context)를 예측합니다. GloVe (Global Vectors for Word '\n",
      " 'Representation)GloVe는 단어-단어 공기행렬(word-word co-occurrence matrix)을 사용, 단어 벡터를 '\n",
      " '학습합니다.전역적인 통계 정보를 활용하여 단어 간의 의미적 유사성을 반영합니다.2) 시퀀스 모델링 시퀀스 모델링의 기본 개념시퀀스 '\n",
      " '모델링(Sequence Modeling)은 순차적인 데이터를 처리하고 예측하는 모델링 기법입니다. 시퀀스 모델링은 주로 RNN, '\n",
      " 'LSTM, GRU와 같은 순환 신경망을 사용합니다.ALT 입력 시퀀스시퀀스 모델링에서는 입력 데이터가 순차적인 형태로 제공됩니다.예를 '\n",
      " '들어, 텍스트 데이터는 단어의 시퀀스로 표현됩니다. 은닉 상태순환 신경망은 이전 시간 단계의 은닉 상태를 현재 시간 단계로 전달하여, '\n",
      " '시퀀스의 패턴을 학습합니다. 출력 시퀀스시퀀스 모델링의 출력은 입력 시퀀스와 동일한 길이의 시퀀스일 수도 있고, 단일 값일 수도 '\n",
      " '있습니다.02. Transformer와 BERT✔️Transformer의 구조에 대해 알아보고 이를 이용한 BERT 모델에 대해서 '\n",
      " '배워봅시다1) Transformer의 구조와 원리 Transformer의 구조와 원리Transformer는 순차적인 데이터를 병렬로 '\n",
      " '처리할 수 있는 모델로, 자연어 처리에서 뛰어난 성능을 보입니다.Transformer는 인코더-디코더(Encoder-Decoder) '\n",
      " '구조로 구성됩니다.ALT 인코더 (Encoder)입력 시퀀스를 처리하여 인코딩된 표현을 생성합니다.각 인코더 층은 셀프 '\n",
      " '어텐션(Self-Attention)과 피드포워드 신경망(Feed-Forward Neural Network)으로 구성됩니다. 디코더 '\n",
      " '(Decoder)인코딩된 표현을 바탕으로 출력 시퀀스를 생성합니다.각 디코더 층은 셀프 어텐션, 인코더-디코더 어텐션, 피드포워드 '\n",
      " '신경망으로 구성됩니다. 어텐션 메커니즘 (Attention Mechanism)어텐션 메커니즘은 입력 시퀀스의 각 위치에 가중치를 '\n",
      " '부여하여, 중요한 정보를 강조합니다.셀프 어텐션은 입력 시퀀스 내의 단어 간의 관계를 학습합니다.2) BERT의 개념과 응용 '\n",
      " 'BERT란?BERT(Bidirectional Encoder Representations from Transformers)는 '\n",
      " 'Transformer 인코더를 기반으로 한 사전 학습된 언어 모델입니다.BERT는 양방향으로 문맥을 이해할 수 있어, 다양한 자연어 처리 '\n",
      " '작업에서 뛰어난 성능을 보입니다. 사전 학습(Pre-training)BERT는 대규모 텍스트 코퍼스를 사용하여 사전 학습됩니다.마스킹 '\n",
      " '언어 모델(Masked Language Model)과 다음 문장 예측(Next Sentence Prediction) 작업을 통해 '\n",
      " '학습됩니다. 파인튜닝 (Fine-tuning)사전 학습된 BERT 모델을 특정 작업에 맞게 파인튜닝합니다.텍스트 분류, 질의 응답, '\n",
      " '텍스트 생성 등 다양한 자연어 처리 작업에 적용할 수 있습니다.Copyright ⓒ TeamSparta All rights '\n",
      " 'reserved.')\n",
      "('\\n'\n",
      " 'Chunk 9:\\n'\n",
      " '[스파르타코딩클럽] 9. ResNet[SCC] 기초가 탄탄한 딥러닝/[스파르타코딩클럽] 기초가 탄탄한 딥러닝 - '\n",
      " '4주차/[스파르타코딩클럽] 9. ResNet제작:[스파르타코딩클럽] 9. ResNet[수업 목표]비전 모델의 길을 열어준 ResNet!왜 '\n",
      " '좋은 지 한번 알아봅시다[목차]01. 개념💡모든 토글을 열고 닫는 단축키\\n'\n",
      " 'Windows : Ctrl + alt + t \\n'\n",
      " 'Mac : ⌘ + ⌥ + t 01. 개념✔️ResNet 기본 개념과 동작 방식에 대해 알아봅시다1) ResNet 기본 개념과 동작 방식 '\n",
      " 'ResNet이란?ResNet(Residual Network)은 깊은 신경망을 학습하기 위해 개발된 모델로, 잔차 학습(Residual '\n",
      " 'Learning) 개념을 도입하여 매우 깊은 네트워크에서도 효율적인 학습이 가능하도록 합니다. ResNet은 2015년 Microsoft '\n",
      " 'Research에서 개발되었으며, 딥러닝 모델이 너무 깊어질 때 발생하는 기울기 소실 문제를 해결합니다.  ResNet의 기본 개념깊은 '\n",
      " '신경망의 문제깊은 신경망은 더 많은 계층을 쌓아 복잡한 패턴을 학습할 수 있지만, 너무 깊어지면 학습이 어려워지는 문제가 있습니다. 주로 '\n",
      " '기울기 소실(Vanishing Gradient)이나 기울기 폭발(Exploding Gradient) 같은 현상 때문에 발생합니다. 이는 '\n",
      " '모델이 더 이상 깊어지지 못하고 성능이 저하되는 결과를 초래합니다.잔차 학습(Residual Learning)ResNet은 이러한 문제를 '\n",
      " '해결하기 위해 잔차 학습(Residual Learning)을 도입합니다. 잔차 학습은 각 층의 출력이 바로 다음 층의 입력으로 전달되지 '\n",
      " '않고, 이전 층의 입력을 더해줌으로써 학습을 돕습니다. 이를 통해 기울기 소실 문제를 완화할 수 있습니다.2)  ResNet의 주요 특징 '\n",
      " '기울기 소실 문제 해결ResNet은 잔차 학습을 통해 깊은 네트워크에서도 기울기 소실 문제를 해결합니다.입력을 출력에 더해줌으로써 신호가 '\n",
      " '더욱 쉽게 전달되어 학습이 원활하게 이루어집니다. 간단한 블록 구조ResNet은 간단한 블록 구조를 사용하여 네트워크를 쉽게 확장할 수 '\n",
      " '있습니다.  높은 성능ResNet은 이미지 분류, 객체 검출 등 다양한 컴퓨터 비전 작업에서 높은 성능을 발휘합니다. 깊은 네트워크에서도 '\n",
      " '안정적으로 학습할 수 있어, 복잡한 패턴을 잘 학습합니다.3) ResNet 실습 코드Python복사import torch\\n'\n",
      " 'import torch.nn as nn\\n'\n",
      " 'import torch.nn.functional as F\\n'\n",
      " '\\n'\n",
      " 'class Block(nn.Module):\\n'\n",
      " 'def __init__(self, in_ch, out_ch, stride=1):\\n'\n",
      " 'super(Block, self).__init__()\\n'\n",
      " '# 첫 번째 컨볼루션 레이어\\n'\n",
      " '        self.conv1 = nn.Conv2d(in_ch, out_ch, kernel_size=3, stride=stride, '\n",
      " 'padding=1, bias=False)\\n'\n",
      " '        self.bn1 = nn.BatchNorm2d(out_ch) # 배치 정규화\\n'\n",
      " '# 두 번째 컨볼루션 레이어\\n'\n",
      " '        self.conv2 = nn.Conv2d(out_ch, out_ch, kernel_size=3, stride=1, '\n",
      " 'padding=1, bias=False)\\n'\n",
      " '        self.bn2 = nn.BatchNorm2d(out_ch) # 배치 정규화\\n'\n",
      " '# 입력과 출력의 차원이 다를 경우 shortcut 경로 정의\\n'\n",
      " '        self.skip_connection = nn.Sequential()\\n'\n",
      " 'if stride != 1 or in_ch != out_ch:\\n'\n",
      " '            self.skip_connection = nn.Sequential(\\n'\n",
      " '                nn.Conv2d(in_ch, out_ch, kernel_size=1, stride=stride, '\n",
      " 'bias=False), # 차원 맞추기 위한 1x1 컨볼루션\\n'\n",
      " '                nn.BatchNorm2d(out_ch) # 배치 정규화\\n'\n",
      " ')\\n'\n",
      " 'def forward(self, x):\\n'\n",
      " '# 첫 번째 컨볼루션 + ReLU 활성화 함수\\n'\n",
      " '        output = F.relu(self.bn1(self.conv1(x)))\\n'\n",
      " '# 두 번째 컨볼루션 후 배치 정규화\\n'\n",
      " '        output = self.bn2(self.conv2(output))\\n'\n",
      " '# shortcut 경로 출력과 현재 블록의 출력 더하기\\n'\n",
      " '        output += self.skip_connection(x)\\n'\n",
      " '# 최종 ReLU 활성화 함수 적용\\n'\n",
      " '        output = F.relu(output)\\n'\n",
      " 'return output\\n'\n",
      " '\\n'\n",
      " '# ResNet 모델 정의\\n'\n",
      " 'class CustomResNet(nn.Module):\\n'\n",
      " 'def __init__(self, block, layers, num_classes=10):\\n'\n",
      " 'super(CustomResNet, self).__init__()\\n'\n",
      " '        self.initial_channels = 64 # 첫 번째 레이어의 입력 채널 수 정의\\n'\n",
      " '# 첫 번째 컨볼루션 레이어\\n'\n",
      " '        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, '\n",
      " 'bias=False)\\n'\n",
      " '        self.bn1 = nn.BatchNorm2d(64) # 배치 정규화\\n'\n",
      " '# ResNet의 각 레이어 생성\\n'\n",
      " '        self.layer1 = self._create_layer(block, 64, layers[0], stride=1)\\n'\n",
      " '        self.layer2 = self._create_layer(block, 128, layers[1], stride=2)\\n'\n",
      " '        self.layer3 = self._create_layer(block, 256, layers[2], stride=2)\\n'\n",
      " '        self.layer4 = self._create_layer(block, 512, layers[3], stride=2)\\n'\n",
      " '# 평균 풀링 레이어\\n'\n",
      " '        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\\n'\n",
      " '# 최종 완전 연결 레이어\\n'\n",
      " '        self.fc = nn.Linear(512, num_classes)\\n'\n",
      " '# ResNet의 각 레이어를 생성하는 함수\\n'\n",
      " 'def _create_layer(self, block, out_ch, num_layers, stride):\\n'\n",
      " '        layer_list = []\\n'\n",
      " '# 첫 번째 블록은 stride를 받을 수 있음\\n'\n",
      " '        layer_list.append(block(self.initial_channels, out_ch, stride))\\n'\n",
      " '        self.initial_channels = out_ch  # 다음 블록을 위해 채널 수 업데이트\\n'\n",
      " '# 나머지 블록들은 기본 stride를 사용\\n'\n",
      " 'for _ in range(1, num_layers):\\n'\n",
      " '            layer_list.append(block(out_ch, out_ch))\\n'\n",
      " 'return nn.Sequential(*layer_list)\\n'\n",
      " 'def forward(self, x):\\n'\n",
      " '# 첫 번째 컨볼루션 + ReLU 활성화 함수\\n'\n",
      " '        x = F.relu(self.bn1(self.conv1(x)))\\n'\n",
      " '# 각 레이어를 순차적으로 통과\\n'\n",
      " '        x = self.layer1(x)\\n'\n",
      " '        x = self.layer2(x)\\n'\n",
      " '        x = self.layer3(x)\\n'\n",
      " '        x = self.layer4(x)\\n'\n",
      " '# 평균 풀링 및 텐서의 차원 축소\\n'\n",
      " '        x = self.avgpool(x)\\n'\n",
      " '        x = torch.flatten(x, 1)\\n'\n",
      " '# 최종 완전 연결 레이어를 통해 클래스별 예측값 출력\\n'\n",
      " '        x = self.fc(x)\\n'\n",
      " 'return x\\n'\n",
      " '\\n'\n",
      " '# Custom ResNet-18 모델 생성 (각 레이어의 블록 수는 2개씩)\\n'\n",
      " 'model = CustomResNet(Block, [2, 2, 2, 2], num_classes=10)\\n'\n",
      " '\\n'\n",
      " '\\u200bCopyright ⓒ TeamSparta All rights reserved.')\n",
      "('\\n'\n",
      " 'Chunk 10:\\n'\n",
      " '[스파르타코딩클럽] 10. 이미지 처리 모델[SCC] 기초가 탄탄한 딥러닝/[스파르타코딩클럽] 기초가 탄탄한 딥러닝 - '\n",
      " '4주차/[스파르타코딩클럽] 10. 이미지 처리 모델제작:[스파르타코딩클럽] 10. 이미지 처리 모델[수업 목표]이미지 처리 모델에 대해 '\n",
      " '배워봅시다Pytorch로 간단한 YOLO 모델 구현 실습을 진행해 봅시다[목차]01. CNN기반 이미지 분류모든 토글을 열고 닫는 '\n",
      " '단축키\\n'\n",
      " 'Windows : Ctrl + alt + t \\n'\n",
      " 'Mac : ⌘ + ⌥ + t 01. CNN기반 이미지 분류CNN기반의 이미지분류 아키텍쳐 소개와 YOLO, 이미지 세그멘테이션에 대해 '\n",
      " '배워봅시다1) ResNet 등 주요 CNN 아키텍쳐 소개 ResNet (Residual Network)ResNet은 매우 깊은 신경망을 '\n",
      " '학습할 수 있도록 설계된 아키텍처입니다.잔차 연결(Residual Connection)을 도입하여, 기울기 소실 문제를 '\n",
      " '해결합니다.ResNet-50, ResNet-101, ResNet-152 등의 변형이 있습니다. VGGVGG는 작은 3x3 필터를 사용하여 '\n",
      " '깊이를 증가시킨 아키텍처입니다.VGG16과 VGG19가 대표적인 모델입니다.단순하고 규칙적인 구조로 인해, 다양한 변형이 가능합니다. '\n",
      " 'InceptionInception은 다양한 크기의 필터를 병렬로 적용하여, 여러 수준의 특징을 추출합니다.Inception 모듈을 '\n",
      " '사용하여, 네트워크의 깊이와 너비를 동시에 확장합니다.GoogLeNet(Inception v1), Inception v2, '\n",
      " 'Inception v3 등이 있습니다.2) 객체 탐지(YOLO) YOLO(You Only Look Once) YOLO(You Only '\n",
      " 'Look Once)는 객체 탐지(Object Detection) 모델로, 이미지에서 객체의 위치와 클래스를 동시에 예측합니다.YOLO는 '\n",
      " '이미지 전체를 한 번에 처리하여, 빠르고 정확한 객체 탐지를 수행합니다.ALT YOLO의 개념YOLO는 이미지를 SxS 그리드로 나누고, '\n",
      " '각 그리드 셀에서 객체의 존재 여부를 예측합니다.각 그리드 셀은 B개의 바운딩 박스와 C개의 클래스 확률을 출력합니다. YOLO의 동작 '\n",
      " '원리입력 이미지를 CNN을 통해 특징 맵으로 변환합니다.특징 맵을 SxS 그리드로 나누고, 각 그리드 셀에서 바운딩 박스와 클래스 확률을 '\n",
      " '예측합니다.예측된 바운딩 박스와 클래스 확률을 바탕으로, 객체의 위치와 클래스를 결정합니다.3) 이미지 세그멘테이션 이미지 세그멘테이션 '\n",
      " '기법과 응용이미지 세그멘테이션(Image Segmentation)은 이미지의 각 픽셀을 클래스 레이블로 분류하는 작업입니다. 이미지 '\n",
      " '세그멘테이션은 주로 시맨틱 세그멘테이션과 인스턴스 세그멘테이션 두가지로 나뉩니다ALT시맨틱 세그멘테이션 (Semantic '\n",
      " 'Segmentation)\\n'\n",
      " '이미지의 각 픽셀을 클래스 레이블로 분류합니다이미지의 각 픽셀을 클래스 레이블로 분류합니다\\ufeff\\n'\n",
      " '인스턴스 세그멘테이션 (Instance Segmentation)\\n'\n",
      " '시맨틱 세그멘테이션과 달리, 같은 클래스 내에서도 개별 객체를 구분합니다.시맨틱 세그멘테이션과 달리, 같은 클래스 내에서도 개별 객체를 '\n",
      " '구분합니다.\\ufeff\\u200b 주요 세그멘테이션 모델FCN (Fully Convolutional Network): 모든 레이어를 '\n",
      " '합성곱 레이어로 구성하여, 픽셀 단위의 예측을 수행합니다.U-Net: U자형 구조를 가지며, 인코더-디코더 아키텍처를 사용하여 '\n",
      " '세그멘테이션을 수행합니다.Mask R-CNN: 객체 탐지와 인스턴스 세그멘테이션을 동시에 수행하는 모델입니다.Copyright ⓒ '\n",
      " 'TeamSparta All rights reserved.')\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema import Document\n",
    "\n",
    "# 로드된 문서 전처리(청킹)\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=20)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# 문자열 리스트를 Document 객체로 변환\n",
    "notion_docs = [Document(page_content=text) for text in txt_list]\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=notion_docs, embedding=OpenAIEmbeddings())\n",
    "print(f\"Number of document chunks: {len(notion_docs)}\")\n",
    "\n",
    "# 상위 10개의 청크 출력\n",
    "print(\"Top 10 chunks:\")\n",
    "for i, chunk in enumerate(notion_docs[:10], 1):\n",
    "    pprint(f\"\\nChunk {i}:\\n{chunk.page_content}\")\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "prompt = ChatPromptTemplate.from_messages([(\"system\", \"\"\"\n",
    "    당신은 AI 강사입니다. 아래 context를 기반으로 하나의 퀴즈를 만들어 사용자의 대답을 기다리세요.\n",
    "    퀴즈는 보기가 있는 객관식 또는 O,X 형태로 출제해주세요. (주로 코드 내용과 관련된 문제를 추천합니다.)\n",
    "    이후, 사용자의 대답을 확인하고 아래 형식을 바탕으로 피드백을 제공하세요:\n",
    "    - 정답 여부: \"N번\" 또는 \"예/아니오\"\n",
    "    - 추가 설명: (정답과 관련된 추가 정보를 제공하세요)\n",
    "    \n",
    "    Context: {context}\n",
    "    \"\"\")])\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "rag_chain = (\n",
    "        {\"context\": retriever | format_docs}\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Quiz:\n",
      "퀴즈: 아래 코드의 실행 결과는 무엇일까요?\n",
      "\n",
      "```python\n",
      "def add(a, b=10):\n",
      "    return a + b\n",
      "\n",
      "result = add(5)\n",
      "print(result)\n",
      "```\n",
      "\n",
      "1. 5\n",
      "2. 10\n",
      "3. 15\n",
      "4. 오류 발생\n",
      "\n",
      "정답을 선택해 주세요. (1, 2, 3, 4 중 하나를 선택해 주세요.)\n",
      "Feedback:\n",
      "AIMessage(content='사용자의 답변: 3 (15)\\n\\n피드백: 정답은 3이 맞습니다! \\n\\n코드에서 `add` 함수는 두 개의 매개변수를 가지고 있으며, 두 번째 매개변수 `b`는 기본값으로 10을 가집니다. `add(5)`를 호출할 때, `a`에는 5가 전달되고, `b`는 기본값인 10이 사용됩니다. 따라서 함수는 `5 + 10`을 계산하여 15를 반환하게 됩니다. \\n\\n결과적으로 `print(result)`는 15를 출력합니다. 잘 하셨습니다!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 134, 'prompt_tokens': 142, 'total_tokens': 276, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0705bf87c0', 'finish_reason': 'stop', 'logprobs': None}, id='run-3b7d051a-9ce6-4fdb-bc79-76dcfba145b6-0', usage_metadata={'input_tokens': 142, 'output_tokens': 134, 'total_tokens': 276})\n",
      "Generated Quiz:\n",
      "퀴즈: 다음 중 \"all-in-one\"이란 용어의 의미로 가장 적절한 것은 무엇인가요?\n",
      "\n",
      "1. 여러 기능이 하나의 플랫폼이나 제품에 통합된 형태\n",
      "2. 모든 것이 독립적으로 운영되는 방식\n",
      "3. 단일 기능만을 제공하는 시스템\n",
      "4. 모든 제품이 별도로 판매되는 경우\n",
      "\n",
      "사용자의 대답을 기다리겠습니다!\n",
      "Feedback:\n",
      "AIMessage(content='사용자의 답변: 1\\n\\n피드백: 정답입니다! \"all-in-one\"이라는 용어는 여러 기능이 하나의 플랫폼이나 제품에 통합된 형태를 의미합니다. 이는 사용자에게 편리함을 제공하고 여러 기능을 개별적으로 사용할 필요가 없게 해줍니다. 잘 하셨습니다! 추가 질문이 있으면 언제든지 물어보세요.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 85, 'prompt_tokens': 140, 'total_tokens': 225, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0705bf87c0', 'finish_reason': 'stop', 'logprobs': None}, id='run-665582c3-aa9a-4aeb-b4e2-ce6e6eda4831-0', usage_metadata={'input_tokens': 140, 'output_tokens': 85, 'total_tokens': 225})\n",
      "Generated Quiz:\n",
      "퀴즈: 다음 코드의 결과 값은 무엇일까요? \n",
      "\n",
      "```python\n",
      "def add_numbers(a, b):\n",
      "    return a + b\n",
      "\n",
      "result = add_numbers(5, 3)\n",
      "print(result)\n",
      "```\n",
      "\n",
      "1. 8\n",
      "2. 15\n",
      "3. 2\n",
      "4. 오류 발생\n",
      "\n",
      "정답을 선택해 주세요! (1, 2, 3, 4 중 하나)\n",
      "Feedback:\n",
      "AIMessage(content='사용자의 답변: 1 (8) - 정답입니다!\\n\\n피드백: 잘 하셨습니다! 코드에서 `add_numbers` 함수는 두 개의 매개변수 `a`와 `b`를 받아서 이들을 더한 값을 반환합니다. `add_numbers(5, 3)`을 호출하면 5와 3을 더한 8이 반환되며, `print(result)`는 그 값을 출력합니다. 따라서 결과는 8입니다. \\n\\n더 궁금한 점이 있으면 언제든지 질문해 주세요!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 117, 'prompt_tokens': 142, 'total_tokens': 259, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0705bf87c0', 'finish_reason': 'stop', 'logprobs': None}, id='run-35b6d03e-ea8f-47d5-81d0-6ee52fc8d936-0', usage_metadata={'input_tokens': 142, 'output_tokens': 117, 'total_tokens': 259})\n",
      "Generated Quiz:\n",
      "퀴즈: 다음 중 \"all-in-one\"이라는 용어의 의미로 가장 적절한 것은 무엇인가요?\n",
      "\n",
      "1. 모든 기능이 하나의 장치나 소프트웨어에 통합되어 있는 상태\n",
      "2. 여러 개의 서로 다른 제품을 조합하여 사용하는 것\n",
      "3. 특정 기능만을 가진 독립적인 제품\n",
      "4. 사용자가 원하는 기능만 선택적으로 사용할 수 있는 제품\n",
      "\n",
      "사용자의 대답을 기다리겠습니다!\n",
      "Feedback:\n",
      "AIMessage(content='정답입니다! \"All-in-one\"이라는 용어는 일반적으로 모든 기능이 하나의 장치나 소프트웨어에 통합되어 있는 상태를 의미합니다. 따라서 1번 선택지는 정확한 설명입니다. \\n\\n다른 선택지들은 각각 다른 개념을 나타내고 있습니다. 예를 들어, 2번은 여러 제품을 조합하는 것을, 3번은 특정 기능만을 가진 독립적인 제품을, 4번은 사용자가 원하는 기능만 선택적으로 사용할 수 있는 제품을 설명합니다. \\n\\n잘 하셨습니다! 추가적인 질문이 있다면 언제든지 말씀해 주세요.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 132, 'prompt_tokens': 151, 'total_tokens': 283, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_3de1288069', 'finish_reason': 'stop', 'logprobs': None}, id='run-4e810992-e351-44d1-b1cd-dc1db7d10bf4-0', usage_metadata={'input_tokens': 151, 'output_tokens': 132, 'total_tokens': 283})\n",
      "Generated Quiz:\n",
      "퀴즈: 다음 중 \"all-in-one\"이라는 용어가 일반적으로 사용되는 분야가 아닌 것은 무엇인가요?\n",
      "\n",
      "1. 소프트웨어\n",
      "2. 가전제품\n",
      "3. 음식 조리\n",
      "4. 자동차\n",
      "\n",
      "사용자의 대답을 기다리겠습니다.\n",
      "대화를 종료합니다.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 사용자가 \"exit\" 을 입력할 경우, 대화가 종료됩니다.\n",
    "while True: \n",
    "    query = \"context에 포함된 내용을 바탕으로 퀴즈를 생성해줘.\"\n",
    "    # if query.strip().lower() == \"exit\":\n",
    "    #     print(\"대화를 종료합니다.\")\n",
    "    #     break\n",
    "    \n",
    "    # 1. 퀴즈 생성\n",
    "    quiz = rag_chain.invoke(query)\n",
    "    print(\"Generated Quiz:\")\n",
    "    print(quiz)\n",
    "    \n",
    "    # 2. 사용자 답변 수집\n",
    "    user_answer = input(\"답변을 입력하세요: \")\n",
    "    if user_answer.strip().lower() == \"exit\":\n",
    "        print(\"대화를 종료합니다.\")\n",
    "        break\n",
    "    \n",
    "    # 3. 사용자 답변에 대한 피드백 생성\n",
    "    feedback_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", f\"\"\"\n",
    "        AI 강사로서 다음 퀴즈의 정답 여부를 확인하고 피드백을 제공하세요.\n",
    "        퀴즈: {quiz}\n",
    "        사용자의 답변: {user_answer}\n",
    "        피드백:\n",
    "        \"\"\")\n",
    "    ])\n",
    "    feedback_chain = feedback_prompt | llm\n",
    "    feedback = feedback_chain.invoke({\"quiz\": quiz, \"answer\": user_answer})\n",
    "    print(\"Feedback:\")\n",
    "    pprint(feedback)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv1014",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
