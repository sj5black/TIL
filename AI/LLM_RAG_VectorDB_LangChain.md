# LLM(Large Language Model)
 - 방대한 양의 텍스트 데이터를 학습하여 자연어를 이해하고 생성할 수 있는 인공지능 모델(GPT, BERT)
 - 매우 큰 크기의 파라미터를 가지고 있으며, 텍스트의 맥락(Context)을 파악해 다양한 언어 작업을 수행

**LLM의 주요 기능**
```
자연어 이해 (NLU) : 질문이나 명령을 이해하고 적절히 응답
텍스트 생성 : 기존 데이터를 바탕으로 자연스러운 텍스트를 생성
번역 및 요약 : 다른 언어로 번역하거나 긴 텍스트를 요약
질문 응답 (Q&A) : 사용자의 질문에 정확하게 답변하는 기능
```

>> LLM이 모든 답변을 자체적으로 생성하는 데는 한계가 있기 때문에, 이를 보완하는 기법들이 필요하고, 그 대표적인 기법 중 하나가 바로 RAG 이다.

# RAG (Retrieval-Augmented Generation)
 - 검색 기반 생성 기법
 - 최신 정보나 특정 도메인 지식에 대해 LLM이 가지는 한계를 보완
 - 직접 답을 생성하는 대신, 외부 데이터베이스나 문서에서 관련 정보를 검색한 후 그 정보를 바탕으로 답변을 생성하는 방식

**RAG 의 동작 원리**

1️. **질문 입력**
사용자가 질문을 하면, RAG 시스템은 질문에 맞는 답변을 생성하기 전에 **검색 단계**로 전환

2️. **문서 검색 (Retrieval)**
벡터DB, 기타 정보 저장소에서 질문과 관련된 문서를 검색. (텍스트를 벡터화하여 의미적으로 유사한 문서를 탐색)

3.**답변 생성 (Generation)**
검색된 문서를 바탕으로 **LLM**이 최종적으로 답변 생성

# Vector DB
 - 텍스트, 이미지 등의 데이터를 벡터 형태로 변환해 저장하고, 그 벡터를 기반으로 데이터를 빠르고 효율적으로 검색하는 데이터베이스
- 임베딩(embedding)으로 데이터를 벡터화하여, 유사한 의미를 가진 데이터들을 빠르게 검색 (임베딩은 텍스트나 이미지를 벡터로 변환하는 과정)

**Vector DB의 동작 과정**

1️. **임베딩 생성**
문서나 텍스트를 **벡터**로 변환. (해당 텍스트의 **의미적 정보**)

2️. **벡터 저장**
생성된 벡터를 데이터베이스에 저장

3️. **벡터 검색**
사용자가 검색어를 입력하면, 해당 검색어를 벡터로 변환한 후, 데이터베이스에서 **유사한 벡터**를 탐색

4️. **결과 제공**
유사한 벡터를 가진 문서나 데이터를 검색 결과로 제공

```
Vector DB는 단순 키워드 매칭이 아닌, 텍스트의 의미에 기반한 검색이 가능하여 유사한 의미를 가진 텍스트도 검색이 가능하다. 또한, 대량의 벡터 데이터를 매우 빠르게 처리할 수 있어서, 대규모 텍스트 데이터에 대해 효율적으로 검색이 가능하다.
```

# LangChain
 - LLM과 같은 언어 모델을 더욱 효율적으로 활용할 수 있게 도와주는 프레임워크
 - 다양한 LLM과 외부 리소스를 결합해 강력한 언어 기반 애플리케이션을 만들 수 있도록 돕는 것이 목표

 **LangChain의 주요 기능**

- **LLM과 데이터 소스 결합**: **RAG**처럼 외부 데이터를 검색해서 **LLM**이 이를 처리 가능
- **작업 흐름 자동화**: 여러 개의 **LLM** 작업을 순차적으로 실행할 수 있는 워크플로우를 제공
- **대화형 AI 개발**: 여러 번의 대화 흐름을 제어할 수 있는 **대화 관리** 기능을 통해 챗봇이나 대화형 에이전트를 쉽게 구축 가능
