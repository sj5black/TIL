# 과적화 방지 기법
### 1. 정규화 (Normalization)
 - 데이터의 스케일이나 분산이 서로 다른 데이터들을 표준화, 정규화 시켜서 특정 컬럼값에 weight 가 과도하게 쏠리는 현상을 방지

```
예시 데이터셋

특징 A: 키 (단위: 센티미터) – 값의 범위가 150~200
특징 B: 월 수입 (단위: 원) – 값의 범위가 2백만 원~1천만 원

이 경우, 특징 B가 값이 훨씬 큰 범위를 가지기 때문에
학습 중 모델은 자연스럽게 '월 수입'에 더 많은 가중치를 줄 가능성이 높습니다.
이로 인해 모델이 '키'보다 '월 수입'에 과도하게 의존하는 편향된 학습이 일어날 수 있고,
새로운 데이터에 대해서는 일반화 능력이 떨어지면서 과적합이 발생할 위험이 커집니다.

정규화의 과정과 효과

만약 '키'와 '월 수입'의 데이터를 각각 표준화를 통해 평균이 0이고 분산이 1이 되도록 변환하면, 두 특징의 값이 비슷한 범위에 놓이게 됩니다.
이렇게 되면 학습할 때 각 특징이 동일한 중요도로 고려되기 때문에 모델이 특정 특징에 과도하게 의존하지 않고, 더 균형 잡힌 학습을 할 수 있습니다.
이를 통해 모델이 새로운 데이터에서도 일반화 능력을 가지게 되어 과적합을 방지하는 효과를 얻을 수 있습니다.

정규화를 통해 데이터가 일정한 범위를 갖도록 하면, 가중치가 빠르게 수렴하며 학습 속도가 개선될 수 있습니다.
데이터 스케일이 일정해짐으로써 모델이 각 특징의 패턴에 고르게 학습하게 되고, 이는 학습 중에 발생할 수 있는 과적합을 줄여줍니다.
```

### 2. 드롭아웃 (Dropout)

- 조기 종료(Early Stopping)